- en: Chapter 2. Command-line Operations and Indexes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章. 命令行操作和索引
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Creating test data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建测试数据
- en: Performing simple querying, projections, and pagination from the Mongo shell
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从Mongo shell执行简单的查询、投影和分页
- en: Updating and deleting data from the shell
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从shell中更新和删除数据
- en: Creating an index and viewing plans of queries
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建索引并查看查询计划
- en: Creating a background and foreground index in the shell
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在shell中创建背景和前景索引
- en: Creating and understanding sparse indexes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和理解稀疏索引
- en: Expiring documents after a fixed interval using the TTL index
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TTL索引在固定间隔后过期文档
- en: Expiring documents at a given time using the TTL index
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TTL索引在给定时间过期文档
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In this chapter we will be performing simple queries using the mongo shell.
    Later in the chapter, we will have a detailed look at commonly used MongoDB indexes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用mongo shell执行简单的查询。在本章后面，我们将详细了解常用的MongoDB索引。
- en: Creating test data
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建测试数据
- en: This recipe is about creating test data for some of the recipes in this chapter
    and also for the later chapters in this book. We will demonstrate how to load
    a CSV file in a mongo database using the mongo import utility. This is a basic
    recipe, and if the reader is aware of the data import utility; they can just download
    the CSV file from the Packt website (`pincodes.csv`), load it in the collection
    by themselves, and skip the rest of the recipe. We will use the default database,
    `test`, and the collection will be named `postalCodes`.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方是为本章的一些配方以及本书后面的章节创建测试数据。我们将演示如何使用mongo导入实用程序将CSV文件加载到mongo数据库中。这是一个基本的配方，如果读者了解数据导入实用程序，他们可以直接从Packt网站下载CSV文件(`pincodes.csv`)，自己将其加载到集合中，并跳过其余的配方。我们将使用默认数据库`test`，集合将被命名为`postalCodes`。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The data used here is for postcodes in India. Download the `pincodes.csv` file
    from the Packt website. The file is a CSV file with 39,732 records; it should
    create 39,732 documents on successful import. We need to have the Mongo server
    up and running. Refer to the *Installing single node MongoDB* recipe from [Chapter
    1](ch01.html "Chapter 1. Installing and Starting the Server"), *Installing and
    Starting the Server* for instructions on how to start the server. The server should
    begin listening for connections on the default port, `27017`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的数据是印度的邮政编码。从Packt网站下载`pincodes.csv`文件。该文件是一个包含39,732条记录的CSV文件；成功导入后应该创建39,732个文档。我们需要让Mongo服务器处于运行状态。参考[第1章](ch01.html
    "第1章. 安装和启动服务器")中的*安装单节点MongoDB*配方，了解如何启动服务器的说明。服务器应该开始监听默认端口`27017`上的连接。
- en: How to do it…
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Execute the following command from the shell with the file to be imported in
    the current directory:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从shell中使用以下命令执行要导入的文件：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Start the mongo shell by typing in `mongo` on the command prompt.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在命令提示符上输入`mongo`来启动mongo shell。
- en: 'In the shell, execute the following command:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在shell中，执行以下命令：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How it works…
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'Assuming that the server is up and running, the CSV file has been downloaded
    and is kept in a local directory where we execute the import utility with the
    file in the current directory. Let''s look at the options given in the `mongoimport`
    utility and their meanings:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 假设服务器正在运行，CSV文件已经下载并保存在本地目录中，我们在其中执行导入实用程序。让我们看看`mongoimport`实用程序中给出的选项及其含义：
- en: '| Command-line option | Description |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 命令行选项 | 描述 |'
- en: '| --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `--type` | This specifies that the type of the input file is CSV. It defaults
    to JSON; another possible value being TSV. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| `--type` | 这指定输入文件的类型为CSV。它默认为JSON；另一个可能的值是TSV。 |'
- en: '| `-d` | This is the target database in which the data will be loaded. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| `-d` | 这是要加载数据的目标数据库。 |'
- en: '| `-c` | This is the collection in the previously mentioned database in which
    the data will be loaded. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| `-c` | 这是前面提到的数据库中要加载数据的集合。 |'
- en: '| `--headerline` | This is relevant only in case of TSV or CSV files. It indicates
    that the first line of the file is the header. The same names would be used as
    the name of the fields in the document. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| `--headerline` | 这只在TSV或CSV文件的情况下相关。它指示文件的第一行是标题。相同的名称将用作文档中字段的名称。 |'
- en: '| `--drop` | Drop the collection before importing data. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| `--drop` | 在导入数据之前删除集合。 |'
- en: The final value on the command prompt after all the options are given is the
    name of the file, `pincodes.csv`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在给出所有选项后，命令提示符上的最终值是文件名`pincodes.csv`。
- en: 'If the import goes through successfully, you should see something similar to
    the following printed to the console:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果导入成功，您应该在控制台上看到类似以下内容的输出：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Finally, we start the mongo shell and find the count of the documents in the
    collection; it should indeed be 39,732 as seen in the preceding import log.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们启动mongo shell并查找集合中文档的计数；正如在前面的导入日志中所看到的，它应该确实是39,732。
- en: Note
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The postal code data has been taken from [https://github.com/kishorek/India-Codes/](https://github.com/kishorek/India-Codes/).
    This data is not taken from an official source and might not be accurate as it
    is being compiled manually for free public use.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 邮政编码数据来自[https://github.com/kishorek/India-Codes/](https://github.com/kishorek/India-Codes/)。这些数据不是来自官方来源，可能不准确，因为它是手动编译的，供公众免费使用。
- en: See also
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Performing simple querying, projections, and pagination from Mongo shell*
    recipe is about executing some basic queries on the data imported.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*在Mongo shell中执行简单的查询、投影和分页*配方是关于在导入的数据上执行一些基本查询。'
- en: Performing simple querying, projections, and pagination from Mongo shell
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Mongo shell执行简单的查询、投影和分页
- en: In this recipe, we will get our hands dirty with a bit of querying to select
    documents from the test data that we set up in our previous recipe, *Creating
    test data*. There is nothing extravagant in this recipe and someone who is well
    versed with the query language basics can skip this recipe. Others who aren't
    too comfortable with basic querying or those who want to get a small refresher
    can continue to read the next section of the recipe. Additionally, this recipe
    is intended to get a feel of the test data setup from the previous recipe.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将通过一些查询来选择我们在前一个配方*创建测试数据*中设置的测试数据中的文档。在这个配方中没有什么奢侈的东西，熟悉查询语言基础知识的人可以跳过这个配方。其他不太熟悉基本查询或想要进行小小复习的人可以继续阅读配方的下一部分。此外，这个配方旨在让您感受到前一个配方中设置的测试数据。
- en: Getting ready
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To execute simple queries, we need to have a server up and running. A simple
    single node is what we need. Refer to the *Installing single node MongoDB* recipe
    from [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"), *Installing
    and Starting the Server* for instructions on how to start the server. The data
    that we would be operating on needs to be imported in the database. The steps
    to import the data are given in the previous recipe, *Creating test data*. You
    also need to start the mongo shell and connect to the server running on the localhost.
    Once these prerequisites are complete, we are good to go.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行简单的查询，我们需要有一个正在运行的服务器。一个简单的单节点就是我们需要的。请参考[第1章](ch01.html "第1章。安装和启动服务器")中的*安装单节点MongoDB*配方，了解如何启动服务器的说明。我们将要操作的数据需要导入到数据库中。导入数据的步骤在前一个配方*创建测试数据*中给出。您还需要启动mongo
    shell并连接到在本地主机上运行的服务器。一旦这些先决条件完成，我们就可以开始了。
- en: How to do it…
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Let''s first find a count of the documents in the collection:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先找到集合中文档的数量：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s find just one document from the `postalCodes` collection as follows:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从`postalCodes`集合中找到一个文档：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we find multiple documents in the collection as follows:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们按如下方式在集合中找到多个文档：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding query retrieves all the keys of the first 20 documents and displays
    them on the shell. At the end of the result, you will notice a line that says
    `Type "it" for more`. By typing `"it"`, the mongo shell will iterate over the
    resulting cursor. Let''s do a couple of things now; we will just display the `city`,
    `state`, and `pincode` fields. Additionally, we want to display the documents
    numbered 91 to 100 in the collection. Let''s see how we do this:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前面的查询检索了前20个文档的所有键，并在shell上显示它们。在结果的末尾，您会注意到一行，上面写着`键入"it"以获取更多内容`。通过键入`"it"`，mongo
    shell将遍历结果游标。现在让我们做一些事情；我们将只显示`city`、`state`和`pincode`字段。此外，我们想显示集合中编号为91到100的文档。让我们看看如何做到这一点：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s move a step ahead and write a slightly complex query where we find the
    top 10 cities in the state of Gujarat sorted by the name of the city, and, similar
    to the last query, we just select `city`, `state`, and the `pincode` field:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们再进一步，编写一个稍微复杂的查询，在其中按照城市名称找到古吉拉特邦的前10个城市，并且与上一个查询类似，我们只选择`city`、`state`和`pincode`字段：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works…
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: This recipe is pretty simple and allows us to get a feel for the test data that
    we set up in the previous recipe. Nevertheless, as with other recipes, I do owe
    you all some explanation for what we did here.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方非常简单，让我们感受到了我们在前一个配方中设置的测试数据。尽管如此，和其他配方一样，我确实需要向大家解释一下我们在这里做了什么。
- en: We first found the count of the documents in the collection using `db.postalCodes.count()`
    and it should give us 39,732 documents. This should be in sync with the logs that
    we saw while importing the data in the postal codes collection. We next queried
    for one document from the collection using `findOne`. This method returns the
    first document in the result set of the query. In absence of a query or sort order,
    as in this case, it will be the first document in the collection sorted by its
    natural order.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用`db.postalCodes.count()`找到了集合中文档的数量，应该有39,732个文档。这应该与我们在导入邮政编码集合数据时看到的日志保持一致。接下来，我们使用`findOne`从集合中查询一个文档。这个方法返回查询结果集中的第一个文档。在没有查询或排序顺序的情况下，就像在这种情况下一样，它将是按其自然顺序排序的集合中的第一个文档。
- en: Next, we perform `find` rather than `findOne`. The difference between both of
    them is that the `find` operation returns an iterator for the result set, which
    we can use to traverse through the results of the find operation, whereas `findOne`
    returns a document. Adding a pretty method call to the `find` operation will print
    the result in a pretty or formatted way.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们执行`find`而不是`findOne`。它们之间的区别在于`find`操作返回结果集的迭代器，我们可以使用它来遍历`find`操作的结果，而`findOne`返回一个文档。对`find`操作添加一个pretty方法调用将以漂亮或格式化的方式打印结果。
- en: Tip
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Note that the `pretty` method makes sense and works only with `find` and not
    with `findOne`. This is because the return value of `findOne` is a document and
    there is no `pretty` operation on the returned document.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`pretty`方法只对`find`有效，而对`findOne`无效。这是因为`findOne`的返回值是一个文档，而返回的文档上没有`pretty`操作。
- en: 'We will now execute the following query on the mongo shell:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将在mongo shell上执行以下查询：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, we pass two parameters to the `find` method:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们向`find`方法传递了两个参数：
- en: The first one is `{}`, which is the query to select the documents, and, in this
    case, we ask mongo to select all the documents.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个是`{}`，这是选择文档的查询，在这种情况下，我们要求mongo选择所有文档。
- en: The second parameter is the set of fields that we want in the result documents
    also known as **projection**. Remember that the `_id` field is present by default
    unless we explicitly say `_id:0`. For all the other fields, we need to say `<field_name>:1`
    or `<field_name>:true`. The find portion with projections is the same as saying
    `select field1``, field2 from table` in a relational world, and not specifying
    the fields to be selected in the find is saying `select * from table` in a relational
    world.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个参数是我们想要在结果文档中的字段集，也被称为**投影**。请记住，`_id`字段默认存在，除非我们明确指定`_id:0`。对于所有其他字段，我们需要说`<field_name>:1`或`<field_name>:true`。具有投影的查找部分与在关系世界中说`select
    field1``, field2 from table`是一样的，而不指定要选择的字段在查找中说`select * from table`在关系世界中。
- en: 'Moving on, we just need to look at what `skip` and `limit` do:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们只需要看一下`skip`和`limit`的作用：
- en: The `skip` function skips the given number of documents from the result set
    all the way up to the end document
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`skip`函数从结果集中跳过给定数量的文档，直到最后一个文档'
- en: The `limit` function then limits the result to the given number of documents
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limit`函数然后将结果限制为给定数量的文档'
- en: Let's see what this all means with an example. By doing .`skip(90).limit(10)`,
    we say that we want to skip the first `90` documents from the result set and start
    returning from the 91st document. The limit, however, says that we will be returning
    only `10` documents from the 91st document.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看看这意味着什么。通过执行.`skip(90).limit(10)`，我们说我们要跳过结果集中的前90个文档，并从第91个文档开始返回。然而，limit表示我们将只从第91个文档返回10个文档。
- en: Now, there are some border conditions that we need to know here. What if skip
    is being provided with a value more than the total number of documents in the
    collection? Well, in this case, no documents will be returned. Additionally, if
    the number provided to the limit function is more than the actual number of documents
    remaining in the collection, then the number of documents returned will be the
    same as the remaining documents in the collection and no exception will be thrown
    in either cases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这里有一些边界条件，我们需要知道。如果skip提供的值大于集合中的文档总数会怎么样？在这种情况下，将不会返回任何文档。此外，如果提供给limit函数的数字大于集合中剩余的实际文档数量，则返回的文档数量将与集合中剩余的文档数量相同，并且在任一情况下都不会抛出异常。
- en: Updating and deleting data from the shell
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从shell更新和删除数据
- en: This again will be a simple recipe that will be looking at executing deletes
    and updates on a test collection. We won't be dealing with the same test data
    that we imported as we don't want to update/delete any of that, but instead, we
    will work on a test collection created for this recipe only.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一个简单的示例，将在测试集合上执行删除和更新。我们不会处理导入的相同测试数据，因为我们不想更新/删除任何数据，而是我们将在仅为此示例创建的测试集合上工作。
- en: Getting ready
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, we will create a collection called `updAndDelTest`. We will
    require the server to be up and running. Refer to the *Installing single node
    MongoDB* recipe from [Chapter 1](ch01.html "Chapter 1. Installing and Starting
    the Server"), *Installing and Starting the Server* for instructions on how to
    start the server. Start the shell with the `UpdAndDelTest.js` script loaded. This
    script will be available on the Packt website for download. To know how to start
    the shell with a script preloaded, refer to the *Connecting to a single node in
    the Mongo shell with JavaScript* recipe in [Chapter 1](ch01.html "Chapter 1. Installing
    and Starting the Server"), *Installing and Starting the Server*.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此示例，我们将创建一个名为`updAndDelTest`的集合。我们需要服务器运行。有关如何启动服务器的说明，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*安装单节点MongoDB*示例，*安装和启动服务器*。使用加载了`UpdAndDelTest.js`脚本的shell启动。此脚本可在Packt网站上下载。要了解如何使用预加载的脚本启动shell，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*使用JavaScript连接Mongo shell中的单个节点*示例，*安装和启动服务器*。
- en: How to do it…
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤…
- en: 'Start the MongoDB shell and preload the script:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动MongoDB shell并预加载脚本：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'With the shell started and script loaded, execute the following in the shell:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用启动的shell和加载的脚本，在shell中执行以下操作：
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If all goes well, you should see `Inserted 20 documents in updAndDelTest` printed
    to the console:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一切顺利，您应该在控制台上看到`在updAndDelTest中插入了20个文档`的打印：
- en: 'To get a feel of the collection, let''s query it as follows:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了了解集合的情况，让我们查询如下：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We should see that for each value of `x` as `1` and `2`, we have `y` incrementing
    from 1 to 10 for each value of `x`.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该看到对于`x`的每个值为`1`和`2`，我们有`y`从1到10递增的值。
- en: 'We will first update some documents and observe the results. Execute the following
    update:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先更新一些文档并观察结果。执行以下更新：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Execute the following `find` command and observe the results; we should get
    10 documents. For each of them, note the value of `y`.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下`find`命令并观察结果；我们应该得到10个文档。对于每个文档，注意`y`的值。
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We shall now execute the following update:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将执行以下更新：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Executing the query given in step 6 again to view the updated documents. It
    will show the same documents that we saw earlier. Take a note of the values of
    `y` again and compare them to the results that we saw when we executed this query
    last time before executing the update given in step 7.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次执行步骤6中给出的查询以查看更新后的文档。它将显示我们之前看到的相同文档。再次注意`y`的值，并将其与我们上次执行此查询之前执行步骤7中给出的更新时看到的结果进行比较。
- en: 'We will now see how delete works. We will again choose the documents where
    `x` is `1` for the deletion test. Let''s delete all the documents where `x` is
    `1` from the collection:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将看看删除是如何工作的。我们将再次选择`x`为`1`的文档进行删除测试。让我们从集合中删除所有`x`为`1`的文档：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Execute the following `find` command and observe the results. We will not get
    any results. It seems that the `remove` operation has removed all the documents
    with `x` as `1`.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下`find`命令并观察结果。我们将不会得到任何结果。似乎`remove`操作已删除所有`x`为`1`的文档。
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: When you are in the mongo shell and you want to see the source code of a function,
    simply type in the function name without the parenthesis. For example, in this
    recipe, we can view the code of our custom function by typing the function name,
    `prepareTestData`, without the parenthesis, and press *Enter*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在mongo shell中，并且想要查看函数的源代码时，只需输入函数名称而不带括号。例如，在这个示例中，我们可以通过输入函数名称`prepareTestData`（不带括号）来查看我们自定义函数的代码，并按下*Enter*键。
- en: How it works…
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'First, we set up the data that we will use for the updating and deleting `test`.
    We have already seen the data and know what it is. An interesting thing to observe
    is that when we execute an update such as `db.updAndDelTest.update({x:1}, {$set:{y:0}})`,
    it only updates the first document that matches the query provided as the first
    parameter. This is something we will observe when we query the collection after
    this update. The update function has the following format `db.<collection name>.update(query,
    update object, {upsert: <boolean>, multi:<boolean>})`.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们设置将用于更新和删除`test`的数据。我们已经看到了数据并知道它是什么。一个有趣的观察是，当我们执行更新操作，比如`db.updAndDelTest.update({x:1},
    {$set:{y:0}})`，它只会更新与作为第一个参数提供的查询匹配的第一个文档。这是我们在此更新后查询集合时将观察到的事情。更新函数的格式如下：`db.<collection
    name>.update(query, update object, {upsert: <boolean>, multi:<boolean>})`。'
- en: We will see what upsert is in the later recipes. The multi parameter is set
    to `false` by default. This means that multiple documents will not be updated
    by the `update` method; only the first matching document will be updated. However,
    when we do `db.updAndDelTest.update({x:1}, {$set:{y:0}}, {multi:true})` with multi
    set to `true`, all the documents in the collection that match the given query
    are updated. This is something that we can verify after querying the collection.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面的示例中看到upsert是什么。multi参数默认设置为`false`。这意味着`update`方法不会更新多个文档；只有第一个匹配的文档会被更新。然而，当我们使用`db.updAndDelTest.update({x:1},
    {$set:{y:0}}, {multi:true})`并将multi设置为`true`时，集合中匹配给定查询的所有文档都会被更新。这是我们在查询集合后可以验证的事情。
- en: Removals, on the other hand, behave differently. By default, the `remove` operation
    deletes all the documents that match the provided query. However, if we want to
    delete only one document, we explicitly pass the second parameter as `true`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，删除的行为不同。默认情况下，`remove`操作会删除所有与提供的查询匹配的文档。然而，如果我们只想删除一个文档，我们可以将第二个参数明确传递为`true`。
- en: Note
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The default behavior of update and remove is different. An `update` call, by
    default, updates only the *first* matching document, whereas `remove` deletes
    *all* the documents matching the query.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 更新和删除的默认行为是不同的。默认情况下，`update`调用只会更新*第一个*匹配的文档，而`remove`会删除与查询匹配的*所有*文档。
- en: Creating index and viewing plans of queries
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建索引并查看查询计划
- en: In this recipe, we will look at querying the data, analyzing its performance
    by explaining the query plan, and then optimizing it by creating indexes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将查看如何查询数据，通过解释查询计划来分析其性能，然后通过创建索引来优化它。
- en: Getting ready
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: For the creation of indexes, we need to have a server up and running. A simple
    single node is what we need. Refer to the *Installing single node MongoDB* recipe
    from [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"), *Installing
    and Starting the Server* for instructions on how to start the server. The data
    that we will operate on needs to be imported in the database. The steps to import
    the data are given in the previous recipe, *Creating test data*. Once this prerequisite
    is complete, we are good to go.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于索引的创建，我们需要运行一个服务器。一个简单的单节点就是我们需要的。请参考[第1章](ch01.html "第1章。安装和启动服务器")中的*安装单节点MongoDB*示例，了解如何启动服务器的说明。我们将要操作的数据需要导入到数据库中。导入数据的步骤在前一个示例*创建测试数据*中给出。一旦这个先决条件完成，我们就可以开始了。
- en: How to do it…
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: We are trying to write a query that would find us all the zip codes in a given
    state.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在尝试编写一个查询，该查询将找到给定州中的所有邮政编码。
- en: 'Execute the following query to view the plan of this query:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下查询以查看此查询的计划：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Take a note of the following fields: `stage`, `nReturned`, `totalDocsExamined`,
    `docsExamined`, and `executionTimeMillis` in the result of the explain plan operation.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释计划操作的结果中，注意以下字段：`stage`、`nReturned`、`totalDocsExamined`、`docsExamined`和`executionTimeMillis`。
- en: 'Let''s again execute the same query, but this time, we limit the results to
    100 results only:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们再次执行相同的查询，但这次，我们将结果限制为仅100个结果：
- en: '[PRE18]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Take a note of the following fields: `nReturned`, `totalDocsExamined`, `docsExamined`,
    and `executionTimeMillis` in the result.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在结果中注意以下字段：`nReturned`、`totalDocsExamined`、`docsExamined`和`executionTimeMillis`。
- en: 'We now create an index on the `state` and `pincode` fields as follows:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在在`state`和`pincode`字段上创建索引，如下所示：
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Execute the following query:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下查询：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Take a note of the following fields: `stage`, `nReturned`, `totalDocsExamined`,
    `docsExamined`, and `executionTimeMillis` in the result.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意以下字段：`stage`、`nReturned`、`totalDocsExamined`、`docsExamined`和`executionTimeMillis`。
- en: 'As we want the pincodes only, we modify the query as follows and view its plan:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为我们只想要邮政编码，所以我们修改查询如下并查看其计划：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Take a note of the following fields: `stage`, `nReturned`, `totalDocsExamined`,
    `docsExamined`, and `executionTimeMillis` in the result.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在结果中注意以下字段：`stage`、`nReturned`、`totalDocsExamined`、`docsExamined`和`executionTimeMillis`。
- en: How it works…
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: There is a lot to explain here. We will first discuss what we just did and how
    to analyze the stats. Next, we will discuss some points to be kept in mind for
    the index creation and some caveats.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多要解释的地方。我们将首先讨论我们刚刚做的事情以及如何分析统计数据。接下来，我们将讨论索引创建时需要注意的一些要点和一些注意事项。
- en: Analyzing the plan
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析计划
- en: 'Okay, let''s look at the first step and analyze the output that we executed:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们看看我们执行的第一步并分析输出：
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output on my machine is as follows: ( I am skipping the nonrelevant fields
    for now.)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的机器上的输出如下：（我现在跳过了不相关的字段。）
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The value of the `stage` field in the result is `COLLSCAN`, which means that
    a full collection scan (all the documents scanned one after another) has happened
    in order to search the matching documents in the entire collection. The `nReturned`
    value is `6446`, which is the number of results that matched the query. The `totalDocsExamined`
    and `docsExamined` field have values of `39,732`, which is the number of documents
    in the collection scanned to retrieve the results. This is the also the total
    number of documents present in the collection and all were scanned for the result.
    Finally, `executionTimeMillis` is the number of milliseconds taken to retrieve
    the result.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 结果中`stage`字段的值为`COLLSCAN`，这意味着为了在整个集合中搜索匹配的文档，进行了完整的集合扫描（所有文档一个接一个地扫描）。`nReturned`的值为`6446`，这是与查询匹配的结果数量。`totalDocsExamined`和`docsExamined`字段的值为`39,732`，这是扫描集合以检索结果的文档数量。这也是集合中存在的文档总数，所有文档都被扫描以获取结果。最后，`executionTimeMillis`是检索结果所用的毫秒数。
- en: Improving the query execution time
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提高查询执行时间
- en: 'So far, the query doesn''t look too good in terms of performance and there
    is great scope for improvement. To demonstrate how the limit applied to the query
    affects the query plan, we can find the query plan again without the index but
    with the limit clause as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，就性能而言，查询看起来并不太好，有很大的改进空间。为了演示应用于查询的限制如何影响查询计划，我们可以再次找到没有索引但有限制子句的查询计划，如下所示：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The query plan this time around is interesting. Though we still haven't created
    an index, we do see an improvement in the time that the query took for execution
    and the number of objects scanned to retrieve the results. This is due to the
    fact that mongo ignores the scanning of the remaining documents once the number
    of documents specified in the `limit` function has been reached. We can thus conclude
    that it is recommended that you use the `limit` function to limit your number
    of results where the maximum number of documents accessed is known up front. This
    may give better query performance. The word `may` is important as, in the absence
    of an index, the collection might still be completely scanned if the number of
    matches is not met.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这次的查询计划很有趣。虽然我们仍然没有创建索引，但我们确实看到了查询执行所需的时间和检索结果所需的对象数量有所改善。这是因为一旦达到了`limit`函数中指定的文档数量，mongo就会忽略剩余文档的扫描。因此，我们可以得出结论，建议您使用`limit`函数来限制结果的数量，其中已知要访问的文档数量是有限的。这可能会提高查询性能。`可能`这个词很重要，因为在没有索引的情况下，如果匹配的文档数量不足，集合仍然可能被完全扫描。
- en: Improvement using indexes
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用索引进行改进
- en: 'Moving on, we then create a compound index on the state and pincode field.
    The order of the index is ascending in this case (as the value is one) and is
    not significant unless we plan to execute a multi-key sorting. This is a deciding
    factor as to whether the result can be sorted using an index only or mongo needs
    to sort it in memory later on before returning the results. As far as the plan
    of the query is concerned, we can see that there is a significant improvement:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们在state和pincode字段上创建了一个复合索引。在这种情况下，索引的顺序是升序（因为值为1），除非我们计划执行多键排序，否则这并不重要。这是一个决定性因素，决定了结果是否可以仅使用索引进行排序，还是mongo需要在返回结果之前在内存中对其进行排序。就查询计划而言，我们可以看到有了显著的改进：
- en: '[PRE25]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `inputStage` field now has the `IXSCAN` value, which shows that the index
    is indeed used now. The number of results stays, as expected, the same at `6446`.
    The number of objects scanned in the index and the documents scanned in the collection
    has now reduced to the same number of documents as in the result. This is because
    we have now used an index that gives us the starting document to scan, and only
    then, the required number of documents are scanned. This is similar to using the
    book's index to find a word or scanning the entire book to search for the word.
    As expected, the time in `executionTimeMillis` has reduced as well.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`inputStage`字段现在具有`IXSCAN`值，这表明现在确实使用了索引。结果的数量保持不变，仍为`6446`。在索引中扫描的对象数量和集合中扫描的文档数量现在已经减少到与结果中的文档数量相同。这是因为我们现在使用了一个索引，它给出了我们要扫描的起始文档，然后只扫描所需数量的文档。这类似于使用书的索引查找单词或扫描整本书以搜索单词。如预期的那样，`executionTimeMillis`中的时间也减少了。'
- en: Improvement using covered indexes
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用覆盖索引进行改进
- en: This leaves us with one field, `executionStages`, which is `FETCH`, and we will
    see what this means. To know what this value is, we need to look briefly at how
    indexes operate.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这留下了一个字段，`executionStages`，它是`FETCH`，我们将看看这意味着什么。要了解这个值是什么，我们需要简要了解索引是如何操作的。
- en: Indexes store a subset of fields of the original document in the collection.
    The fields present in the index are the same as those that the index is created
    on. The fields, however, are kept sorted in the index in an order specified during
    the index creation. Apart from the fields, there is an additional value stored
    in the index that acts as a pointer to the original document in the collection.
    Thus, whenever the user executes a query, the index is consulted to get a set
    of matches if the query contains fields that an index is present on. The pointer,
    stored with the index entries matching the query, is then used to make another
    IO operation to fetch the complete document from the collection, which is then
    returned to the user.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 索引存储了集合中原始文档的字段子集。索引中存在的字段与创建索引的字段相同。然而，这些字段按照在索引创建期间指定的顺序在索引中保持排序。除了字段之外，索引中还存储了一个额外的值，作为指向集合中原始文档的指针。因此，每当用户执行查询时，如果查询包含索引存在的字段，就会查询索引以获取一组匹配项。然后，与查询匹配的索引条目一起存储的指针被用于进行另一个IO操作，以从集合中获取完整的文档，然后返回给用户。
- en: The value of `executionStages`, which is `FETCH`, indicates that the data requested
    by the user in the query is not entirely present in the index, but an additional
    IO operation is needed to retrieve the entire document from the collection following
    the pointer from the index. If the value is present in the index itself, an additional
    operation to retrieve the document from the collection would not be necessary
    and the data from the index would be returned. This is called a covered index,
    and the value of `executionStages`, in this case, would be `IXSCAN`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`executionStages`的值为`FETCH`，表示用户在查询中请求的数据并不完全存在于索引中，而是需要进行额外的IO操作，从索引指向的集合中检索整个文档。如果值本身存在于索引中，则不需要额外的操作来从集合中检索文档，而是会返回索引中的数据。这称为覆盖索引，在这种情况下，`executionStages`的值将是`IXSCAN`。'
- en: In our case, we just needed the pincodes. So, why not use projection in our
    queries to retrieve just what we need? This would also make the index covered
    as the index entry just has the state's name and pincode, and the required data
    can be served completely without retrieving the original document from the collection.
    The plan of the query in this case is interesting too.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们只需要邮政编码。那么，为什么不在我们的查询中使用投影来检索我们需要的内容呢？这也会使索引成为覆盖索引，因为索引条目只包含州名和邮政编码，所需的数据可以完全提供，而无需从集合中检索原始文档。在这种情况下，查询的计划也很有趣。
- en: 'Execute the following command:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下命令：
- en: '[PRE26]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This gives us the following plan:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了以下计划：
- en: '[PRE27]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The value of the `totalDocsExamined` and `executionStage: PROJECTION` fields
    is something to observe. As expected, the data that we requested in the projection
    can be served from the index alone. In this case, we scanned 6446 entries in the
    index and thus, the `totalKeysExamined` value is `6446`.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '观察`totalDocsExamined`和`executionStage: PROJECTION`字段的值。如预期的那样，我们在投影中请求的数据可以仅从索引中提供。在这种情况下，我们扫描了索引中的6446个条目，因此`totalKeysExamined`的值为`6446`。'
- en: As the entire result was fetched from the index, our query did not fetch any
    documents from the collection. Hence, the value of `totalDocsExamined` is `0`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于整个结果都是从索引中获取的，我们的查询没有从集合中获取任何文档。因此，“totalDocsExamined”的值为“0”。
- en: As this collection is small, we do not see a significant difference in the execution
    time of the query. This will be more evident on larger collections. Making use
    of indexes is great and gives us a good performance. Making use of covered index
    gives us an even better performance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个集合很小，我们没有看到查询执行时间的显着差异。这在更大的集合上将更加明显。使用索引是很好的，可以给我们良好的性能。使用覆盖索引可以给我们更好的性能。
- en: Note
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The explain results feature of MongoDB has had a major overhaul in version 3.0\.
    I would suggest spending a few minutes going through its documentation at [http://docs.mongodb.org/manual/reference/explain-results/](http://docs.mongodb.org/manual/reference/explain-results/).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB版本3.0的解释结果功能进行了重大改进。我建议花几分钟阅读其文档：[http://docs.mongodb.org/manual/reference/explain-results/](http://docs.mongodb.org/manual/reference/explain-results/)。
- en: Another thing to remember is that if your document has a lot of fields, try
    and use projection to retrieve only the number of fields we need. The `_id` field
    is retrieved every time by default. Unless we plan to use it, set `_id:0` to not
    retrieve it if it is not a part of the index. Executing a covered query is the
    most efficient way to query a collection.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 还要记住的一件事是，如果您的文档有很多字段，请尝试使用投影仅检索我们需要的字段数量。默认情况下，`_id`字段会被检索。除非我们打算使用它，否则将`_id:0`设置为不检索它，如果它不是索引的一部分。执行覆盖查询是查询集合的最有效方式。
- en: Some caveats of index creations
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 索引创建的一些注意事项
- en: We will now see some pitfalls in index creation and some facts when an array
    field is used in the index.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到索引创建中的一些陷阱以及在索引中使用数组字段时的一些事实。
- en: Some of the operators that do not use the index efficiently are the `$where`,
    `$nin`, and `$exists` operators. Whenever these operators are used in the query,
    one should bear in mind that a possible performance bottleneck might occur when
    the data size increases.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一些不高效使用索引的运算符是`$where`，`$nin`和`$exists`运算符。每当在查询中使用这些运算符时，应该牢记，当数据量增加时可能会出现性能瓶颈。
- en: 'Similarly, the `$in` operator must be preferred over the `$or` operator as
    both can be used to achieve more or less the same result. As an exercise, try
    to find the pincodes in the state of Maharashtra and Gujarat in the `postalCodes`
    collection. Write two queries: one using `$or` and one using the `$in` operator.
    Explain the plan for both these queries.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，`$in`运算符必须优先于`$or`运算符，因为两者都可以用来实现或多或少相同的结果。作为练习，尝试在`postalCodes`集合中找到马哈拉施特拉邦和古吉拉特邦的邮政编码。编写两个查询：一个使用`$or`，一个使用`$in`运算符。解释这两个查询的计划。
- en: What happens when an array field is used in the index?
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 当数组字段用于索引时会发生什么？
- en: Mongo creates an index entry for each element present in the array field of
    a document. So, if there are 10 elements in an array in a document, there will
    be 10 index entries, one for each element in the array. However, there is a constraint
    while creating indexes containing array fields. When creating indexes using multiple
    fields, no more than one field can be of a type array, and this is done to prevent
    a possible explosion in the number of indexes on adding even a single element
    to the array used in the index. If we think of it carefully, an index entry is
    created for each element in the array. If multiple fields of the type array were
    allowed to be a part of an index, then we would have a large number of entries
    in the index, which would be a product of the length of these array fields. For
    example, a document added with two array fields, each of length 10, would add
    100 entries to the index if it is allowed to create one index using these two
    array fields.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Mongo为文档的数组字段中的每个元素创建一个索引条目。因此，如果文档的数组中有10个元素，将会有10个索引条目，每个数组中的元素都有一个。然而，在创建包含数组字段的索引时有一个约束。在使用多个字段创建索引时，不能有超过一个字段是数组类型，这是为了防止在数组中添加一个元素时可能导致索引数量激增。如果我们仔细考虑一下，我们会发现每个数组元素都会创建一个索引条目。如果允许多个数组字段成为索引的一部分，那么索引中的条目数量将会很大，这将是这些数组字段长度的乘积。例如，如果一个文档添加了两个长度为10的数组字段，如果允许使用这两个数组字段创建一个索引，将会向索引中添加100个条目。
- en: This should be good enough, for now, to scratch the surfaces of a plain, vanilla
    index. We will see more options and types in the following few recipes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该足够了，现在，来初步了解一个简单的、普通的索引。在接下来的几个配方中，我们将看到更多的选项和类型。
- en: Creating a background and foreground index in the shell
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在shell中创建后台和前台索引
- en: In our previous recipe, we looked at how to analyze the queries, how to decide
    what index needs to be created, and how to create indexes. This, by itself, is
    straightforward and looks reasonably simple. However, for large collections, things
    start getting worse as the index creation time is large. The objective of this
    recipe is to throw some light on these concepts and avoid these pitfalls while
    creating indexes, especially on large collections.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的配方中，我们看到了如何分析查询，如何决定需要创建什么索引，以及如何创建索引。这本身是直接的，看起来相当简单。然而，对于大型集合，随着索引创建时间的增加，情况开始变得更糟。这个配方的目标是为这些概念扔一些光，避免在创建索引时遇到这些陷阱，特别是在大型集合上。
- en: Getting ready
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: For the creation of indexes, we need to have a server up and running. A simple
    single node is what we need. Refer to the *Installing single node MongoDB* recipe
    from [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"), *Installing
    and Starting the Server* for instructions on how to start the server.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建索引，我们需要一个正在运行的服务器。一个简单的单节点就是我们需要的。请参考[第1章](ch01.html "第1章 安装和启动服务器")中的*安装单节点MongoDB*配方，了解如何启动服务器的说明。
- en: Start connecting two shells to the server by just typing `mongo` from the operating
    system shell. Both of them will, by default, connect to the `test` database.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在操作系统shell中键入`mongo`来连接两个shell到服务器。它们都将默认连接到`test`数据库。
- en: 'Our test data for zip codes is too small to demonstrate the problem faced in
    index creation on large collections. We need to have more data and thus, we will
    start by creating some data to simulate the problems during index creation. The
    data has no practical meaning but is good enough to test the concepts. Copy the
    following piece in one of the started shells and execute: (It is a pretty easy
    snippet to type out.)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的邮政编码测试数据太小，无法展示在大型集合上创建索引时遇到的问题。我们需要更多的数据，因此，我们将开始创建一些数据来模拟在创建索引过程中遇到的问题。这些数据没有实际意义，但足够测试概念。在其中一个已启动的shell中复制以下内容并执行：（这是一个相当容易输入的片段。）
- en: '[PRE28]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'A document in this collection will look something as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这个集合中的文档看起来是这样的：
- en: '[PRE29]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The execution will take quite a lot of time, so we need to be patient. Once
    the execution is over, we are all set for the action.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 执行将需要相当长的时间，所以我们需要耐心等待。一旦执行完成，我们就可以开始操作了。
- en: Note
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you are keen to know what the current number of documents loaded in the
    collection is, keep evaluating the following from the second shell periodically:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道集合中当前加载的文档数量，可以定期从第二个shell中评估以下内容：
- en: '[PRE30]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How to do it…
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Create an index on the `value` field of the document as follows:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文档的`value`字段上创建索引，如下所示：
- en: '[PRE31]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'While the index creation is in progress, which should take quite some time,
    switch over to the second console and execute the following:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在索引创建过程中，这应该需要相当长的时间，切换到第二个控制台并执行以下操作：
- en: '[PRE32]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Both the index creation shell and the one where we executed `findOne` will be
    blocked and the prompt will not be shown on both of them until the index creation
    is complete.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 索引创建shell和我们执行`findOne`的shell都将被阻塞，直到索引创建完成，两者都不会显示提示。
- en: 'Now, this was foreground index creation by default. We want to see the behavior
    in background index creation. Drop the created index as follows:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，这是默认的前台索引创建。我们想看看后台索引创建的行为。按照以下方式删除已创建的索引：
- en: '[PRE33]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Create the index again, but this time in background, as follows:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次创建索引，但这次是在后台进行，如下所示：
- en: '[PRE34]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In the second mongo shell, execute `findOne` as follows:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个mongo shell中，执行以下`findOne`：
- en: '[PRE35]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This should return one document, which is unlike the first instance, where the
    operation was blocked until the index creation completed in the foreground.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该返回一个文档，这与第一个实例不同，那里的操作会一直被阻塞，直到前台的索引创建完成。
- en: 'In the second shell, repeatedly execute the following explain operation with
    a four-to-five second interval between each explain plan invocation until the
    index creation process is complete:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个shell中，反复执行以下解释操作，每次解释计划调用之间间隔四到五秒，直到索引创建过程完成：
- en: '[PRE36]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: How it works…
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Let's now analyze what we just did. We created about five million documents
    with no practical importance, but we are just looking to get some data that will
    take a significant amount of time to build the index.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在分析一下我们刚刚做的事情。我们创建了大约五百万个没有实际重要性的文档，但我们只是想获取一些数据，这将花费大量时间来构建索引。
- en: An index can be built in two ways, in the foreground and background. In either
    case, the shell doesn't show the prompt until the `createIndex` operation has
    been completed and will block all operations until the index is created. To illustrate
    the difference between a foreground and background index creation, we executed
    a second mongo shell.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 索引可以通过两种方式构建，前台和后台。在任何一种情况下，shell在`createIndex`操作完成之前都不会显示提示，并且会阻塞所有操作，直到索引创建完成。为了说明前台和后台索引创建之间的区别，我们执行了第二个mongo
    shell。
- en: We first created the index in the foreground, which is the default behavior.
    This index building didn't allow us to query the collection (from the second shell)
    until the index was constructed. The `findOne` operation is blocked until the
    entire index was built (from the first shell) before returning the result. On
    other hand, the index that was built in the background didn't block the `findOne`
    operation. If you want to try inserting new documents into the collection while
    the index building is on, this should work very well. Feel free to drop the index
    and recreate it in the background, while simultaneously inserting a document into
    the `indexTest` collection, and you will notice that it works smoothly.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在前台创建了索引，这是默认行为。这个索引构建不允许我们查询集合（从第二个shell）直到索引构建完成。`findOne`操作在整个索引构建完成之前（从第一个shell）都会被阻塞。另一方面，在后台构建的索引不会阻塞`findOne`操作。如果您想在索引构建过程中尝试向集合中插入新文档，这应该能很好地工作。随时删除索引并在后台重新创建它，同时向`indexTest`集合中插入一个文档，您会注意到它可以顺利进行。
- en: Well, what is the difference between the two approaches and why not always build
    the index in the background? Apart from an extra parameter, `{background:true}`
    (which can also be`{background:1}`) passed as a second parameter to the `createIndex`
    call, there are few differences. The index creation process in the background
    will be slightly slower than the index created in the foreground. Furthermore,
    internally—though not relevant to the end user—the index created in the foreground
    will be more compact than the one created in the background.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这两种方法之间有什么区别，为什么不总是在后台构建索引？除了作为第二个参数传递给`createIndex`调用的额外参数`{background:true}`（也可以是`{background:1}`）之外，还有一些区别。后台索引创建过程将比前台创建的索引稍慢。此外，在内部——虽然与最终用户无关——在前台创建的索引将比在后台创建的索引更紧凑。
- en: Other than this, there will be no significant difference. In fact, if a system
    is running and an index needs to be created while it is serving the end users
    (not recommended, but a situation can come up at times that demands index creation
    in a live system), then creating an index in the background is the only way you
    can do it. There are other strategies to perform such administrative activities,
    which we will see in some recipes in the administration section.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，没有其他显著的区别。实际上，如果系统正在运行并且需要在为最终用户提供服务时创建索引（虽然不建议，但有时可能需要在活动系统中进行索引创建），那么在后台创建索引是唯一的方法。有其他策略可以执行此类管理活动，我们将在管理部分的一些示例中看到。
- en: 'To make things worse for foreground index creation, the lock acquired by mongo
    during index creation is not at the collection level but is at the database level.
    To explain what this means, we will have to drop the index on the `indexTest`
    collection and perform the following small exercise:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前台索引创建来说，mongo在索引创建期间获取的锁不是在集合级别，而是在数据库级别。为了解释这意味着什么，我们将不得不删除`indexTest`集合上的索引，并执行以下小练习：
- en: 'Start by creating the index in the foreground from the shell by executing the
    following command:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先通过从shell执行以下命令来在前台创建索引：
- en: '[PRE37]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, insert a document into the person collection, which may or may not exist
    at this point in the test database, as follows:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将一个文档插入到person集合中，该集合此时可能存在，也可能不存在于测试数据库中，如下所示：
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We will see that this insert operation in the person collection will be blocked
    while index creation on the `indexTest` collection is in process. However, if
    this insert operation was done on a collection in a different database during
    the index building, it would execute normally without blocking. (You can try this
    out as well.) This clearly shows that the lock is acquired at the database level
    and not at the collection or global level.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到，person集合中的此插入操作将在`indexTest`集合的索引创建过程中被阻塞。但是，如果此插入操作是在索引构建期间的不同数据库中的集合上执行的，它将正常执行而不会阻塞。（您也可以尝试一下。）这清楚地表明锁是在数据库级别而不是在集合或全局级别获取的。
- en: Note
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Prior to version 2.2 of mongo, locks were at the global level, which is at the
    mongod process level, and not at the database level as we saw previously. You
    need to remember this fact when dealing with a distribution of mongo older than
    version 2.2.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在mongo的2.2版本之前，锁是在全局级别，即在mongod进程级别，而不是在我们之前看到的数据库级别。当处理旧于2.2版本的mongo分布时，您需要记住这一点。
- en: Creating and understanding sparse indexes
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和理解稀疏索引
- en: Schemaless design is one of the fundamental features of Mongo. This allows documents
    in a collection to have disparate fields, with some fields present in some documents
    and absent in others. In other words, these fields might be sparse, which might
    have already given you a clue on what sparse indexes are. In this recipe, we will
    create some random test data and see how sparse indexes behave against a normal
    index. We shall see the advantages and one major pitfall of using a sparse index.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Mongo的无模式设计是Mongo的基本特性之一。这允许集合中的文档具有不同的字段，一些文档中存在一些字段，而其他文档中不存在。换句话说，这些字段可能是稀疏的，这可能已经给你一个关于稀疏索引是什么的线索。在这个示例中，我们将创建一些随机测试数据，并查看稀疏索引在普通索引中的行为。我们将看到使用稀疏索引的优势和一个主要的缺陷。
- en: Getting ready
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, we need to create a collection called `sparseTest`. We will
    require a server to be up and running. Refer to the *Installing single node MongoDB*
    recipe from [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"),
    *Installing and Starting the Server* for instructions on how to start the server.
    Start the shell with the `SparseIndexData.js` script loaded. This script is available
    on the Packt website for download. To know how to start the shell with a script
    preloaded, refer to the *Connecting to a single node in the Mongo shell with JavaScript*
    recipe in [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"),
    *Installing and Starting the Server*.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们需要创建一个名为`sparseTest`的集合。我们需要一个正在运行的服务器。有关如何启动服务器的说明，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*安装单节点MongoDB*示例，*安装和启动服务器*。使用加载了`SparseIndexData.js`脚本的shell启动。此脚本可在Packt网站上下载。要了解如何使用预加载的脚本启动shell，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*使用JavaScript在Mongo shell中连接到单个节点*示例，*安装和启动服务器*。
- en: How to do it…
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: Load the data in the collection by invoking the following. This should import
    100 documents in the `sparseTest` collection.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用以下方法加载集合中的数据。这应该会在`sparseTest`集合中导入100个文档。
- en: '[PRE39]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, take a look at the data by executing the following query, taking note
    of the `y` field in the top few results:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过执行以下查询来查看数据，注意顶部几个结果中的`y`字段：
- en: '[PRE40]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We can see that the `y` field is absent, or it is unique if it is present.
    Let''s then execute the following query:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到`y`字段不存在，或者如果存在的话是唯一的。然后执行以下查询：
- en: '[PRE41]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Take a note of the result; it contains both the documents that match the condition
    as well as fields that do not contain the given field, `y`.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意结果；它包含符合条件的文档以及不包含给定字段`y`的字段。
- en: 'As the value of `y` seems unique, let''s create a new unique index on the `y`
    field as follows:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于`y`的值似乎是唯一的，让我们按照以下方式在`y`字段上创建一个新的唯一索引：
- en: '[PRE42]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This throws an error complaining that the value is not unique and the offending
    value is the null value.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这会抛出一个错误，抱怨值不是唯一的，冒犯的值是null值。
- en: 'We will fix this by making this index sparse as follows:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将通过以下方式将此索引设置为稀疏：
- en: '[PRE43]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This should fix our problem. To confirm that the index got created, execute
    the following on the shell:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该解决我们的问题。为了确认索引已创建，请在shell上执行以下操作：
- en: '[PRE44]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This should show two indexes, the default one on `_id` and the one that we just
    created in the preceding step.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该显示两个索引，一个是默认的`_id`索引，另一个是我们刚刚在上一步中创建的索引。
- en: Now, execute the query that we executed earlier in step 3 again and see the
    result.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，再次执行我们在步骤3中执行的查询，并查看结果。
- en: 'Look at the result and compare it with what we saw before the index was created.
    Re-execute the query but with the following hint forcing a full collection scan:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看结果并将其与创建索引之前看到的结果进行比较。重新执行查询，但使用以下提示强制进行完整集合扫描：
- en: '[PRE45]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Observe the result.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察结果。
- en: How it works…
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: These were a lot of steps that we just performed. We will now dig deeper and
    explain the internals and reasoning for the weird behavior that we see while querying
    the collection that used sparse indexes.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们刚刚执行的许多步骤。我们现在将深入探讨并解释使用稀疏索引查询集合时看到的奇怪行为的内部和推理。
- en: The test data that we created using the JavaScript method just created documents
    with a key, `x`, whose value is a number starting from one, all the way up to
    100\. The value of `y` is set only when `x` is a multiple of three—its value is
    a running number as well, starting from one and should go up to a maximum of 33
    when `x` is `99`.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用JavaScript方法创建的测试数据只是创建了一个名为`x`的键的文档，其值是从一开始的数字，一直到100。只有当`x`是三的倍数时，才设置`y`的值-它的值也是一个从一开始的递增数字，当`x`是`99`时，它应该最多达到33。
- en: 'We then execute a query and see the following result:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然后执行查询并查看以下结果：
- en: '[PRE46]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The value where `y` is `2` is missing in the result and this is what we intended.
    Note that the documents where `y` isn't present are still seen in the result.
    We now plan to create an index on the `y` field. As the field is either not present
    or has a value that is unique, it seems natural that a unique index should work.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 结果中缺少`y`为`2`的值，这正是我们想要的。请注意，结果中仍然可以看到`y`不存在的文档。我们现在计划在`y`字段上创建一个索引。由于该字段要么不存在，要么具有唯一值，因此唯一索引应该能够正常工作。
- en: Internally, indexes add an entry in the index by default, even if the field
    is absent in the original document in the collection. The value going in the index
    will, however, be null. This means that there will be the same number of entries
    in the index as the number of documents in the collection. For a unique index,
    the value (including the null values) should be unique across the collection,
    which explains why we got an exception during index creation where the field is
    sparse (not present in all the documents).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在内部，索引默认情况下会在索引中添加一个条目，即使原始文档中的字段在集合中不存在。然而，进入索引的值将是null。这意味着索引中将有与集合中文档数量相同的条目。对于唯一索引，值（包括null值）应该在整个集合中是唯一的，这解释了为什么在创建稀疏字段的索引时会出现异常（字段不在所有文档中都存在）。
- en: A solution for this problem is making the index sparse, and all we did was add
    `sparse:1` to the options along with `unique:1`. This does not put an entry in
    the index if the field doesn't exist in the document. Thus, the index will now
    contain fewer entries. It will only contain those entries where the field is present
    in the document. This not only makes the index smaller, making it easy to fit
    in the memory, but also solves our problem of adding a unique constraint. The
    last thing that we want is an index of a collection with millions of documents
    to have millions of entries, where only a few hundred have some values defined.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一个方法是使索引稀疏化，我们所做的就是在选项中添加`sparse:1`以及`unique:1`。如果文档中不存在该字段，则不会在索引中放入条目。因此，索引现在将包含更少的条目。它只包含那些字段存在于文档中的条目。这不仅使索引变小，易于放入内存，而且解决了添加唯一约束的问题。我们最不希望的是，拥有数百万文档的集合的索引有数百万条目，而只有少数几百条目有一些值定义。
- en: 'Though we can see that creating a sparse index did make the index efficient,
    it introduced a new problem where some query results were not consistent. The
    same query that we executed earlier yields different results. See the following
    output:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以看到创建稀疏索引确实使索引更有效，但它引入了一个新问题，即一些查询结果不一致。我们之前执行的相同查询产生了不同的结果。请参见以下输出：
- en: '[PRE47]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Why did this happen? The answer lies in the query plan for this query. Execute
    the following to view the plan of this query:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会发生这种情况？答案在于这个查询的查询计划。执行以下操作查看此查询的计划：
- en: '[PRE48]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: This plan shows that it used the index to fetch the matching results. As this
    is a sparse index, all the documents that didn't have the `y` field are not present
    in it and they didn't show up in the result, though they should have. This is
    a pitfall that we need to be careful of when querying a collection with a sparse
    index and the query happens to use the index. It will yield unexpected results.
    One solution is to force a full collection scan, where we provide the query analyzer
    a hint using the `hint` function. Hints are used to force query analyzers to use
    a user-specified index. Though this is not recommended usually as you really need
    to know what you are doing, this is one of the scenarios where this is really
    needed. So, how do we force a full table scan? All we do is provide `{$natural:1}`
    in the `hint` function. A natural ordering of a collection is the order that it
    is stored in on the disk for a particular collection. This `hint` forces a full
    table scan and now we get the results as before. The query performance will, however,
    degrade for large collections as it is now using a full table scan.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计划表明它使用索引来获取匹配的结果。由于这是一个稀疏索引，所有没有`y`字段的文档都不在其中，它们也没有出现在结果中，尽管它们应该出现。这是一个我们在查询使用稀疏索引的集合时需要小心的陷阱。它会产生意想不到的结果。一个解决方案是强制进行全集合扫描，我们可以使用`hint`函数为查询分析器提供提示。提示用于强制查询分析器使用用户指定的索引。尽管通常不建议这样做，因为你真的需要知道你在做什么，但这是真正需要的情况之一。那么，我们如何强制进行全表扫描呢？我们只需在`hint`函数中提供`{$natural:1}`。集合的自然排序是指它在磁盘上存储的特定集合的顺序。这个`hint`强制进行全表扫描，现在我们得到了之前的结果。然而，对于大集合，查询性能会下降，因为现在使用了全表扫描。
- en: If the field is present in a lot of documents (There is no formal cutoff for
    what is a *lot*; it can be 50% for some or 75% for others.) and not really sparse,
    then making the index sparse doesn't make much sense apart from when we want to
    make it unique.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如果字段存在于许多文档中（对于什么是*很多*没有正式的标准；对于一些人来说可能是50%，对于其他人来说可能是75%），并且不是真正稀疏的，那么使索引稀疏化除了当我们想要使其唯一之外就没有太多意义了。
- en: Note
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If two documents have a null value for the same field, unique index creation
    will fail, and creating it as a sparse index will not help either.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个文档对于相同字段具有空值，唯一索引创建将失败，并且将其创建为稀疏索引也不会有帮助。
- en: Expiring documents after a fixed interval using the TTL index
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TTL索引在固定间隔后过期文档
- en: One of the interesting features in Mongo is automatically expiring data in the
    collection after a predetermined amount of time. This is a very useful tool when
    we want to purge some data older than a particular timeframe. For a relational
    database, it is not common for folks to set up a batch job that runs every night
    to perform this operation.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Mongo中一个有趣的特性是在预定的时间后自动删除集合中的数据。当我们想要清除一些比特定时间段更旧的数据时，这是一个非常有用的工具。对于关系数据库来说，通常不会有人设置每晚运行的批处理作业来执行此操作。
- en: With the TTL feature of Mongo, you need not worry about this as the database
    takes care of it out of the box. Let's see how we can achieve this.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 有了Mongo的TTL功能，您不必担心这个问题，因为数据库会自动处理。让我们看看如何实现这一点。
- en: Getting ready
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Let's create data in Mongo that we want to play with using the TTL indexes.
    We will create a collection called `ttlTest` for this purpose. We will require
    a server to be up and running. Refer to the *Installing single node MongoDB* recipe
    from [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"), *Installing
    and Starting the Server* for instructions on how to start the server. Start the
    shell with the `TTLData.js` script loaded. This script is available on the Packt
    website for download. To know how to start the shell with a script preloaded,
    refer to the *Connecting to a single node in the Mongo shell with JavaScript*
    recipe from [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"),
    *Installing and Starting the Server*.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在Mongo中创建一些数据，以便使用TTL索引进行操作。我们将为此目的创建一个名为`ttlTest`的集合。我们需要一个服务器正在运行。有关如何启动服务器的说明，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*安装单节点MongoDB*配方，*安装和启动服务器*。使用加载了`TTLData.js`脚本的shell启动。此脚本可在Packt网站上下载。要了解如何使用预加载的脚本启动shell，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*使用JavaScript在Mongo shell中连接到单节点*配方，*安装和启动服务器*。
- en: How to do it…
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Assuming that the server has started and the script provided is loaded on the
    shell, invoke the following method from the mongo shell:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设服务器已启动，并且提供的脚本已加载到shell中，请从mongo shell中调用以下方法：
- en: '[PRE49]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Create a TTL index on the `createDate` field as follows:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`createDate`字段上创建TTL索引如下：
- en: '[PRE50]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, query the collection as follows:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，按以下方式查询集合：
- en: '[PRE51]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This should give us three documents. Repeat the process and execute the `find`
    query in approximately 30-40 seconds repeatedly to see the three documents getting
    deleted until the entire collection has zero documents left in it.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该给我们三个文件。重复这个过程，并且在大约30-40秒内执行`find`查询，以便看到三个文件被删除，直到整个集合中没有文件为止。
- en: How it works…
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Let's start by opening the `TTLData.js` file and see what is going on inside
    it. The code is pretty simple and it just gets the current date using new `Date()`.
    It then creates three documents with `createDate` that were four, three, and two
    minutes behind the current time for the three documents. So, on the execution
    of the `addTTLTestData()` method in this script, we have three documents in the
    `ttlTest` collection with each having a difference of one minute in their creation
    time.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从打开`TTLData.js`文件开始，看看里面发生了什么。代码非常简单，它只是使用new `Date()`获取当前日期。然后在这个脚本中的`addTTLTestData()`方法的执行中，我们有三个文档在`ttlTest`集合中，每个文档的创建时间相差一分钟。
- en: 'The next step is the core of the TTL feature: the creation of the TTL index.
    It is similar to the creation of any other index using the `createIndex` method,
    except that it also accepts a second parameter that is a JSON object. These two
    parameters are as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是TTL功能的核心：创建TTL索引。它类似于使用`createIndex`方法创建任何其他索引，只是它还接受一个JSON对象作为第二个参数。这两个参数如下：
- en: The first parameter is `{createDate:1}`; this will tell mongo to create an index
    on the `createDate` field, and the order of the index is ascending as the value
    is `1` (`-1` would have been descending).
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个参数是`{createDate:1}`；这将告诉mongo在`createDate`字段上创建一个索引，索引的顺序是升序的，因为值是`1`（`-1`将是降序的）。
- en: The second parameter, `{expireAfterSeconds:300}`, is what makes this index a
    TTL index, and it tells Mongo to automatically expire the documents after 300
    seconds (five minutes).
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个参数`{expireAfterSeconds:300}`是使该索引成为TTL索引的关键，它告诉Mongo在300秒（五分钟）后自动使文档过期。
- en: Okay, but five minutes since when? Is it the time they were inserted in the
    collection or some other timestamp? In this case, it considers the `createTime`
    field as the base because this was the field that we created the index on.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，但是从什么时候开始的五分钟？它是它们被插入集合的时间还是其他时间戳？在这种情况下，它认为`createTime`字段是基础，因为这是我们创建索引的字段。
- en: 'This now raises a question: if a field is being used as a base for the computation
    of time, there has to be some restriction on its type. It just doesn''t make sense
    to create a TTL index, as we created previously, on a `char` field holding, say,
    the name of a person.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在引发一个问题：如果一个字段被用作时间计算的基础，那么它的类型必须受到一定的限制。在一个`char`字段上创建TTL索引就没有意义，比如说，保存一个人名字的字段。
- en: Yes; as we guessed, the type of the field can be of a BSON type date or an array
    of dates. What will happen in the case where an array has multiple dates? What
    will be considered in that case?
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 是的；正如我们猜测的那样，字段的类型可以是BSON类型的日期或日期数组。在数组中有多个日期的情况下会发生什么？在这种情况下会考虑什么？
- en: It turns out that Mongo uses a minimum of dates available in the array. Try
    this scenario out as an exercise.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是Mongo使用数组中可用的日期的最小值。尝试这种情况作为练习。
- en: Put two dates separated by about five minutes from each other in a document
    against the field name, `updateField`, and then create a TTL index on this field
    to expire the document after 10 minutes (600 seconds). Query the collection and
    see when the document gets deleted from the collection. It should get deleted
    after roughly 10 minutes have elapsed after the minimum time value present in
    the `updateField` array.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个文档中，对`updateField`字段放入两个相隔大约五分钟的日期，然后在这个字段上创建一个TTL索引，使文档在10分钟（600秒）后过期。查询集合，看看文档何时从集合中删除。它应该在`updateField`数组中的最小时间值之后大约10分钟后被删除。
- en: 'Apart from the constraint for the type of field, there are a few more constraints:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 除了字段类型的约束外，还有一些其他约束：
- en: If a field already has an index on it, you cannot create a TTL index. As the
    `_id` field of the collection already has an index by default, it effectively
    means that you cannot create a TTL index on the `_id` field.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个字段已经有了索引，你就不能创建TTL索引。因为集合的`_id`字段已经默认有了索引，这实际上意味着你不能在`_id`字段上创建TTL索引。
- en: A TTL index cannot be a compound index involving multiple fields.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TTL索引不能是涉及多个字段的复合索引。
- en: If a field doesn't exist, it will never expire. (That's pretty logical, I guess.)
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果字段不存在，它将永远不会过期。（我想这很合乎逻辑。）
- en: It cannot be created on capped collections. In case you are not aware of capped
    collections, they are special collections in Mongo with a size limit on them with
    a FIFO insertion order and delete old documents to make place for new documents,
    if needed.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不能在封闭集合上创建。如果你不知道封闭集合，它们是Mongo中的特殊集合，它们有一个大小限制，按照FIFO插入顺序删除旧文档，以便为新文档腾出空间。
- en: Note
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: TTL indexes are supported only on the Mongo version 2.2 and above. Note that
    the document will not be deleted at exactly the given time in the field. The cycle
    will be of a granularity of one minute, which will delete all the documents eligible
    for deletion since the last time the cycle was run.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: TTL索引仅支持Mongo版本2.2及以上。请注意，文档不会在字段中给定的确切时间被删除。周期将以一分钟的粒度进行，这将删除自上次运行周期以来符合删除条件的所有文档。
- en: See also
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: A use case might not demand deleting all the documents after a fixed interval
    has elapsed. What if we want to customize the point until a document stays in
    the collection? This too can be achieved, which is what will be demonstrated in
    the next recipe, *Expiring documents at a given time using the TTL index*.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 使用情况可能不要求在固定时间间隔后删除所有文档。如果我们想要自定义文档在集合中停留的时间，也可以实现，这将在下一个示例“使用TTL索引在特定时间到期的文档”中进行演示。
- en: Expiring documents at a given time using the TTL index
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TTL索引在特定时间到期的文档
- en: In the previous recipe, *Expiring documents after a fixed interval using the
    TTL index*, we have seen how documents can expire after a fixed time period. However,
    there can be some cases where we might want to have documents expiring at different
    times. This is not what we saw in the previous recipe. In this recipe, we will
    see how we can specify the time that the document can expire and it might be different
    for different documents.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例“使用TTL索引在固定时间间隔后到期的文档”中，我们已经看到文档在固定时间段后到期的情况。但是，可能存在一些情况，我们希望文档在不同时间到期。这与上一个示例中所看到的情况不同。在本示例中，我们将看到如何指定文档可以到期的时间，对于不同的文档可能是不同的。
- en: Getting ready
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: For this recipe, we will create a collection called `ttlTest2`. We will require
    a server to be up and running. Refer to the *Installing single node MongoDB* recipe
    from [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"), *Installing
    and Starting the Server* for instructions on how to start the server. Start the
    shell with the `TTLData.js` script loaded. This script is available on the Packt
    website for download. To know how to start the shell with a script preloaded,
    refer to the *Connecting to a single node in the Mongo shell with JavaScript*
    recipe in [Chapter 1](ch01.html "Chapter 1. Installing and Starting the Server"),
    *Installing and Starting the Server*.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本示例，我们将创建一个名为“ttlTest2”的集合。我们需要一个正在运行的服务器。有关如何启动服务器的说明，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*安装单节点MongoDB*示例，*安装和启动服务器*。使用加载了“TTLData.js”脚本的shell。此脚本可在Packt网站上下载。要了解如何使用预加载脚本启动shell，请参阅[第1章](ch01.html
    "第1章。安装和启动服务器")中的*使用JavaScript连接Mongo shell中的单节点*示例，*安装和启动服务器*。
- en: How to do it…
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Load the required data in the collection using the `addTTLTestData2` method.
    Execute the following on the mongo shell:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用“addTTLTestData2”方法在集合中加载所需的数据。在mongo shell上执行以下操作：
- en: '[PRE52]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now, create the TTL index on the `ttlTest2` collection as follows:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，按照以下步骤在“ttlTest2”集合上创建TTL索引：
- en: '[PRE53]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Execute the following `find` query to view the three documents in the collection:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下“find”查询以查看集合中的三个文档：
- en: '[PRE54]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Now, after approximately four, five, and seven minutes, see that the documents
    with the IDs two, one, and three get deleted, respectively.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，大约四、五和七分钟后，查看ID为2、1和3的文档是否分别被删除。
- en: How it works…
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: Let's start by opening the `TTLData.js` file and see what is going on inside
    it. Our method of interest for this recipe is `addTTLTestData2`. This method simply
    creates three documents in the `tllTest2` collection with `_id` of `1`, `2`, and
    `3` with their `exipryDate` fields set to `5`, `4`, and `7` minutes after the
    current time, respectively. Note that this field has a future date, unlike the
    date given in the previous recipe, where it was a creation date.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始打开“TTLData.js”文件，看看里面发生了什么。我们本次示例感兴趣的方法是“addTTLTestData2”。该方法简单地在“tllTest2”集合中创建了三个文档，其“_id”分别为“1”、“2”和“3”，其“exipryDate”字段分别设置为当前时间之后的“5”、“4”和“7”分钟。请注意，与上一个示例中给出的创建日期不同，该字段具有未来日期。
- en: 'Next, we create an index: `db.ttlTest2.createIndex({expiryDate :1}, {expireAfterSeconds:0})`.
    This is different from the way we created the index for the previous recipe, where
    the `expireAfterSeconds` field of the object was set to a non-zero value. This
    is how the value of the `expireAfterSeconds` attribute is interpreted. If the
    value is non-zero, then this is the time in seconds that has elapsed after a base
    time when the document will be deleted from the collection by Mongo. This base
    time is the value held in the field that the index is created on (`createTime`,
    as in the previous recipe). If this value is zero, then the date value that the
    index is created on (`expiryDate`, in this case) will be the time when the document
    will expire.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个索引：“db.ttlTest2.createIndex({expiryDate :1}, {expireAfterSeconds:0})”。这与我们在上一个示例中创建索引的方式不同，其中对象的“expireAfterSeconds”字段设置为非零值。这是“expireAfterSeconds”属性值的解释方式。如果值为非零，则这是文档将在Mongo中从集合中删除的基准时间之后经过的秒数。此基准时间是索引创建的字段中保存的值（如上一个示例中的“createTime”）。如果此值为零，则索引创建的日期值（在本例中为“expiryDate”）将是文档到期的时间。
- en: To conclude, TTL indexes work well if you want to delete the document upon expiry.
    There are quite a lot of cases where we might want to move the document to an
    archive collection, where the archived collection might be created based on, say,
    the year and month. In any such scenarios, a TTL index is not helpful and we might
    have to write an external job ourselves that does this work. Such a job could
    also read the collection for a range of documents, add them to the target collection,
    and delete them from the source collection. The folks at MongoDB have already
    planned to release a feature that addresses this issue.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，如果要在到期后删除文档，则TTL索引效果很好。有很多情况下，我们可能希望将文档移动到存档集合中，存档集合可能是基于年份和月份创建的。在任何这种情况下，TTL索引都没有帮助，我们可能需要自己编写一个外部作业来完成这项工作。这样的作业还可以读取一系列文档，将它们添加到目标集合中，并从源集合中删除它们。MongoDB的开发人员已经计划发布一个解决这个问题的功能。
- en: See also
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In this and the previous recipe, we looked at TTL indexes and how to use them.
    However, what if, after creating a TTL index, we want to modify the TTL value?
    This is possible using the `collMod` option. See more on this option in the administration
    section.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个和前一个教程中，我们看了看TTL索引以及如何使用它们。然而，如果在创建了TTL索引之后，我们想要修改TTL值怎么办？这是可以通过使用`collMod`选项来实现的。在管理部分可以了解更多关于这个选项的信息。
