- en: 7\. Data Aggregation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7. 数据聚合
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter introduces you to the concept of aggregation and its implementation
    in MongoDB. You will learn how to identify the parameters and structure of the
    aggregate command, combine and manipulate data using the primary aggregation stages,
    work with large datasets using advanced aggregation stages, and optimize and configure
    your aggregation to get the best performance out of your queries.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向您介绍了聚合的概念及其在MongoDB中的实现。您将学习如何识别聚合命令的参数和结构，使用主要聚合阶段组合和操作数据，使用高级聚合阶段处理大型数据集，并优化和配置聚合以获得查询的最佳性能。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapters, we learned the fundamentals of interacting with MongoDB.
    With these basic operations (`insert`, `update`, and `delete`), we can now begin
    exploring and manipulating our data as we would with any other database. We also
    observed how, by fully leveraging the `find` command options, we can use operators
    to answer more specific questions about our data. We can also sort, limit, skip,
    and project on our query to create useful result sets.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们学习了与MongoDB交互的基础知识。通过这些基本操作（`insert`，`update`和`delete`），我们现在可以开始探索和操作我们的数据，就像操作任何其他数据库一样。我们还观察到，通过充分利用`find`命令选项，我们可以使用操作符来回答关于我们数据的更具体的问题。我们还可以在查询中进行排序、限制、跳过和投影，以创建有用的结果集。
- en: In more straightforward situations, these result sets may be enough to answer
    your desired business question or satisfy a use case. However, more complex problems
    require more complex queries to answer. Solving such problems with just the `find`
    command would be highly challenging and would likely require multiple queries
    or some processing on the client side to organize or link the data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在更简单的情况下，这些结果集可能足以回答您所需的业务问题或满足用例。然而，更复杂的问题需要更复杂的查询来解决。仅使用`find`命令解决这些问题将是非常具有挑战性的，并且可能需要多个查询或在客户端进行一些处理来组织或链接数据。
- en: The basic limitation is where you have data contained in two separate collections.
    To find the correct data, you would have to run two queries instead of one, joining
    the data on the client or application level. This may not seem like a big problem,
    but as your application or dataset increases in scale, performance and complexity
    also grow. Wherever possible, it is ideal for the server to do all the heavy lifting,
    returning only the data we are looking for in a single query. This is where the
    **aggregation pipeline** comes in.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 基本限制是当您的数据包含在两个单独的集合中。要找到正确的数据，您将不得不运行两个查询，而不是一个，将数据连接在客户端或应用程序级别。这可能看起来不是一个大问题，但随着应用程序或数据集的规模增加，性能和复杂性也会增加。在可能的情况下，最好让服务器来处理所有繁重的工作，只返回我们在单个查询中寻找的数据。这就是**聚合管道**的作用。
- en: The `find` command. Beyond that, the pipeline structure of aggregation allows
    developers and database analysts to easily, iteratively, and quickly build queries
    on ever-changing and growing datasets. If you want to accomplish anything significant
    at scale in MongoDB, you'll need to write complex, multi-stage aggregation pipelines.
    In this chapter, we will learn exactly how to do that.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`find`命令。除此之外，聚合的管道结构允许开发人员和数据库分析师轻松、迭代地快速构建查询，处理不断变化和增长的数据集。如果您想在MongoDB中以规模完成任何重要的工作，您将需要编写复杂的多阶段聚合管道。在本章中，我们将学习如何做到这一点。'
- en: Note
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For the duration of this chapter, the exercises and activities included are
    iterations on a single scenario. The data and examples are based on the MongoDB
    Atlas sample database called `sample_mflix`.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的整个过程中，包括的练习和活动都是针对一个场景的迭代。数据和示例都基于名为`sample_mflix`的MongoDB Atlas示例数据库。
- en: Consider a scenario in which a cinema company is running its annual classic
    movie marathon and is trying to decide what their lineup should be. They need
    a variety of popular movies meeting specific criteria to satisfy their customer
    base. The company has asked you to research and determine the films they should
    show. In this chapter, we will use aggregations to retrieve data given a complex
    set of constraints, and then transform and manipulate data to create new results
    and answer business questions across our entire dataset with a single query. This
    will help the cinema company decide what movies they should be showing to satisfy
    their customers.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个情景，一个电影公司正在举办年度经典电影马拉松，并试图决定他们应该播放什么电影。他们需要各种符合特定标准的热门电影来满足他们的客户群。公司已经要求你进行研究，确定他们应该展示哪些电影。在本章中，我们将使用聚合来检索给定一组复杂约束条件的数据，然后转换和操作数据，以创建新的结果，并用单个查询回答整个数据集的业务问题。这将帮助电影公司决定他们应该展示哪些电影来满足他们的客户。
- en: It's worth noting that the aggregation pipeline is robust enough that there
    are many ways to accomplish the same task. The exercises and activities covered
    in this chapter are just one solution to the scenarios posed and can be solved
    using different patterns. The best way to master the aggregation pipeline is to
    consider multiple methods to solve the same problem.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，聚合管道足够强大，有许多方法可以完成相同的任务。本章涵盖的练习和活动只是解决所提出情景的一个解决方案，并且可以使用不同的模式来解决。掌握聚合管道的最佳方法是考虑多种方法来解决同一个问题。
- en: aggregate Is the New find
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合是新的查找
- en: The `aggregate` command in MongoDB is similar to the `find` command. You can
    provide the criteria for your query in the form of JSON documents, and it outputs
    a `cursor` containing the search result. Sounds simple, right? That's because
    it is. Although aggregations can become very large and complex, at their core,
    they are relatively simple.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB中的`aggregate`命令类似于`find`命令。您可以以JSON文档的形式提供查询的条件，并输出包含搜索结果的`cursor`。听起来很简单，对吧？那是因为它确实如此。尽管聚合可能变得非常庞大和复杂，但在其核心，它们是相对简单的。
- en: The key element in aggregation is called the pipeline. We will cover it in detail
    shortly, but at a high level, a pipeline is a series of instructions, where the
    input to each instruction is the output of the previous one. Simply put, aggregation
    is a method for taking a collection and, in a procedural way, filtering, transforming,
    and joining data from other collections to create new, meaningful datasets.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合中的关键元素称为管道。我们将很快详细介绍它，但在高层次上，管道是一系列指令，其中每个指令的输入是前一个指令的输出。简而言之，聚合是一种以程序方式从集合中获取数据，并进行过滤、转换和连接其他集合的方法，以创建新的有意义的数据集。
- en: Aggregate Syntax
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合语法
- en: 'The `aggregate` command operates on a collection like the other **Create, Read,
    Update, Delete** (**CRUD**) commands, like so:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`aggregate`命令与其他**创建、读取、更新、删除**（CRUD）命令一样，操作在集合上，如下所示：'
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There are two parameters used for aggregation. The `pipeline` parameter contains
    all the logic to find, sort, project, limit, transform, and aggregate our data.
    The `pipeline` parameter itself is passed in as an array of JSON documents. You
    can think of this as a series of instructions to be sent to the database, and
    then the resulting data after the final stage is stored in a `cursor` to be returned
    to you. Each stage in the pipeline is completed independently, one after another,
    until none are remaining. The input to the first stage is the collection (`movies`
    in the preceding example), and the input into each subsequent stage is the output
    from the previous stage.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合使用了两个参数。`pipeline`参数包含了查找、排序、投影、限制、转换和聚合数据的所有逻辑。`pipeline`参数本身作为JSON文档数组传递。您可以将其视为要发送到数据库的一系列指令，然后在最终阶段之后产生的数据存储在`cursor`中返回给您。管道中的每个阶段都是独立完成的，依次进行，直到没有剩余的阶段。第一个阶段的输入是集合（在上面的示例中是`movies`），每个后续阶段的输入是前一个阶段的输出。
- en: The second parameter is the `options` parameter. This is optional and allows
    you to specify the details of the configuration, such as how the aggregation should
    execute or some flags that are required during debugging and building your pipelines.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数是`options`参数。这是可选的，允许您指定配置的细节，比如聚合应该如何执行或者在调试和构建管道过程中需要的一些标志。
- en: 'The parameters in an `aggregate` command are fewer than those in the `find`
    command. We will cover `options` as the final topic of this chapter, so for now,
    we can simplify our command by excluding `options` completely, as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`aggregate`命令中的参数比`find`命令中的参数少。我们将在本章的最后一个主题中介绍`options`，所以现在我们可以通过完全排除`options`来简化我们的命令，如下所示：'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding example, rather than writing the pipeline directly into the
    command, we are saving the pipeline as a variable first. Aggregation pipelines
    can become very large and difficult to parse during development. It can sometimes
    be helpful to separate the pipeline (or even large sections of the pipeline) into
    separate variables for code clarity. Although recommended, this pattern is completely
    optional, and is similar to the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，我们首先将管道保存为变量，而不是直接将管道写入命令中。聚合管道可能会变得非常庞大，在开发过程中难以解析。将管道（甚至管道的大部分）分开为单独的变量以提高代码清晰度有时可能会有所帮助。虽然建议这样做，但这种模式完全是可选的，类似于以下内容：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It is recommended that you follow along with these examples in a code or text
    editor, saving your scripts and then copying and pasting them into the MongoDB
    shell. For example, say we create a file called `aggregation.js` with the following
    content:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 建议您在代码或文本编辑器中跟随这些示例，保存您的脚本，然后将其复制粘贴到MongoDB shell中。例如，假设我们创建了一个名为`aggregation.js`的文件，内容如下：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, copying this code directly into the MongoDB shell returns the following
    output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将此代码直接复制到MongoDB shell中，将返回以下输出：
- en: '![Figure 7.1: Results of the aggreagation (output truncated for brevity)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.1：聚合结果（为简洁起见输出被截断）'
- en: '](img/B15507_07_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_01.jpg)'
- en: 'Figure 7.1: Results of the aggreagation (output truncated for brevity)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：聚合结果（为简洁起见输出被截断）
- en: We can see in this output that once the `MyAggregation_A.js` function is defined,
    we only need to call that function again to see the results of our aggregation
    (in this case, a list of movies). You can call this function again and again without
    having to write the entire pipeline every time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在定义了`MyAggregation_A.js`函数之后，我们只需要再次调用该函数即可查看我们聚合的结果（在本例中是电影列表）。您可以一遍又一遍地调用这个函数，而无需每次都写整个管道。
- en: By structuring your aggregations this way, you will not lose any of them. It
    also has the added benefit of letting you load all your aggregations into the
    shell interactively as functions. However, you can also copy and paste the entire
    function into the MongoDB shell if you prefer or simply enter it interactively.
    In this chapter, we will use a mix of both methods.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以这种方式构建聚合，您将不会丢失任何聚合。它还有一个额外的好处，可以让您将所有聚合作为函数交互地加载到shell中。但是，如果您愿意，也可以将整个函数复制粘贴到MongoDB
    shell中，或者直接交互输入。在本章中，我们将两种方法混合使用。
- en: The Aggregation Pipeline
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合管道
- en: As mentioned earlier, the key element in aggregation is the pipeline, which
    is a series of instructions to perform on the initial collection. You can think
    of the data as water flowing through this pipeline, being transformed and filtered
    at each stage until it is finally poured out the end of the pipeline as a result.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，聚合中的关键元素是管道，它是对初始集合执行的一系列指令。您可以将数据视为流经此管道的水，在每个阶段进行转换和过滤，直到最终作为结果倒出管道的末端。
- en: 'In the following diagram, the orange blocks represent the aggregation pipeline.
    Each of these blocks in the pipeline is referred to as an aggregation stage:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，橙色块代表聚合管道。管道中的每个块都被称为聚合阶段：
- en: '![Figure 7.2: Aggregation pipeline'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.2：聚合管道'
- en: '](img/B15507_07_02.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_02.jpg)'
- en: 'Figure 7.2: Aggregation pipeline'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：聚合管道
- en: Something to note about aggregations is that, although the pipeline always begins
    with one collection, using certain stages, we can add collections further in the
    pipeline. We will cover joining collections later in this chapter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 关于聚合的一点需要注意的是，虽然管道始终以一个集合开始，但使用某些阶段，我们可以在管道中进一步添加集合。我们将在本章后面讨论加入集合。
- en: Large multi-stage pipelines may look intimidating, but if you understand the
    structure of the command and the individual operations that can be performed at
    a given stage, then you can easily break the pipeline down into smaller parts.
    In this first topic, we will explore the construction of an aggregation pipeline,
    compare a query implemented using `find` with one created using `aggregate`, and
    identify some basic operators.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 大型多阶段管道可能看起来令人生畏，但是如果您了解命令的结构以及可以在给定阶段执行的各个操作，那么您可以轻松地将管道分解为较小的部分。在本主题中，我们将探讨聚合管道的构建，比较使用`find`实现的查询与使用`aggregate`创建的查询，并识别一些基本操作符。
- en: Pipeline Syntax
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道语法
- en: 'The syntax of an aggregation pipeline is very simple, much like the `aggregate`
    command itself. The pipeline is an array, with each item in the array being an
    object:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合管道的语法非常简单，就像`aggregate`命令本身一样。管道是一个数组，数组中的每个项都是一个对象：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Each of the objects in the array represents a single stage in the overall pipeline,
    with the stages being executed in their array order (top to bottom). Each stage
    object takes the form of the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数组中的每个对象代表整个管道中的单个阶段，阶段按其数组顺序（从上到下）执行。每个阶段对象采用以下形式：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The stage represents the action we want to perform on the data (such as `limit`
    or `sort`) and the parameters can be either a single value or another object,
    depending on the stage.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 该阶段代表我们要对数据执行的操作（如`limit`或`sort`），参数可以是单个值或另一个对象，具体取决于阶段。
- en: 'The pipeline can be passed in two ways, either as a saved variable or directly
    as a command. The following example demonstrates how the pipeline can be passed
    as a variable:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 管道可以通过两种方式传递，可以作为保存的变量，也可以直接作为命令。以下示例演示了如何将管道作为变量传递：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, typing in the `db.theaters.aggregate(pipeline)` command in the MongoDB
    shell will provide the following output:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在MongoDB shell中键入`db.theaters.aggregate(pipeline)`命令将提供以下输出：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Passing it directly into the command, the output will look as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 直接将其传递到命令中，输出如下：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, you get the same output using either method.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，使用任一方法都会得到相同的输出。
- en: Creating Aggregations
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建聚合
- en: 'Let''s begin to explore the pipeline itself. The following code, when pasted
    in the MongoDB shell, will help us get a list of all the theaters in the state
    of Minnesota (MN):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始探索管道本身。将以下代码粘贴到MongoDB shell中，将帮助我们获取明尼苏达州（MN）所有剧院的列表：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will give us the following output:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This syntax should look very familiar by now. This is quite a simple command,
    so let''s look at the steps involved:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语法现在应该看起来非常熟悉。这是一个非常简单的命令，让我们看看涉及的步骤：
- en: Match the theater collection to get a list of all theaters in the state of `MN` (Minnesota).
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 匹配剧院收集以获取`MN`（明尼苏达州）州内所有剧院的列表。
- en: Project only the city in which the theater is located.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只投影剧院所在的城市。
- en: Sort the list by `city` name.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按`city`名称对列表进行排序。
- en: Limit the result to the first `three` theaters.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果限制为前`三`个剧院。
- en: 'Let''s rebuild this command as an aggregation. Don''t worry if this looks a
    little intimidating at first. We''ll walk through it step by step:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将此命令重建为聚合。如果一开始看起来有点令人生畏，不要担心。我们将逐步进行解释：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should see the following output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下输出：
- en: '![Figure 7.3: Results of the aggregation (output truncated for brevity)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.3：聚合结果（为简洁起见输出被截断）'
- en: '](img/B15507_07_03.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_03.jpg)'
- en: 'Figure 7.3: Results of the aggregation (output truncated for brevity)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3：聚合结果（为简洁起见输出被截断）
- en: If you run these two functions, you will get the same results. Remember, both
    `find` and `aggregate` commands return a cursor, but we're using `.forEach(printjson);`
    at the end to print them out to the console for ease of understanding.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行这两个函数，将会得到相同的结果。请记住，`find`和`aggregate`命令都返回一个游标，但我们在最后使用`.forEach(printjson);`将它们打印到控制台以便理解。
- en: 'If you observe the preceding example, you should be able to match up much of
    the same functionality from `find`. `project`, `sort`, and `limit` are all there
    as JSON documents just like in the `find` command. The only noticeable difference
    with these is that they are now documents in an array instead of functions. The
    `$match` stage at the very beginning of our pipeline is the equivalent of our
    filter document. So, let''s break it down step by step:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您观察前面的示例，应该能够从`find`中匹配出大部分相同的功能。`project`、`sort`和`limit`都以JSON文档的形式存在，就像在`find`命令中一样。这些的唯一显着差异是它们现在是数组中的文档，而不是函数。我们管道开头的`$match`阶段相当于我们的过滤文档。因此，让我们逐步分解它：
- en: 'First, search the theater''s collection, to locate documents that match the
    state `MN`:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，搜索剧院收集，以查找与州`MN`匹配的文档：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Pass this list of theaters to the second stage, which projects only the city
    the theaters exist in for the selected state:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此剧院列表传递到第二阶段，该阶段仅投影所选州内剧院所在的城市：
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This list of cities (and IDs) is then passed to a `sort` stage, which sorts
    the data alphabetically by city name:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后将这个城市（和ID）列表传递到`sort`阶段，按城市名称按字母顺序排序数据：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, the list is passed to a `limit` stage, outputting just the first three
    entries:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，列表传递到`limit`阶段，仅输出前三个条目：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Pretty simple, right? You can imagine how large and complex this pipeline could
    get in production, but one of its strengths is the ability to break down large
    pipelines into smaller subsections or individual stages. By looking at stages
    individually and sequentially, seemingly incomprehensible queries can become reasonably
    straightforward. It's also important to note that the order of the steps is just
    as important as the stages themselves, not just logically but also to increase
    performance. The `$match` and `$project` stages execute first because these will
    reduce the size of the result set at each stage. Although not applicable to every
    type of query, it is generally good practice to try and reduce the number of documents
    you are working with early on, disregarding any documents that will add excessive
    loads to the server.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 相当简单，对吧？您可以想象这个管道在生产中可能会变得多么庞大和复杂，但它的一个优点是能够将大型管道分解为较小的子部分或单个阶段。通过逐个和顺序地查看阶段，看似难以理解的查询可以变得相当简单。同样重要的是要注意，步骤的顺序与阶段本身一样重要，不仅在逻辑上，而且在性能上也是如此。`$match`和`$project`阶段首先执行，因为这些将在每个阶段减少结果集的大小。虽然不适用于每种类型的查询，但通常最好的做法是尽早尝试减少您正在处理的文档数量，忽略任何会给服务器增加过大负载的文档。
- en: Although the pipeline structure itself is simple, there are more complex stages
    and operators required to accomplish advanced aggregations, as well as optimize
    them. We'll look at many of these over the next few topics.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管管道结构本身很简单，但是需要更复杂的阶段和运算符来完成高级聚合，并对其进行优化。在接下来的几个主题中，我们将看到许多这样的内容。
- en: 'Exercise 7.01: Performing Simple Aggregations'
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.01：执行简单的聚合
- en: Before we begin this exercise, let's revisit the movie company from the scenario
    outlined in the *Introduction* in which a cinema company runs the classic movie
    marathon every year. In previous years, they have used a manual process for several
    subcategories before finally merging all the data by hand. As part of your initial
    research for this task, you are going to try to recreate one of their smaller
    manual processes as a MongoDB aggregation. This task will make you more familiar
    with the dataset and create a foundation for more complex queries.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这个练习之前，让我们回顾一下*介绍*中概述的电影公司，该公司每年都会举办经典电影马拉松。在以前的几年里，他们在最终手工合并所有数据之前，对几个子类别使用了手动流程。作为这项任务的初始研究的一部分，您将尝试将他们的一个较小的手动流程重新创建为MongoDB聚合。这个任务将使您更熟悉数据集，并为更复杂的查询打下基础。
- en: 'The process you have decided to recreate is as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 您决定重新创建的流程如下：
- en: '"*Return the top three movies in the romance genre sorted by IMDb rating, and
    return only movies released before 2001.*"'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: “*返回按IMDb评分排序的前三部爱情类型电影，并且只返回2001年之前发布的电影*”
- en: 'This can be done by executing the following steps:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过执行以下步骤来完成：
- en: 'Translate your query into sequential stages that you can map to your aggregation
    stages: limit to three movies, match only romance movies, sort by IMDb rating,
    and match only movies released before 2001.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的查询转换为顺序阶段，这样您就可以将其映射到聚合阶段：限制为三部电影，仅匹配爱情电影，按IMDb评分排序，并且仅匹配2001年之前发布的电影。
- en: 'Simplify your stages wherever possible by merging duplicate stages. In this
    case, you can merge the two match stages: limit to three movies, sort by IMDb
    rating, and match romance movies released before 2001.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽可能简化您的阶段，通过合并重复的阶段来简化。在这种情况下，您可以合并两个匹配阶段：限制为三部电影，按IMDb评分排序，并匹配2001年之前发布的爱情电影。
- en: It's important to remember that the order of the stages is essential and will
    produce incorrect results unless we rearrange them. To demonstrate this in action,
    we'll leave them in the incorrect order for now.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，阶段的顺序是至关重要的，除非我们重新排列它们，否则将产生错误的结果。为了演示这一点，我们将暂时保留它们的错误顺序。
- en: 'Take a quick peek into the structure of the movie documents to help write the stages:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 快速查看电影文档的结构，以帮助编写阶段：
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The document appears as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 文档如下所示：
- en: '![Figure 7.4: Looking at the document structure (output truncated for brevity)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.4：查看文档结构（输出被截短以保持简洁）'
- en: '](img/B15507_07_04.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_04.jpg)'
- en: 'Figure 7.4: Looking at the document structure (output truncated for brevity)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4：查看文档结构（输出被截短以保持简洁）
- en: For this particular use case, you will need the `imdb.rating`, `released`, and
    `genres` fields. Now that you know what you're searching for, you can begin writing
    up your pipeline.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个特定的用例，您将需要`imdb.rating`、`released`和`genres`字段。现在您知道您要搜索什么，可以开始编写您的管道了。
- en: 'Create a file called `Ch7_Activity1.js` and add the following basic stages:
    `limit` to limit the output to three movies, `sort` to sort them by their rating,
    and `match` to make sure you only find romantic movies released before 2001:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Ch7_Activity1.js`的文件，并添加以下基本阶段：`limit`以将输出限制为三部电影，`sort`以按其评分对其进行排序，并且`match`以确保您只找到2001年之前发布的爱情电影：
- en: '[PRE17]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `$match` operator functions very similarly to the filter parameter in the
    `find` command. You can simply pass in two conditions instead of one.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`$match`运算符的功能与`find`命令中的过滤参数非常相似。您可以简单地传入两个条件而不是一个。'
- en: 'For the `older than 2001` condition, use the `$lte` operator:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`早于2001年`的条件，使用`$lte`运算符：
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Because the `genres` field is an array (movies can belong to multiple genres),
    you must use the `$in` operator to find arrays containing your desired value.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 因为`genres`字段是一个数组（电影可以属于多种类型），您必须使用`$in`运算符来查找包含您所需值的数组。
- en: 'Run this pipeline now; you may notice that it returns no documents:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在运行这个管道；您可能会注意到它不返回任何文档：
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Is it possible that no documents satisfy this query? Of course, there may be
    no movies that satisfy all these requirements. However, as you may have already
    guessed, that is not the case here. As stated earlier, it''s the order of this
    pipeline that''s producing misleading results. Because your limit stage is the
    first stage in your pipeline, you are only ever looking at three documents, and
    the subsequent stages don''t have enough data to find a match. Therefore, it is
    always important to remember:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 是否可能没有文档满足这个查询？当然，可能没有电影满足所有这些要求。然而，正如你可能已经猜到的那样，在这里并非如此。正如前面所述，导致产生误导结果的是管道的顺序。因为你的限制阶段是管道中的第一个阶段，你只能查看三个文档，后续阶段没有足够的数据来找到匹配。因此，记住这一点总是很重要：
- en: '*When writing aggregation pipelines, the order of operations matters.*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*在编写聚合管道时，操作的顺序很重要。*'
- en: 'So, rearrange them to make sure that you only limit your documents at the end
    of your pipeline. Thanks to the array-like structure of the command, this is quite
    easy: just cut the limit stage and paste it at the end of your pipeline.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重新排列它们，确保你只在管道的末尾限制你的文档。由于命令的类似数组结构，这是相当容易的：只需剪切限制阶段，然后粘贴到管道的末尾。
- en: 'Arrange the stages so that the limit occurs last and does not produce incorrect results:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安排阶段，使限制发生在最后，不会产生不正确的结果：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Rerun this after the change. This time, the documents are returned:![Figure
    7.5: Output with valid document return (output truncated for brevity)'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在更改后重新运行这个查询。这次，文档被返回：![图7.5：有效文档返回的输出（为简洁起见，输出被截断）
- en: '](img/B15507_07_05.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_05.jpg)'
- en: 'Figure 7.5: Output with valid document return (output truncated for brevity)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：有效文档返回的输出（为简洁起见，输出被截断）
- en: 'This is one of the challenges of writing aggregation pipelines: it is an iterative
    process and can be cumbersome when dealing with large numbers of complex documents.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这是编写聚合管道的挑战之一：这是一个迭代过程，当处理大量复杂文档时可能会很麻烦。
- en: One way to relieve this pain point is to add stages during development that
    simplify the data, and then to remove these stages in your final query. In this
    case, you will add a stage to project only the data you're querying on. This will
    make it easier to tell whether you're capturing the right conditions. You must
    be careful when doing this that you do not affect the results of the query. We
    will discuss this in more detail later in this chapter. For now, you can simply
    add the projection stage right at the end to ensure that it will not interfere
    with your query.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解这一痛点的一种方法是在开发过程中添加简化数据的阶段，然后在最终查询中删除这些阶段。在这种情况下，你将添加一个阶段，只投影你正在查询的数据。这将使你更容易判断你是否捕捉到了正确的条件。在这样做时，你必须小心，不要影响查询的结果。我们将在本章后面更详细地讨论这个问题。现在，你可以简单地在最后添加投影阶段，以确保它不会干扰你的查询。
- en: 'Add a projection stage at the end of the pipeline to help debug your query:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在管道的末尾添加一个投影阶段来帮助调试你的查询：
- en: '[PRE21]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Run this query again and you will see a much shorter, more easily understood
    output, as shown in the following code block:![Figure 7.6: Output for the preceding
    snippet'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次运行这个查询，你会看到一个更短、更容易理解的输出，如下面的代码块所示：![图7.6：前面片段的输出
- en: '](img/B15507_07_06.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_06.jpg)'
- en: 'Figure 7.6: Output for the preceding snippet'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：前面片段的输出
- en: 'If you''re running the code from a file on your desktop, remember that you
    can simply copy and paste the entire code snippet (as follows) directly into your
    shell:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是从桌面上的文件运行代码，请记住，你可以直接将整个代码片段（如下所示）复制并粘贴到你的shell中：
- en: '[PRE22]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output should be as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该如下：
- en: '![Figure 7.7: List of the top classic romance movies released before 2001'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.7：2001年之前发布的经典浪漫电影排行榜'
- en: '](img/B15507_07_07.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_07.jpg)'
- en: 'Figure 7.7: List of the top classic romance movies released before 2001'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7：2001年之前发布的经典浪漫电影排行榜
- en: 'You can also see that each of the returned movies is in the romance category,
    was released before 2001, and has a high IMDb rating. So, in this exercise, you
    have successfully created your first aggregation pipeline. Now, let''s take the
    pipeline we just completed and try to improve it with a little effort. It is often
    helpful, when you believe you have completed a pipeline, to ask yourself:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以看到返回的每部电影都是浪漫类别的，2001年之前发布的，并且具有较高的IMDb评分。因此，在这个练习中，你成功地创建了你的第一个聚合管道。现在，让我们拿刚刚完成的管道，努力改进一下。当你相信你已经完成了一个管道时，询问自己通常是有帮助的：
- en: '*"Can I reduce the number of documents being passed down the pipeline?"*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: “我能减少通过管道传递的文档数量吗？”
- en: In the next exercise, we will try to answer this question.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将尝试回答这个问题。
- en: 'Exercise 7.02: Aggregation Structure'
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.02：聚合结构
- en: Think of the pipeline as a multi-tiered funnel. It starts broad at the top and
    becomes thinner as it approaches the bottom. As you pour documents into the top
    of the funnel, there are many documents, but as you move further down, this number
    keeps reducing at every stage, until only the documents that you want as output
    exit at the bottom. Usually, the easiest way to accomplish this is to do your
    matching (*filtering*) first.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 把管道想象成一个多层漏斗。它从顶部开始变宽，向底部变窄。当你把文档倒入漏斗顶部时，有很多文档，但随着你向下移动，这个数字在每个阶段都在减少，直到只有你想要的文档在底部输出。通常，实现这一点的最简单方法是先进行匹配（*过滤*）。
- en: 'In this pipeline, you will sort all the documents in the collection, and discard
    the ones that don''t match. You are currently sorting documents you don''t need.
    Swap those stages around:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个管道中，你将对集合中的所有文档进行排序，并丢弃不匹配的文档。你目前正在对不需要的文档进行排序。交换这些阶段：
- en: 'Swap the `match` and `sort` stages to improve the efficiency of your pipeline:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交换`match`和`sort`阶段以提高管道的效率：
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Another thing to consider is that, although you do have a list of movies matching
    the criteria, you want your result to be meaningful to your use case. In this
    case, you want your result to be meaningful and useful to the movie company looking
    at this data. It is likely that they will care most about the movie title and
    rating. They may also wish to see that the movie matches their requirements, so
    let's project those out at the end as well, discarding all other attributes.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的事情是，虽然你有一个符合条件的电影列表，但你希望你的结果对你的用例有意义。在这种情况下，你希望你的结果对查看这些数据的电影公司有意义和用处。他们可能最关心电影的标题和评分。他们可能还希望看到电影是否符合他们的要求，所以最后让我们将这些投影出来，丢弃所有其他属性。
- en: 'Add the movie `title` field to your projection stage. Your final aggregation
    should look like this:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在投影阶段添加电影 `title` 字段。你的最终聚合应该是这样的：
- en: '[PRE24]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Rerun your pipeline by copying and pasting the code from *step 2* into your
    mongo shell. You should see that the top two movies are `Pride and Prejudice`
    and `Forrest Gump`:![Figure 7.8: Output for preceding snippet'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过复制并粘贴 *步骤2* 中的代码重新运行你的管道。你应该看到排名前两的电影是 `傲慢与偏见` 和 `阿甘正传`：![图7.8：前面片段的输出
- en: '](img/B15507_07_08.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_08.jpg)'
- en: 'Figure 7.8: Output for preceding snippet'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：前面片段的输出
- en: If you see these results, you have just optimized your first aggregation pipeline.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看到这些结果，你刚刚优化了你的第一个聚合管道。
- en: As you can see, the aggregation pipeline is flexible, robust, and easy to manipulate,
    but you may be thinking that it seems a little heavy-duty for this use case and
    that possibly a simple `find` command might do the trick in most cases. Indeed,
    the aggregation pipeline is not needed for every simple query, but you're just
    getting started. In the next few sections, you'll see what the `aggregate` command
    provides that the `find` command does not.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，聚合管道是灵活、强大且易于操作的，但你可能会认为对于这种用例来说似乎有点过于复杂，可能大多数情况下一个简单的 `find` 命令就能解决问题。的确，聚合管道并不是每个简单查询都需要的，但你只是刚刚开始。在接下来的几节中，你将看到
    `aggregate` 命令提供了 `find` 命令所不具备的功能。
- en: Manipulating Data
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据操作
- en: 'Most of our activities and examples can be reduced to the following: there
    is a document or documents in a collection that should return some or all the
    documents in an easy-to-digest format. At their core, the `find` command and aggregation
    pipeline are just about identifying and fetching the correct document. However,
    the capability of the aggregation pipeline is much more robust and broader than
    that of the `find` command.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们大部分的活动和示例都可以归结为以下几点：在一个集合中有一个或多个文档应该以一种简单易懂的格式返回一些或所有文档。在本质上，`find` 命令和聚合管道只是关于识别和获取正确的文档。然而，聚合管道的能力要比
    `find` 命令更加强大和广泛。
- en: Using some of the more advanced stages and techniques in the pipeline allows
    us to transform our data, derive new data, and generate insights across a broader
    scope. This more extensive implementation of the aggregate command is more common
    than merely rewriting a find command as a pipeline. If you want to answer complex
    questions or extract the highest possible value from your data, you'll need to
    know how to achieve the aggregation part of your aggregation pipelines.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用管道中一些更高级的阶段和技术可以让我们转换我们的数据，衍生新的数据，并在更广泛的范围内生成见解。聚合命令的这种更广泛的实现比仅仅将一个 find 命令重写为一个管道更为常见。如果你想要回答复杂的问题或从你的数据中提取最大可能的价值，你需要知道如何实现聚合管道的聚合部分。
- en: After all, we haven't even begun to aggregate any data yet. In this topic, we'll
    explore the basics of how you can begin to transform and aggregate your data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 毕竟，我们甚至还没有开始聚合任何数据。在这个主题中，我们将探讨如何开始转换和聚合你的数据的基础知识。
- en: The Group Stage
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分组阶段
- en: As you may expect from the name, the `$group` stage allows you to group (*or
    aggregate*) documents based on a specific condition. Although there are many other
    stages and methods to accomplish various tasks with the `aggregate` command, the
    `$group` stage serves as the cornerstone of the most powerful queries. Previously,
    the most significant unit of data we could return was a single document. We can
    sort these documents to gain insight through a direct comparison of the documents.
    However, once we master the `$group` stage, we will be able to increase the scope
    of our queries to an entire collection by aggregating our documents into large
    logical units. Once we have the larger groups, we can apply our filters, sorts,
    limits, and projections just as we did on a per-document basis.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从名称中期望的那样，`$group` 阶段允许你根据特定条件对文档进行分组（*或聚合*）。虽然有许多其他阶段和方法可以使用 `aggregate`
    命令来完成各种任务，但是 `$group` 阶段是最强大查询的基石。以前，我们能够返回的最重要的数据单元是一个文档。我们可以对这些文档进行排序，通过直接比较文档来获得洞察力。然而，一旦我们掌握了
    `$group` 阶段，我们就能够通过将文档聚合成大的逻辑单元来增加我们查询的范围到整个集合。一旦我们有了更大的分组，我们可以像在每个文档基础上一样应用我们的过滤、排序、限制和投影。
- en: 'The most basic implementation of a `$group` stage accepts only an `_id` key,
    with the value being an expression. This expression defines the criteria by which
    the pipeline groups documents together. This value becomes the `_id` of the newly
    outputted document with one document generated for each unique `_id` that the
    `$group` stage creates. For example, the following code will group all movies
    by their rating, outputting a single record for each rating category:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`$group` 阶段的最基本实现只接受一个 `_id` 键，其值为一个表达式。这个表达式定义了管道将文档分组在一起的条件。这个值成为了新生成的文档的
    `_id`，每个唯一的 `_id` 会生成一个文档。例如，以下代码将按照电影的评分对其进行分组，为每个评分类别输出一个记录：'
- en: '[PRE25]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The resultant output will be as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 结果输出将如下所示：
- en: '![Figure 7.9: Resultant output for preceding snippet'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.9：前面片段的结果输出'
- en: '](img/B15507_07_09.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_09.jpg)'
- en: 'Figure 7.9: Resultant output for preceding snippet'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9：前面片段的结果输出
- en: The first thing you may notice in our `$group` stage is the `$` notation before
    the `rated` field. As stated previously, the value of our `_id` key was an *expression*.
    In aggregation terms, an expression can be a literal, an expression object, an
    operator, or a field path. In this case, we are passing in a field path, which
    tells the pipeline which field to access in the input documents. You may or may
    not have run into field paths before in MongoDB.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `$group` 阶段中，你可能会注意到的第一件事是 `rated` 字段之前的 `$` 符号。如前所述，我们的 `_id` 键的值是一个*表达式*。在聚合术语中，表达式可以是文字，表达式对象，运算符或字段路径。在这种情况下，我们传递了一个字段路径，它告诉管道应该访问输入文档中的哪个字段。在
    MongoDB 中，你可能已经遇到过字段路径，也可能没有。
- en: 'You may be wondering why we can''t just pass the field name as we would in
    a find command. This is because when aggregating, we need to tell the pipeline
    that we want to access the field of the document that it is currently aggregating.
    The `$group` stage will interpret `_id: "$rated"` as equivalent to `_id: "$$CURRENT.rated"`.
    This may seem complicated, but it indicates that for each document, it will fit
    into the group matching that same (current) document with the `"rated"` key. This
    will become clearer with practice in the next section.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '你可能会想为什么我们不能像在find命令中那样传递字段名。这是因为在聚合时，我们需要告诉管道我们想要访问当前正在聚合的文档的字段。`$group` 阶段将
    `_id: "$rated"` 解释为等同于 `_id: "$$CURRENT.rated"`。这可能看起来很复杂，但它表明对于每个文档，它将适合与具有相同（当前）文档的
    `"rated"` 键的组匹配。在下一节的实践中，这将变得更清晰。'
- en: So far, grouping by a single field has been useful to get a list of unique values.
    However, this hasn't told us much more about our data. We want to know more about
    these distinct groups; for example, how many titles fit into each of these groups?
    This is where our accumulator expressions will come in handy.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，按单个字段分组已经很有用，可以得到唯一值的列表。然而，这并没有告诉我们更多关于我们的数据。我们想要了解这些不同的组更多信息；例如，每个组中有多少个标题？这就是我们的累加表达式会派上用场的地方。
- en: Accumulator Expressions
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 累加器表达式
- en: 'The `$group` command can accept more than just one argument. It can also accept
    any number of additional arguments in the following format:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`$group` 命令可以接受不止一个参数。它还可以接受任意数量的其他参数，格式如下：'
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let''s break this down into its three components:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个分解成它的三个组件：
- en: '`field` will define the key of our newly computed field for each group.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`field` 将为每个组定义我们新计算的字段的键。'
- en: '`accumulator` must be a supported accumulator operator. These are a group of
    operators, like other operators you may have worked with already – such as `$lte`
    – except, as the name suggests, they will accumulate their value across multiple
    documents belonging to the same group.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`accumulator` 必须是一个受支持的累加器运算符。这些是一组运算符，就像你可能已经使用过的其他运算符一样 - 例如 `$lte` - 除了，正如名称所示，它们将在属于同一组的多个文档之间累积它们的值。'
- en: '`expression` in this context will be passed to the `accumulator` operator as
    the input of what field in each document it should be accumulating.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，`expression` 将作为输入传递给 `accumulator` 运算符，告诉它应该累积每个文档中的哪个字段。
- en: 'Building on the previous example, let''s identify the total number of movies
    in each group:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例基础上，让我们确定每个组中电影的总数：
- en: '[PRE27]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You can see from this that we can create a new field called `numTitles`, with
    the value of this field for each group being the sum of the documents. These newly
    created fields are often referred to as `1` with the accumulated result so far.
    Running this in the MongoDB shell will give us the following results:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 从中可以看出，我们可以创建一个名为 `numTitles` 的新字段，该字段的值是每个组的文档总和。这些新创建的字段通常被称为累积结果迄今为止的 `1`。在
    MongoDB shell 中运行这个命令将给我们以下结果：
- en: '![Figure 7.10: Output for preceding snippet'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.10：前面片段的输出'
- en: '](img/B15507_07_10.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_10.jpg)'
- en: 'Figure 7.10: Output for preceding snippet'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10：前面片段的输出
- en: 'Similarly, instead of accumulating `1` on each document, you can accumulate
    the value of a given field. For example, let''s say we want to find the total
    runtime of every single film in a rating. We group by the `rating` field and accumulate
    the runtime of each film:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以累积给定字段的值，而不仅仅是在每个文档上累积 `1`。例如，假设我们想要找到每部电影在一个评级中的总运行时间。我们按 `rating` 字段分组，并累积每部电影的运行时间：
- en: '[PRE28]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Remember, we must prefix the runtime field with the `$` symbol to tell MongoDB
    we are referring to the runtime value of each document we are accumulating. Our
    new result is as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们必须在运行时间字段前加上 `$` 符号，告诉 MongoDB 我们正在引用我们正在累积的每个文档的运行时间值。我们的新结果如下：
- en: '![Figure 7.11:Output for preceding snippet'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.11：前面片段的输出'
- en: '](img/B15507_07_11.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_11.jpg)'
- en: Figure 7.11:Output for preceding snippet
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11：前面片段的输出
- en: Although this is a simple example, you can see that with just a single aggregation
    stage and two parameters, we can begin to transform our data in exciting ways.
    Several accumulator operators can be combined and layered to generate much more
    complex and insightful information about groups. We will see some of these operators
    in the upcoming examples.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个简单的例子，但你可以看到，只需一个聚合阶段和两个参数，我们就可以开始以令人兴奋的方式转换我们的数据。几个累加器运算符可以组合和层叠，以生成关于组的更复杂和有见地的信息。我们将在接下来的示例中看到其中一些运算符。
- en: 'It''s important to note that we can use more than just accumulator operators
    as our expressions. We can also use several other useful operators to transform
    data after accumulating it. Let''s say we want to get the average runtime of the
    titles for each of our groups. We can change our `$sum` accumulator to `$avg`,
    which will return the average runtime across each group, so our pipeline becomes
    as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，我们不仅可以使用累加器运算符作为我们的表达式。我们还可以使用其他几个有用的运算符，在累积数据之后对数据进行转换。假设我们想要得到每个组的标题的平均运行时间。我们可以将我们的
    `$sum` 累加器更改为 `$avg`，这将返回每个组的平均运行时间，因此我们的管道变为如下：
- en: '[PRE29]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'And our output becomes:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们的输出变为：
- en: '![Figure 7.12:Average runtime values based on rating'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.12：基于评级的平均运行时间值'
- en: '](img/B15507_07_12.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_12.jpg)'
- en: Figure 7.12:Average runtime values based on rating
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.12：基于评分的平均运行时间值
- en: 'These average runtime values are not particularly useful in this case. Let''s
    add another stage to project the runtime, using the `$trunc` stage, to give us
    an integer value:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，这些平均运行时间值并不特别有用。让我们添加另一个阶段来投影运行时间，使用`$trunc`阶段，给我们一个整数值：
- en: '[PRE30]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This will give us a much more nicely formatted result, like this:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们提供一个更加格式良好的结果，就像这样：
- en: '[PRE31]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This section demonstrated how combining the group stage with operators, accumulators,
    and other stages can help manipulate our data to answer a much broader number
    of business questions. Now, let's start aggregating and put this new stage into
    practice.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 本节演示了如何将分组阶段与运算符、累加器和其他阶段结合起来，以帮助操纵我们的数据来回答更广泛的业务问题。现在，让我们开始聚合并将这个新阶段付诸实践。
- en: 'Exercise 7.03: Manipulating Data'
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.03：操纵数据
- en: In the previous scenario, you became accustomed to the shape of the data and
    recreated one of the client's manual processes as an aggregation pipeline. As
    part of the lead up to the classic movie marathon, the cinema company has decided
    to try and run one movie for each genre (one per week until the marathon) and
    they want to run the most popular genres last to build hype around the event.
    However, they have a problem. Their schedule for these weeks has already been
    dictated, meaning the classic movies will have to fit into the gaps in the schedule.
    So, to accomplish this, they must know the length of the longest movie in each
    genre, including adding time for trailers on each film.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的情景中，你已��习惯了数据的形状，并将客户的一个手动流程重新创建为一个聚合管道。作为经典电影马拉松的前奏，电影公司决定尝试为每种流派运行一部电影（直到马拉松结束每周一部），他们希望最受欢迎的流派最后播放，以此来烘托活动气氛。然而，他们有一个问题。这些周的时间表已经被规定，这意味着经典电影将不得不适应时间表中的空档。因此，为了实现这一目标，他们必须知道每种流派中最长电影的长度，包括每部电影的预告片时间。
- en: Note
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In this scenario, **popularity** is defined by the **IMDb rating**, and trailers
    run for 12 minutes before any film.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，**热门程度**是由**IMDb评分**定义的，而预告片在任何电影之前都会播放12分钟。
- en: 'The aim can be summarized as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 目标可以总结如下：
- en: '*"For only movies older than 2001, find the average and maximum popularity
    for each genre, sort the genres by popularity, and find the adjusted (with trailers)
    runtime of the longest movie in each genre."*'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*“仅针对2001年之前的电影，找到每种流派的平均热门程度和最大热门程度，按热门程度对流派进行排序，并找到每种流派中最长电影的调整（包括预告片）运行时间。”*'
- en: 'Translate the query into sequential stages so that you can map to your aggregation stages:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 将查询转换为顺序阶段，以便你可以映射到你的聚合阶段：
- en: Match movies that were released before 2001.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配2001年之前发布的电影。
- en: Find the average popularity of each genre.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到每种流派的平均热门程度。
- en: Sort the genres by popularity.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按热门程度对流派进行排序。
- en: Output the adjusted runtime of each movie.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出每部电影的调整后的运行时间。
- en: 'Since you''ve learned more about the group stage, elaborate on that step using
    your new knowledge:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你对分组阶段有了更多了解，利用你的新知识详细说明这一步骤：
- en: Match movies that were released before 2001.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配2001年之前发布的电影。
- en: Group all movies by their first genre and accumulate the average and maximum
    IMDb ratings.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按照它们的第一个流派对所有电影进行分组，并累积平均和最大的IMDb评分。
- en: Sort by the average popularity of each genre.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按每种流派的平均热门程度进行排序。
- en: Project the adjusted runtime as `total_runtime`.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将调整后的运行时间投影为`total_runtime`。
- en: The following steps will help you complete this exercise.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成这个练习。
- en: 'Create the outline for your aggregation first. Create a new file called `Ch7_Exercise3.js`:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先创建你的聚合大纲。创建一个名为`Ch7_Exercise3.js`的新文件：
- en: '[PRE32]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Fill in the steps one at a time, starting with `$match`:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一次填写一个步骤，从`$match`开始：
- en: '[PRE33]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This resembles *Exercise 7.01*, *Performing Simple Aggregations*, where you
    matched all the documents released before 2001.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于*练习7.01*，*执行简单的聚合*，在那里你匹配了2001年之前发布的所有文档。
- en: 'For the `$group` stage, first identify your new `id` for each output document:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`$group`阶段，首先为每个输出文档确定你的新`id`：
- en: '[PRE34]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `$arrayElemAt` takes an element from an array at the specified index (*in
    this case, 0*). For this scenario, assume that the first genre in the array is
    the primary genre of a film.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`$arrayElemAt`从数组中取出指定索引处的元素（*在这种情况下是0*）。对于这种情况，假设数组中的第一个流派是电影的主要流派。'
- en: 'Next, specify the new computed fields you require in the result. Remember to
    use the accumulator operators, including `$avg` (*average*) and `$max` (*maximum*).
    Remember that in `accumulator`, because you are referencing a variable, you must
    prefix the field with a `$` notation:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在结果中指定你需要的新计算字段。记住使用累加器运算符，包括`$avg`（*平均*）和`$max`（*最大*）。记住，在`accumulator`中，因为你在引用一个变量，你必须在字段前加上`$`符号：
- en: '[PRE35]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Fill in the `sort` field. Now that you have defined your computed fields, this
    is simple:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写`sort`字段。现在你已经定义了你的计算字段，这很简单：
- en: '[PRE36]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'To get the adjusted runtime, use the `$add` operator and add `12` (minutes).
    You add 12 minutes because the client (the cinema company) has informed you that
    this is the length of the trailers running before each movie. Once you have the
    adjusted runtime, you will no longer need `longest_runtime`:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获得调整后的运行时间，使用`$add`运算符并添加`12`（分钟）。你添加12分钟是因为客户（电影公司）已经告诉你这是每部电影播放前预告片的长度。一旦你有了调整后的运行时间，你将不再需要`longest_runtime`：
- en: '[PRE37]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Also add a `$`. Your final aggregation pipeline should look like this:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还要添加一个`$`。你最终的聚合管道应该是这样的：
- en: '[PRE38]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'If your results are correct, your top few documents should be as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的结果是正确的，你的前几个文档应该如下：
- en: '![Figure 7.13:Top few documents returned'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.13：返回的前几个文档'
- en: '](img/B15507_07_13.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_13.jpg)'
- en: Figure 7.13:Top few documents returned
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.13：返回的前几个文档
- en: The output shows that noir films, documentaries and short films are the most
    popular, and we can also see the average runtime for each category. In the next
    exercise, we will select a title from each category based on certain requirements.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，黑色电影、纪录片和短片是最受欢迎的，我们还可以看到每个类别的平均运行时间。在下一个练习中，我们将根据特定要求从每个类别中选择一个标题。
- en: 'Exercise 7.04: Selecting the Title from Each Movie Category'
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.04：从每个电影类别中选择标题
- en: 'You have now answered the question posed to you by your client. However, this
    result won''t aid them in picking a specific movie. They must execute a different
    query to get a list of movies in each genre and pick the best movie to show from
    the list. Additionally, you have also learned that the maximum time slot available
    is 230 minutes. You will alter this query to offer the cinema company a recommended
    title to choose in each category. The following steps will help you complete this
    exercise:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经回答了客户提出的问题。但是，这个结果对于他们来说并没有帮助选择特定的电影。他们必须执行不同的查询，以获取每个流派的电影列表，并从中选择要展示的最佳电影。此外，您还了解到最大的时间段可用为230分钟。您将修改此查询，以为电影公司提供每个类别的推荐标题。以下步骤将帮助您完成此练习：
- en: 'First, increase the first match to filter out films that aren''t applicable.
    Filter out films longer than 218 minutes (230 plus trailers). Also filter out
    films with a lower rating. To begin, you''ll get movies with a rating above 7.0:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，增加第一个匹配以过滤掉不适用的电影。过滤掉超过218分钟（230加上预告片）的电影。还要过滤掉评分较低的电影。首先，您将获得评分超过7.0的电影：
- en: '[PRE39]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To get the recommended title for each category, use the `$first` accumulator
    in our group stage to get the top document (movie) for each genre. To do this,
    you will have to first sort by rating in descending order, ensuring that the first
    document is also the highest rated. Add a new `$sort` stage after the initial
    `$match` stage:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了获得每个类别的推荐标题，使用我们组阶段中的`$first`累加器来获取每个流派的顶级文档（电影）。为此，您首先需要按评分降序排序，确保第一个文档也是评分最高的。在初始的$match阶段之后添加一个新的$sort阶段：
- en: '[PRE40]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, add the `$first` accumulator to your group stage, adding your new fields.
    Also add `recommended_rating` and `recommended_raw_runtime` fields for ease of
    use:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在组阶段中添加`$first`累加器，添加您的新字段。还添加`recommended_rating`和`recommended_raw_runtime`字段以便使用：
- en: '[PRE41]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Ensure that you add this new field to your final projection:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保将此新字段添加到最终的投影中：
- en: '[PRE42]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Your new final query should look like this:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 您的新最终查询应该如下所示：
- en: '[PRE43]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Execute this, and your first two result documents should look something like
    the following:![Figure 7.14:First two result documents
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行此操作，您的前两个结果文档应该看起来像下面这样：![图7.14：前两个结果文档
- en: '](img/B15507_07_14.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_14.jpg)'
- en: Figure 7.14:First two result documents
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.14：前两个结果文档
- en: You can see that with a few additions to your pipeline, you have extracted the
    movies with the highest ratings and longest runtimes to create extra value for
    your client.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，通过对管道进行一些添加，您已经提取出了评分最高和最长的电影，为客户创造了额外的价值。
- en: In this topic, we saw how we could query data and then sort, limit, and project
    our results. In this topic, we saw that by using more advanced aggregation stages,
    we can accomplish much more complicated tasks. Data is manipulated and transformed
    to create new, meaningful documents. These new stages empower the user to answer
    a much broader range of more difficult business questions, as well as gain valuable
    insight into datasets.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本主题中，我们看到了如何查询数据，然后对结果进行排序、限制和投影。我们还看到，通过使用更高级的聚合阶段，我们可以完成更复杂的任务。数据被操纵和转换以创建新的、有意义的文档。这些新的阶段使用户能够回答更广泛、更困难的业务问题，并获得有价值的数据洞察。
- en: Working with Large Datasets
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理大型数据集
- en: So far, we've been working with a relatively small number of documents. The
    `movies` collection has roughly 23,500 documents in it. This may be a considerable
    number for a human to work with, but for large production systems, you may be
    working on a scale of millions instead of thousands. So far, we have also been
    focusing strictly on a single collection at a time, but what if the scope of our
    aggregation grows to include multiple collections?
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在处理相对较少的文档。`movies`集合中大约有23,500个文档。这对于人类来说可能是一个相当大的数字，但对于大型生产系统来说，您可能会处理数百万而不是数千的规模。到目前为止，我们也一直严格专注于一次处理单个集合，但如果我们的聚合范围扩大到包括多个集合呢？
- en: In the first topic, we briefly discussed how you could use the projection stage
    while developing your pipelines to create more readable output as well as simplify
    your results for debugging. However, we didn't cover how you can improve performance
    when working on much, much larger datasets, both while developing and for your
    final production-ready queries. In this topic, we'll discuss a few of the aggregation
    stages that you need to master when working with large, multi-collection datasets.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个主题中，我们简要讨论了在开发管道时如何使用投影阶段来创建更易读的输出，并简化调试结果。但是，我们没有涵盖在处理更大规模的数据集时如何提高性能，无论是在开发过程中还是在最终的生产就绪查询中。在本主题中，我们将讨论在处理大型多集合数据集时需要掌握的一些聚合阶段。
- en: Sampling with $sample
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用$sample进行抽样
- en: 'The first step in learning how to deal with large datasets is understanding
    `$sample`. This stage is simple yet useful. The only parameter to `$sample` is
    the desired size of your sample. This stage randomly selects documents (up to
    your specified size) and passes them through to the next stage:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 学习如何处理大型数据集的第一步是了解`$sample`。这个阶段简单而有用。`$sample`的唯一参数是您的样本期望大小。这个阶段会随机选择文档（最多达到您指定的大小）并将它们传递到下一个阶段：
- en: '[PRE44]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'By doing this, you can significantly reduce the number of documents going through
    your pipeline. Primarily, this is useful for one of two reasons. The first reason
    is to speed up the execution time when running against enormous datasets—mainly
    while you are fine-tuning or building your aggregation. The second is for queries
    where the use case can tolerate documents missing from the result. For example,
    if you want to return any five films in a genre, you can use `$sample`:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，您可以显著减少通过管道的文档数量。主要是有两个原因。第一个原因是在处理庞大数据集时加快执行时间，尤其是在微调或构建聚合时。第二个原因是对于可以容忍结果中缺少文档的查询用例。例如，如果您想返回某个流派的任意五部电影，您可以使用`$sample`：
- en: '[PRE45]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The following result will be achieved after executing your new `findWithSample()` function:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 执行新的`findWithSample()`函数后，将获得以下结果：
- en: '[PRE46]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: You may be wondering why you wouldn't just use a `$limit` command to achieve
    the same result of reducing the number of documents at some stage in your pipeline.
    The primary reason is that `$limit` always respects the order of the documents
    and thus returns the same documents every time. However, it is important to note
    that in some cases, where you do not require the pseudo-random selection of `$sample`,
    it is wiser to use `$limit`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想为什么不直接使用`$limit`命令来实现在管道的某个阶段减少文档数量的相同结果。主要原因是`$limit`始终遵守文档的顺序，因此每次返回相同的文档。然而，重要的是要注意，在某些情况下，当你不需要`$sample`的伪随机选择时，最好使用`$limit`。
- en: 'Let''s see an example of `$sample` in action. Here is a query to search all
    movies for a specific keyword in the `plot` field, implemented both with and without
    `$sample`:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`$sample`的实际应用。这是一个查询，用于在`plot`字段中搜索特定关键字的所有电影，分别使用和不使用`$sample`实现：
- en: '[PRE47]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The preceding example is not the best way to measure performance, and there
    are much better ways to analyze the performance of your pipelines, such as `Explain`.
    However, since we''ll cover those in later parts of this book, this will serve
    as a simple example. If you run this little script, you will get the following
    result consistently:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子并不是衡量性能的最佳方式，有更好的方法来分析管道的性能，比如`Explain`。然而，由于我们将在本书的后面部分涵盖这些内容，这将作为一个简单的例子。如果你运行这个小脚本，你将始终得到以下结果：
- en: '[PRE48]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'A simple comparison of the two outputs of these two commands is as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个命令的输出的简单比较如下：
- en: '[PRE49]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: With sampling, the performance is significantly improved. However, this is because
    we are only looking at 100 documents. More likely, in this case, we want to sample
    our result after the `match` statement to make sure we don't exclude all our results
    in the first stage. In most scenarios, when working on large datasets where the
    execution time is significant, you may want to sample at the beginning as you
    construct your pipeline and remove the sample once your query is finalized.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 通过抽样，性能得到了显著改善。然而，这是因为我们只查看了100个文档。更可能的是，在这种情况下，我们希望在`match`语句之后对结果进行抽样，以确保我们不会在第一个阶段排除所有结果。在大多数情况下，在处理执行时间显著的大型数据集时，你可能希望在构建管道时从开始进行抽样，并在查询最终确定后移除抽样。
- en: Joining Collections with $lookup
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用$lookup连接集合
- en: Sampling may assist you when developing queries against extensive collections,
    but in production queries, you may sometimes need to write queries that are operating
    across multiple collections. In MongoDB, these collection joins are done using
    the `$lookup` aggregation step.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样可能在针对大型集合开发查询时对你有所帮助，但在生产查询中，你有时需要编写跨多个集合操作的查询。在MongoDB中，使用`$lookup`聚合步骤进行这些集合连接。
- en: 'These joins can be easily understood by the following aggregation:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这些连接可以通过以下聚合轻松理解：
- en: '[PRE50]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let''s dissect this before we try to run it. First, we are running a `$match`
    against the `users` collection to get only two users named `Ned Stark` and `Catelyn
    Stark`. Once we have these two records, we perform our lookup. The four parameters
    of `$lookup` are as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试运行之前，让我们先分析一下。首先，我们对`users`集合运行了`$match`，只获取了两个名为`Ned Stark`和`Catelyn Stark`的用户。一旦我们有了这两条记录，我们执行我们的查找。`$lookup`的四个参数如下：
- en: '`from`: The collection we are joining to our current aggregation. In this case,
    we are joining `comments` to `users`.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from`：我们要连接到当前聚合的集合。在这种情况下，我们将`comments`连接到`users`。'
- en: '`localField`: The field name that we are going to use to join our documents
    in the local collection (*the collection we are running the aggregation on*).
    In this case, the name of our user.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`localField`：我们将用来连接本地集合中文档的字段名称（*我们正在对其进行聚合的集合*）。在这种情况下，是我们用户的名称。'
- en: '`foreignField`: The field that links to `localField` in the `from` collection.
    These may have different names, but in this scenario, it is the same field: `name`.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`foreignField`：链接到`from`集合中的`localField`的字段。它们可能有不同的名称，但在这种情况下，它是相同的字段：`name`。'
- en: '`as`: This is how our new joined data will be labeled.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`as`：这是我们新连接的数据将被标记的方式。'
- en: In this example, the lookup takes the name of our user, searches the `comments`
    collection, and adds any comments with the same name into a new array field for
    the original user document. This new array is called **comments**. In this way,
    we can fetch an array of all related documents in another collection and embed
    them in our original documents for use in the rest of our aggregation.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，查找使用我们用户的名称，搜索`comments`集合，并将具有相同名称的任何评论添加到原始用户文档的新数组字段中。这个新数组被称为**comments**。通过这种方式，我们可以获取另一个集合中所有相关文档的数组，并将它们嵌入到我们原始文档中，以便在聚合的其余部分中使用。
- en: 'If we were to run the pipeline as it is, the beginning of the output would
    look something like this:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们按照现有的管道运行，输出的开头将看起来像这样：
- en: '![Figure 7.15:Output after running the pipeline (truncated for brevity)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.15：运行管道后的输出（为简洁起见截断）'
- en: '](img/B15507_07_15.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_15.jpg)'
- en: Figure 7.15:Output after running the pipeline (truncated for brevity)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.15：运行管道后的输出（为简洁起见截断）
- en: Because the output is very large, the preceding screenshot shows only the start
    of the `comments` array.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 由于输出非常大，前面的截图只显示了`comments`数组的开头部分。
- en: 'In this example, users have made many comments, so the embedded array becomes
    quite substantial and challenging to view. This issue presents an excellent place
    to introduce the `$unwind` operator, as these joins can often result in large
    arrays of related documents. `$unwind` is a relatively simple stage. It deconstructs
    an array field from an input document to output a new document for each element
    in the array. For example, if you unwind this document:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，用户发表了许多评论，因此嵌入的数组变得相当庞大且难以查看。这个问题是引入`$unwind`运算符的一个很好的地方，因为这些连接通常会导致大量相关文档的数组。`$unwind`是一个相对简单的阶段。它会从输入文档中解构一个数组字段，以输出数组中每个元素的新文档。例如，如果你展开这个文档：
- en: '[PRE51]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output will be the following documents:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是以下文档：
- en: '[PRE52]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We can add this new stage to our join and try running it:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以添加这个新的阶段到我们的连接中，然后尝试运行它：
- en: '[PRE53]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We will see output like this:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到如下输出：
- en: '![Figure 7.16:Output for preceding snippet (truncated for brevity)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.16：上述片段的输出（为简洁起见而截断）'
- en: '](img/B15507_07_16.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_16.jpg)'
- en: Figure 7.16:Output for preceding snippet (truncated for brevity)
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.16：上述片段的输出（为简洁起见而截断）
- en: We can see multiple documents per user with a single document for each comment
    instead of one embedded array. With this new format, we can add more stages to
    operate on our new set of documents. For example, we may wish to filter out any
    comments on a specific movie or sort our comments by their date. This combination
    of `$lookup` and `$unwind` is a powerful combination for answering complex questions
    across multiple collections in a single aggregation.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到每个用户有多个文档，每个评论都有一个单独的文档，而不是一个嵌入式数组。有了这种新格式，我们可以添加更多阶段来操作我们的新文档集。例如，我们可能希望过滤掉对特定电影的任何评论，或者按日期对评论进行排序。`$lookup`和`$unwind`的组合对于在单个聚合中跨多个集合回答复杂问题是一个强大的组合。
- en: Outputting Your Results with $out and $merge
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`$out`和`$merge`输出您的结果
- en: Imagine that we've been working on a large, multi-stage aggregation pipeline
    over the last week. We have been debugging, sampling, filtering, and testing our
    pipeline to solve a challenging and complex business problem on a tremendously
    large dataset. We're finally happy with our pipeline, and we want to execute it
    and then save the results for subsequent analysis and presentation.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在过去的一周里，我们一直在一个大型的多阶段聚合管道上工作。我们一直在调试、抽样、过滤和测试我们的管道，以解决一个具有挑战性和复杂业务问题的巨大数据集。最后，我们对我们的管道感到满意，我们想要执行它，然后保存结果以供后续分析和展示。
- en: We could run the query and export the results into a new format. However, this
    would mean re-importing the results if we wanted to run subsequent analysis on
    the result set.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行查询并将结果导出到新的格式。然而，这意味着如果我们想对结果集进行后续分析，就需要重新导入结果。
- en: We could save the output in an array and then re-insert it into MongoDB, but
    that would mean transferring all the data from the server to the client, and then
    back from the client to the server.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将输出保存在一个数组中，然后重新插入到MongoDB中，但这意味着需要将所有数据从服务器传输到客户端，然后再从客户端传输回服务器。
- en: 'Luckily for us, from MongoDB version 4.2 onward, we are provided with two aggregation
    stages that solve this problem for us: `$out` and `$merge`. Both stages allow
    us to take the output from our pipeline and write it into a collection for later
    use. Importantly, this whole process takes place on the server, meaning that all
    the data never needs to be transferred to the client across the network. It''s
    not hard to imagine that after creating a complicated aggregation query, you may
    want to run it once a week and create a snapshot of your result by writing that
    data into a collection.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，从MongoDB 4.2版本开始，我们提供了两个聚合阶段来解决这个问题：`$out`和`$merge`。这两个阶段都允许我们将管道的输出写入一个集合以供以后使用。重要的是，整个过程都在服务器上进行，这意味着所有数据都不需要通过网络传输到客户端。可以想象，在创建了一个复杂的聚合查询之后，您可能希望每周运行一次，并通过将数据写入集合来创建结果的快照。
- en: 'Let''s look at the syntax of both these stages in their most basic form, and
    then we can compare how they function:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这两个阶段的语法，以及它们的最基本形式，然后我们可以比较它们的功能：
- en: '[PRE54]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: As you can see, the syntax without any optional parameters is almost identical.
    In every other regard, however, the two commands diverge. `$out` is very simple;
    the only parameter to specify is the desired output collection. It will either
    create a new collection or completely replace an existing collection. `$out` also
    has several constraints not shared with `$merge`. For example, `$out` must output
    to the same database as the aggregation target.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，没有任何可选参数的语法几乎是相同的。然而，在其他方面，这两个命令是不同的。`$out`非常简单；唯一需要指定的参数是期望的输出集合。它要么创建一个新的集合，要么完全替换现有的集合。`$out`还有一些约束条件，而`$merge`没有。例如，`$out`必须输出到与聚合目标相同的数据库。
- en: When running on a MongoDB 4.2 server, `$merge` will probably be the better option.
    However, for the scope of this book, we will be using the MongoDB free tier, which
    runs MongoDB 4.0\. Therefore, we will focus more on the `$out` stage in these examples.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在MongoDB 4.2服务器上运行时，`$merge`可能是更好的选择。然而，在本书的范围内，我们将使用MongoDB的免费版，它运行的是MongoDB
    4.0。因此，在这些示例中，我们将更多地关注`$out`阶段。
- en: 'The syntax for `$out` is very simple. The only parameter is the collection
    to which we want to output our result. Here is an example of a pipeline with `$out`:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '`$out`的语法非常简单。唯一的参数是我们想要输出结果的集合。以下是一个带有`$out`的管道的示例：'
- en: '[PRE55]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'By running this pipeline, you will receive no output. This is because the output
    has been redirected to our desired collection:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行这个管道，您将不会收到任何输出。这是因为输出已经重定向到我们想要的集合中：
- en: '[PRE56]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We can see that a new collection was created with our result:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，一个新的集合被我们的结果创建了：
- en: '[PRE57]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'And if we run a find on our new collection, we can see that the results of
    our aggregation are now stored within it:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在新的集合上运行一个查找，我们可以看到我们的聚合结果现在存储在其中：
- en: '[PRE58]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: By placing our results into a collection, we can store, share, and update new
    complex aggregation results. We can even run further queries and aggregations
    against this new collection. `$out` is a simple but powerful aggregation stage.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将结果放入一个集合中，我们可以存储、共享和更新新的复杂聚合结果。我们甚至可以对这个新集合运行进一步的查询和聚合。`$out`是一个简单但强大的聚合阶段。
- en: 'Exercise 7.05: Listing the Most User-Commented Movies'
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.05：列出评论最多的电影
- en: The cinema company wishes to learn more about which movies generate the most
    comments from their users. However, given many comments in the database (and your
    disposition to use your newly learned skills), you have decided that while developing
    this pipeline, you will use only a sample of the comments. From this sample, you
    will figure out the most talked-about movies and join these documents with the
    document in the `movies` collection to get more information about the film. The
    company has also requested that the final deliverable of your work is a new collection
    with the output documents. This requirement should be easy to satisfy given that
    you now know the `$merge` stage.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 电影公司希望了解哪些电影从用户那里获得了最多的评论。然而，鉴于数据库中有很多评论（以及您倾向于使用您新学到的技能），您决定在开发此管道时，只使用评论的样本。从这个样本中，您将找出最受关注的电影，并将这些文档与`movies`集合中的文档结合起来，以获取有关电影的更多信息。公司还要求您的最终交付成果是一个包含输出文档的新集合。鉴于您现在已经了解了`$merge`阶段，这个要求应该很容易满足。
- en: Some additional information you have gathered is that they wish for the result
    to be as simple as possible and they wish to know the movie title and rating.
    Additionally, they would like to see the top five most commented-on movies.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 您收集到的一些额外信息是，他们希望结果尽可能简单，并且希望知道电影的标题和评分。此外，他们希望看到评论最多的前五部电影。
- en: 'In this exercise, you will help the cinema company to obtain a list of movies
    that generate the most comments from users. Perform the following steps to complete
    this exercise:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您将帮助电影公司获取用户评论最多的电影列表。执行以下步骤完成这个练习：
- en: 'First, outline the stages in your pipeline; they appear in the following order:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，概述管道中的阶段；它们按以下顺序出现：
- en: '`$sample` the `comments` collection (while building the pipeline).'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建管道时，对`comments`集合进行`$sample`。
- en: '`$group` the comments by the movie for which they are targeted.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '`$group`评论按其所针对的电影分组。'
- en: '`$sort` the result by the number of total comments.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '`$sort`结果按总评论数排序。'
- en: '`$limit` the result to the top five movies by comments.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '`$limit`结果为评论最多的前五部电影。'
- en: '`$lookup` the movie that matches each document.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`$lookup`与每个文档匹配的电影。'
- en: '`$unwind` the movie array to keep the result documents simple.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '`$unwind`电影数组，以保持结果文档简单。'
- en: '`$project` just the movie title and rating.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '`$project`只有电影标题和评分。'
- en: '`$merge` the result into a new collection.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`$merge`结果到一个新的集合中。'
- en: Although this may seem like many stages, each stage is relatively simple, and
    the process can be followed logically from beginning to end.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这可能看起来有很多阶段，但每个阶段都相对简单，整个过程可以从头到尾逻辑地跟随。
- en: 'Create a new file called `Ch7_Exercise5.js` and write up your pipeline skeleton:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Ch7_Exercise5.js`的新文件，并编写您的管道框架：
- en: '[PRE59]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Before deciding on sample size, you should get a sense of how large the `comments`
    collection is. Run `count` against the `comments` collection:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在决定样本大小之前，您应该了解`comments`集合有多大。对`comments`集合运行`count`：
- en: '[PRE60]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Sample roughly ten percent of the collection while you''re developing. Set
    the sample size to `5000` for this exercise:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开发过程中对集合进行大约百分之十的抽样。将本练习的样本大小设置为`5000`：
- en: '[PRE61]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Now that you have the easier steps out of the way, fill in the `$group` statement
    to group the comments by their associated film, accumulating the total number
    of comments for each film:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您已经完成了较容易的步骤，填写`$group`语句，将评论按其关联的电影分组，累积每部电影的评论总数：
- en: '[PRE62]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Next up, add `sort` so the movies with the highest `sumComments` value are
    first:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，添加`sort`，使具有最高`sumComments`值的电影排在第一位：
- en: '[PRE63]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'When building pipelines, it''s important to periodically run them partially
    completed to make sure you see the results you''re expecting. Since you''re about
    halfway through the stages, quickly comment out the incomplete stages and run
    the aggregation to list your most-commented movies. Keep in mind that because
    you are sampling, the results will not be the same each time you run your pipeline.
    The following output is just an example:![Figure 7.17: Example output'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在构建管道时，定期运行部分完成的管道非常重要，以确保您看到预期的结果。由于您正在抽样，每次运行管道时结果都不会相同。以下输出只是一个例子：![图7.17：示例输出
- en: '](img/B15507_07_17.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_17.jpg)'
- en: '[PRE64]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Rerunning this, you can now see a `movie` array with all the movie details
    embedded within it:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 重新运行此代码，现在您可以看到一个带有所有电影详细信息的`movie`数组嵌入其中：
- en: '![Figure 7.19: Output after re-running the pipeline'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.19：重新运行管道后的输出'
- en: '](img/B15507_07_19.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_19.jpg)'
- en: '[PRE65]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Your data is now complete, but you still need to output this result into a
    collection. Add the `$out` step at the end:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的数据现在已经完整，但您仍然需要将此结果输出到一个集合中。在最后添加`$out`步骤：
- en: '[PRE66]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Your final resulting code should look something like this:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 您最终的代码应该看起来像这样：
- en: '[PRE67]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Run this code. If all goes well, you will notice no output from your pipeline
    in the shell, but you should be able to check your newly created collection using
    `find()` and see your result. Remember, due to your sampling stage, the results
    will not be the same every time:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码。如果一切顺利，您将在shell中看不到管道的任何输出，但您应该能够使用`find()`检查您新创建的集合并查看您的结果。请记住，由于抽样阶段，结果每次都不会相同：
- en: '![Figure 7.20: Results from preceding snippet (output truncated for brevity)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.20：前面片段的结果（为简洁起见截断输出）'
- en: '](img/B15507_07_20.jpg)'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_20.jpg)'
- en: 'Figure 7.20: Results from preceding snippet (output truncated for brevity)'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.20：前面片段的结果（为简洁起见截断输出）
- en: With the new phases we have learned about in this topic, we now possess an excellent
    foundation for performing aggregations on more massive, more complex datasets.
    Moreover, importantly, we are now able to join data between multiple collections
    effectively. By doing this, we can increase the scope of our queries and thus
    satisfy a much broader range of use cases.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本主题学到的新阶段，我们现在拥有了在更大、更复杂的数据集上执行聚合的良好基础。而且，更重要的是，我们现在能够有效地在多个集合之间进行数据连接。通过这样做，我们可以扩大我们的查询范围，从而满足更广泛的用例。
- en: With the `out` stage, we can store the result of our aggregations. This allows
    users to explore the results quickly with normal CRUD operations and allows us
    to keep updating the results regularly and easily. The unwind stage has also given
    us the ability to take the joined documents from a lookup and separate them into
    individual documents that we can feed into further pipeline stages.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`out`阶段，我们可以存储聚合的结果。这使用户可以通过常规的CRUD操作快速探索结果，并且可以轻松地保持更新结果。unwind阶段还使我们能够将查找操作中的连接文档分开成单独的文档，以便将其馈送到后续的管道阶段中。
- en: With all these stages combined, we are now able to create extensive new aggregations
    that operate across large, multi-collection datasets.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合所有这些阶段，我们现在能够创建跨大型多集合数据集进行操作的广泛新聚合。
- en: Getting the Most from Your Aggregations
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从您的聚合中获得最大收益
- en: In the last three topics, we have learned about the structure of aggregation
    as well as the key stages required to build up complicated queries. We can search
    large multi-collection datasets with given criteria, manipulate that data to create
    new insights, and output our results into a new or existing collection.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的三个主题中，我们已经了解了聚合的结构以及构建复杂查询所需的关键阶段。我们可以使用给定的条件搜索大型多集合数据集，操纵数据以创建新的见解，并将结果输出到新的或现有集合中。
- en: These fundamentals will allow you to solve most of the problems you will encounter
    in an aggregation pipeline. However, there are several other stages and patterns
    for getting the most out of your aggregations. We won't cover them all in this
    book, but in this topic, we'll discuss a few of the odds and ends that will help
    you fine-tune your pipelines as well as some other odds and ends that we simply
    haven't covered so far. We'll be looking at aggregation options using **Explain**
    to analyze your aggregation.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基础将使您能够解决聚合管道中遇到的大多数问题。然而，还有一些其他阶段和模式可以让您从聚合中获得最大收益。我们不会在本书中涵盖所有这些内容，但在本主题中，我们将讨论一些可以帮助您微调管道的技巧，以及一些我们到目前为止还没有涵盖的其他技巧。我们将使用**Explain**来分析您的聚合选项。
- en: Tuning Your Pipelines
  id: totrans-349
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整您的管道
- en: In an earlier topic, we timed the execution of our pipeline by outputting the
    time before and after our aggregation. This is a valid technique, and you may
    often time your MongoDB queries on the client or application side. However, this
    only gives us a rough approximation of duration and only tells us the total time
    the response took to reach the client, not how long the server took to execute
    the pipeline. MongoDB provides us with a great way of learning exactly how it
    executed our requested query. This feature is known as **Explain** and is the
    usual way to examine and optimize our MongoDB commands.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期的主题中，我们通过输出聚合之前和之后的时间来计算我们的管道的执行时间。这是一种有效的技术，你可能经常在客户端或应用程序端计时你的MongoDB查询。然而，这只能给我们一个大致的持续时间，并且只告诉我们响应到达客户端所花费的总时间，而不是服务器执行管道所花费的时间。MongoDB为我们提供了一个很好的学习方式，可以准确地了解它是如何执行我们请求的查询的。这个功能被称为**Explain**，是检查和优化我们的MongoDB命令的常规方式。
- en: However, there is one catch. **Explain** does not yet support detailed execution
    plans for aggregations, meaning its use is limited when it comes to the optimization
    of pipelines. **Explain** and execution plans will be covered in more detail later
    in this book. Since we can't rely on **Explain** to analyze our pipelines, it
    becomes even more integral to carefully construct and plan our pipeline to improve
    the performance of our aggregations. Although there is no single correct method
    that will work in any situation, there are some heuristics that can generally
    be helpful. We'll walk through a few of these methods with examples. MongoDB does
    a lot of performance optimization under the hood, but these are still good patterns
    to follow.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一个问题。**Explain**目前不支持聚合的详细执行计划，这意味着在优化管道时其使用受到限制。**Explain**和执行计划将在本书的后面更详细地介绍。由于我们不能依赖**Explain**来分析我们的管道，因此更加重要的是仔细构建和规划我们的管道，以提高聚合的性能。虽然没有一种适用于任何情况的单一正确方法，但有一些启发式方法通常会有所帮助。我们将通过一些示例来介绍其中的一些方法。MongoDB在幕后进行了大量的性能优化，但这些仍然是要遵循的良好模式。
- en: Filter Early and Filter Often
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尽早过滤，经常过滤
- en: Each stage of the aggregation pipeline will perform some processing on the input.
    That means the more significant the input, the larger the processing. If you've
    designed your pipeline correctly, this processing is unavoidable for the documents
    you are trying to return. The best you can do is to make sure you're processing
    *only* the documents you want to return.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合管道的每个阶段都会对输入进行一些处理。这意味着输入越重要，处理就越大。如果您正确设计了管道，那么这种处理对于您要返回的文档是不可避免的。您所能做的就是确保您只处理*您想要返回的*文档。
- en: 'The easiest way to accomplish this is by adding or moving pipeline stages that
    filter out documents. We''ve already done this in our previous scenarios with
    `$match` and `$limit`. A common way to ensure this is to have the very first stage
    in your pipeline be a `$match`, which matches only documents you need later in
    the pipeline. Let''s understand this with the help of the following pipeline example,
    where the pipeline is not designed to execute as expected:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一点的最简单方法是添加或移动过滤文档的管道阶段。我们在之前的情景中已经用`$match`和`$limit`做过这个操作。确保这一点的常见方法是将管道中的第一个阶段设置为`$match`，这样可以只匹配后续管道中需要的文档。让我们通过以下管道示例来理解这一点，其中管道没有按预期执行设计：
- en: '[PRE68]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output will be as follows:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE69]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Once you have correctly ordered the pipeline, it will look like the following:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你正确地排序了管道，它将如下所示：
- en: '[PRE70]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This will result in the following output:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '![Figure 7.21: Output for preceding snippet (truncated for brevity)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.21：前面片段的输出（为简洁起见而截断）'
- en: '](img/B15507_07_21.jpg)'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_21.jpg)'
- en: 'Figure 7.21: Output for preceding snippet (truncated for brevity)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.21：前面片段的输出（为简洁起见而截断）
- en: Logically, this change means that the first thing we do is get a list of all
    our eligible documents before sorting them, and then we take the top five and
    project only those five documents.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 从逻辑上讲，这个改变意味着我们首先要做的是在对它们进行排序之前获取所有符合条件的文档列表，然后我们取前五个并且只投影这五个文档。
- en: Both pipelines output the same results, but the second is much more robust and
    easily understood. You may not always see a significant performance increase with
    this change, particularly on smaller datasets. However, this is an excellent practice
    to follow because it will assist you in creating logical, efficient, and straightforward
    pipelines that can be modified or scaled more easily.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个管道都输出相同的结果，但第二个更加健壮且易于理解。你可能不会总是看到这种改变带来显著的性能提升，特别是在较小的数据集上。然而，这是一个很好的实践，因为它将帮助你创建逻辑、高效和简单的管道，可以更容易地进行修改或扩展。
- en: Use Your Indexes
  id: totrans-366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用你的索引
- en: Indexes are another critical element in MongoDB query performance. This book
    covers indexes and their creation in further depth in *Chapter 9*, *Performance*.
    All you need to remember when creating your aggregations is that when utilizing
    stages such as `$sort` and `$match`, you want to make sure that you are operating
    on correctly indexed fields. The concepts around using indexes will then become
    more apparent.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 索引是MongoDB查询性能的另一个关键因素。本书在第9章“性能”中更深入地介绍了索引及其创建。在创建聚合时，你需要记住的是，在使用`$sort`和`$match`等阶段时，你要确保你正在操作的是正确索引的字段。使用索引的概念将会变得更加明显。
- en: Think about the Desired Output
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考虑期望的输出
- en: 'One of the most important ways to improve your pipelines is to plan and evaluate
    them to ensure that you''re getting the desired output that solves your business
    problem. Ask yourself the following questions if you''re having trouble creating
    a finely tuned pipeline:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 改进你的管道最重要的方法之一是计划和评估它们，以确保你得到了解决业务问题的期望输出。如果你在创建一个精心调整的管道时遇到困难，可以问自己以下问题：
- en: Am I outputting all the data to solve my problem?
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是否输出了所有数据来解决我的问题？
- en: Am I outputting only the data required to solve my problem?
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是否只输出了解决问题所需的数据？
- en: Am I able to merge or remove any intermediate steps?
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是否能够合并或删除任何中间步骤？
- en: If you have evaluated your pipeline, tuned it, and still find it to be over-complicated
    or inefficient, you may need to ask some questions about the data itself. Is the
    aggregation difficult because the wrong query is being designed, or even the wrong
    question being asked? Alternatively, perhaps it is a sign that the shape of the
    data needs to be re-evaluated.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经评估了你的管道，调整了它，但仍然觉得它过于复杂或低效，你可能需要对数据本身提出一些问题。聚合是否困难是因为设计了错误的查询，甚至是问了错误的问题？或者，也许这是数据形状需要重新评估的一个迹象。
- en: Aggregation Options
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合选项
- en: 'Altering the pipeline is where you may spend most of your time while working
    with aggregations, and for beginners, you will likely be able to accomplish most
    of your goals by just writing pipelines. As mentioned earlier in this chapter,
    several options can be passed into the `aggregate` command to configure its operation.
    We won''t delve too deeply into these options, but it is helpful to recognize
    them. The following is an example of aggregation with some of our options included:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 修改管道是你在处理聚合时可能会花费大部分时间的地方，对于初学者来说，你可能只需编写管道就能实现大部分目标。正如本章前面提到的，可以传递多个选项到`aggregate`命令中以配置其操作。我们不会深入探讨这些选项，但了解它们是有帮助的。以下是包含一些选项的聚合示例：
- en: '[PRE71]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'To specify these options, a second parameter is passed into the command after
    the pipeline array. In this case, we''ve called it `options`. Some of the options
    to be aware of include the following:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 要指定这些选项，需要在管道数组之后传递第二个参数给命令。在这种情况下，我们称之为`options`。一些需要注意的选项包括以下内容：
- en: '`maxTimeMS`: The amount of time an operation may be processed before MongoDB
    kills it. Essentially a timeout for your aggregation. The default for this is
    `0`, which means operations do not time out.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxTimeMS`：MongoDB在终止操作之前可以处理的时间量。本质上是聚合的超时时间。默认值为`0`，这意味着操作不会超时。'
- en: '`allowDiskUse`: Stages in the aggregation pipeline may only use up a maximum
    amount of memory, making it challenging to handle massive datasets. By setting
    this option to `true`, MongoDB can write temporary files to allow the handling
    of more data.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`allowDiskUse`：聚合管道中的阶段可能只使用最大数量的内存，这使得处理大型数据集变得具有挑战性。通过将此选项设置为`true`，MongoDB可以写临时文件以处理更多的数据。'
- en: '`bypassDocumentValidation`: This option is specifically for pipelines that
    will be writing out to collections using `$out` or `$merge`. If this option is
    set to `true`, document validation will not occur on documents being written to
    the collection from this pipeline.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bypassDocumentValidation`：这个选项专门用于将使用`$out`或`$merge`写入集合的管道。如果将此选项设置为`true`，则不会对从该管道写入集合的文档进行文档验证。'
- en: '`comment`: This option is just for debugging and allows a string to be specified
    that helps identify this aggregation when parsing database logs.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comment`：这个选项只是用于调试，允许指定一个字符串来帮助在解析数据库日志时识别这个聚合。'
- en: Let's perform an exercise now, to put the concepts we learnt about till now,
    into practice.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在让我们进行一个练习，将我们到目前为止学到的概念付诸实践。
- en: 'Exercise 7.06: Finding Award-Winning Documentary Movies'
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.06：查找获奖纪录片
- en: After seeing the results of the aggregation pipelines achieved in the previous
    exercises and the value they are bringing to the cinema company, a few of the
    company's internal engineers have tried to write up some new aggregations themselves.
    The cinema company has asked you to review these pipelines to assist in their
    internal engineers' learning process. You will use some of the preceding techniques
    and your understanding of aggregations from the last three topics to fix up a
    pipeline. The goal of this simple pipeline is to get a list of documentary movies
    with a high rating.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到前几个练习中实现的聚合管道的结果以及它们为电影公司带来的价值后，公司的一些内部工程师尝试自己编写了一些新的聚合。电影公司要求您审查这些管道，以协助他们内部工程师的学习过程。您将使用前面的一些技术和您对最后三个主题中聚合的理解来修复一个管道。这个简单管道的目标是获取一份评分很高的纪录片清单。
- en: 'For this scenario, you will also work under the assumption that there is a
    substantial amount of data in the collection. The pipeline given to you to be
    reviewed is as follows. The purpose of this exercise is to find a few award-winning
    documentary movies and then list the movies that have won the most awards:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种情况，您还将在假设集合中有大量数据的情况下进行工作。给您要审查的管道如下。此练习的目的是找到一些获奖纪录片，并列出获奖最多的电影：
- en: '[PRE72]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The result can be achieved through the following steps:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过以下步骤实现结果：
- en: 'First, merge the two `$match` statements and move `match` to the top of the pipeline:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，合并两个`$match`语句，并将`match`移到管道的顶部：
- en: '[PRE73]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '`sort` is no longer needed at the beginning, so you can move it to the second-to-last
    step:'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不再需要在开头使用`sort`，因此可以将其移动到倒数第二步：
- en: '[PRE74]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The two limits are no longer required. Delete the first one:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不再需要两个限制。删除第一个：
- en: '[PRE75]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Finally, move the projection to the very end, as it only needs to operate on
    the final three documents:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将投影移到最后三个文档：
- en: '[PRE76]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'That''s already looking much better. You''ve been told that the collection
    is vast, so also add some options to the aggregation:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这已经看起来好多了。您被告知集合非常庞大，因此还要为聚合添加一些选项：
- en: '[PRE77]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Run the full query:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行完整查询：
- en: '[PRE78]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'So, your result should be as follows:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您的结果应如下所示：
- en: '![Figure 7.22: List of award-winning documentaries (truncated for brevity)'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.22：获奖纪录片清单（为简洁起见截断）'
- en: '](img/B15507_07_22.jpg)'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_22.jpg)'
- en: 'Figure 7.22: List of award-winning documentaries (truncated for brevity)'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.22：获奖纪录片清单（为简洁起见截断）
- en: With this, you have retrieved the award-winning documentary list as per your
    cinema company's requirements. We have seen in this topic that to get the most
    value from your aggregations, you will be required to design, test, and continually
    re-evaluate your pipeline. The heuristics listed previously are just a small fraction
    of the patterns for designing useful aggregations, however, and researching other
    patterns and procedures is always recommended.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，您已根据您的电影公司的要求检索了获奖纪录片清单。我们在本主题中看到，为了从聚合中获得最大价值，您需要设计、测试和不断重新评估您的管道。然而，先前列出的启发式只是设计有用的聚合的一小部分模式，因此建议您进行其他模式和程序的研究。
- en: We also saw how we could pass in some options to the `aggregate` command to
    assist us in specific use cases or with massive datasets that may take longer
    to process.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了如何向`aggregate`命令传递一些选项，以帮助我们处理特定用例或处理可能需要更长时间的大型数据集。
- en: 'Activity 7.01: Putting Aggregations into Practice'
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动7.01：将聚合实践应用到实践中
- en: The cinema company from previous exercises has been very impressed with the
    insights you've managed to extract from the data using aggregation pipelines.
    However, the company is having trouble managing the different queries and combining
    the data into meaningful results. They have decided that they would like a single,
    unified aggregation that summarizes the essential information for their upcoming
    movie marathon campaign.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几个练习中，电影公司对您使用聚合管道从数据中提取的见解印象深刻。然而，公司在管理不同的查询和将数据组合成有意义的结果方面遇到了麻烦。他们决定他们想要一个单一的、统一的聚合，总结他们即将举办的电影马拉松活动的基本信息。
- en: 'You aim to design, test, and run an aggregation pipeline that will create this
    unified view. You should ensure that the final output of the aggregation answers
    the following business problems:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 您的目标是设计、测试和运行一个聚合管道，以创建这个统一视图。您应确保聚合的最终输出回答以下业务问题：
- en: For each genre, which movie has the most award nominations, given that they
    have won at least one of these nominations?
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每种流派，哪部电影获得了最多的奖项提名，假设它们至少赢得了其中一项提名？
- en: For each of these movies, what is their appended runtime, given that each movie
    has 12 minutes of trailers before it?
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于这些电影中的每一部电影，在每部电影之前都有12分钟的预告片，它们的附加运行时间是多少？
- en: An example of the sorts of things users are saying about this film.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于这部电影的用户评论的例子。
- en: Because this is a classic movie marathon, only movies released before 2001 are eligible.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为这是一场经典的电影马拉松，只有在2001年之前发布的电影才有资格。
- en: Across all genres, list all the genres that have the highest number of award
    wins.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有流派中，列出获奖次数最多的所有流派。
- en: You may complete this activity in whichever way you choose, but try to focus
    on creating a simple and efficient aggregation pipeline that can be tweaked or
    modified in the future. It is sometimes best to try and decide what an output
    document might look like, and then work backward from there.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以以任何方式完成此活动，但请尽量专注于创建一个简单而高效的聚合管道，以便将来进行调整或修改。有时最好尝试并决定输出文档可能是什么样子，然后从那里开始向后工作。
- en: Remember, you may also choose to use the `$sample` stage to speed up your query
    while you're testing, but you must remove these steps in the final solution.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在测试时，您也可以选择使用`$sample`阶段来加快查询速度，但在最终解决方案中必须删除这些步骤。
- en: To keep the desired output simple, limit the result to three documents for this scenario.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持所需的输出简单，将结果限制为此场景的三个文档。
- en: 'The following steps will help you to complete this task:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助您完成此任务：
- en: Filter out any documents that were not released before 2001.
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤掉在2001年之前未发布的任何文件。
- en: Filter out any documents that do not have at least one award win.
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 筛选掉没有至少一次获奖的文件。
- en: Sort the documents by award nominations.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按奖项提名对文件进行排序。
- en: Group the documents into a genre.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文档分组成流派。
- en: Take the first film in each group.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取每个组的第一部电影。
- en: Take the total number of award wins for each group.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取每个组的获奖总数。
- en: Join with the `comments` collection to get a list of comments for each film.
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与`comments`集合连接，获取每部电影的评论列表。
- en: 'Reduce the number of comments for each film to one using projection. (Hint:
    use the `$slice` operator to reduce array length.)'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用投影将每部电影的评论数量减少到一个。（提示：使用`$slice`运算符来减少数组长度。）
- en: Append the trailer time of 12 minutes to each film's runtime.
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每部电影的播放时间追加12分钟。
- en: Sort our result by the total number of award wins.
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按获奖总数对结果进行排序。
- en: Impose a limit of three documents.
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 限制三个文件。
- en: 'The desired output is follows:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 期望的输出如下：
- en: '![Figure 7.23: Final output after executing activity steps'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.23：执行活动步骤后的最终输出'
- en: '](img/B15507_07_23.jpg)'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15507_07_23.jpg)'
- en: 'Figure 7.23: Final output after executing activity steps'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.23：执行活动步骤后的最终输出
- en: Note
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via [this link](B15507_Solution_Final_SZ_ePub.xhtml#_idTextAnchor473).
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过[此链接](B15507_Solution_Final_SZ_ePub.xhtml#_idTextAnchor473)找到此活动的解决方案。
- en: Summary
  id: totrans-435
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have covered all the essential components that you need
    to understand, write, comprehend, and improve MongoDB aggregations. This new functionality
    will help you to answer more complex and difficult questions about your data.
    By creating multi-stage pipelines that join multiple collections, you can increase
    the scope of your queries to the entire database instead of a single collection.
    We also looked at how to write the results into a new collection to enable further
    exploration or manipulation of the data.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经涵盖了您需要了解、编写、理解和改进MongoDB聚合的所有基本组件。这种新功能将帮助您回答关于数据的更复杂和困难的问题。通过创建多阶段的管道，连接多个集合，您可以将查询范围扩大到整个数据库，而不仅仅是单个集合。我们还看了如何将结果写入新集合，以便进一步探索或操纵数据。
- en: In the final section, we covered the importance of ensuring that your pipelines
    are written with scalability, readability, and performance in mind. By focusing
    on these aspects, your pipelines will continue to deliver value in the future
    and can act as a basis for further aggregations.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一节中，我们介绍了确保编写的管道具有可扩展性、可读性和性能的重要性。通过专注于这些方面，您的管道将继续在未来提供价值，并可以作为进一步聚合的基础。
- en: However, what we have covered here is just the beginning of what you can accomplish
    with the aggregation feature. It is critical that you keep exploring, experimenting,
    and testing your pipelines to truly master this MongoDB skill.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们在这里所涵盖的只是您可以通过聚合功能实现的开始。重要的是要不断探索、实验和测试您的管道，以真正掌握这项MongoDB技能。
- en: In the next chapter, we will walk through the creation of an application in
    Node.js with MongoDB as a backend. Even if you're not a developer, this will give
    you meaningful insight into how MongoDB applications are built, along with a deeper
    understanding of building and executing dynamic queries.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍如何在Node.js中使用MongoDB作为后端创建应用程序。即使您不是开发人员，这也将让您深入了解MongoDB应用程序的构建方式，以及对构建和执行动态查询的更深入理解。
