# 第八章：监控、备份和安全性

监控、备份和安全性不应该是事后才考虑的，而是在将 MongoDB 部署到生产环境之前必须进行的过程。此外，监控可以（并且应该）用于在开发阶段排除故障和提高性能。

在本章中，我们将讨论 MongoDB 的运营方面。本章将涵盖制定正确和一致的备份策略以及确保我们的备份策略在需要备份时能够正常工作的内容。最后，我们将讨论 MongoDB 的安全性，包括身份验证、授权、网络级安全性以及如何审计我们的安全设计。

本章将重点关注以下三个领域：

+   监控

+   备份

+   安全

# 监控

当我们设计软件系统时，我们进行了许多明确和隐含的假设。我们总是试图根据我们的知识做出最佳决策，但可能有一些参数我们低估了或没有考虑到。

通过监控，我们可以验证我们的假设，并验证我们的应用程序是否按预期执行并扩展。良好的监控系统对于检测软件错误和帮助我们及早发现潜在的安全事件也至关重要。

# 我们应该监控什么？

迄今为止，在 MongoDB 中监视的最重要的指标是内存使用情况。MongoDB（以及每个数据库系统）广泛使用系统内存来提高性能。无论我们使用 MMAPv1 还是 WiredTiger 存储引擎，使用的内存都是我们应该关注的第一件事。

了解计算机内存的工作原理可以帮助我们评估监控系统的指标。这些是与计算机内存相关的最重要的概念。

# 页面错误

RAM 速度快，但价格昂贵。硬盘驱动器或固态硬盘相对便宜，速度较慢，并且在系统和电源故障的情况下为我们的数据提供耐用性。我们所有的数据都存储在磁盘上，当我们执行查询时，MongoDB 将尝试从内存中获取数据。如果数据不在内存中，它将从磁盘中获取数据并将其复制到内存中。这是一个**页面错误事件**，因为内存中的数据是以页面形式组织的。

随着页面错误的发生，内存被填满，最终，一些页面需要被清除以便将最新的数据放入内存。这被称为**页面驱逐事件**。除非我们有一个非常静态的数据集，否则我们无法完全避免页面错误，但我们确实希望尽量减少页面错误。这可以通过将我们的工作集保留在内存中来实现。

# 常驻内存

**常驻内存**大小是 MongoDB 在 RAM 中拥有的总内存量。这是要监视的基本指标，应该小于可用内存的 80%。

# 虚拟和映射内存

当 MongoDB 请求内存地址时，操作系统将返回一个虚拟地址。这可能是 RAM 中的实际地址，也可能不是，这取决于数据所在的位置。MongoDB 将使用这个虚拟地址来请求底层数据。当我们启用日志记录（几乎总是应该启用），MongoDB 将为日志记录的数据保留另一个地址。虚拟内存指的是 MongoDB 请求的所有数据的大小，包括日志记录。

映射内存不包括日志记录引用。

所有这些意味着，随着时间的推移，我们的映射内存将大致等于我们的工作集，而虚拟内存将大约是我们映射内存的两倍。

# 工作集

工作集是 MongoDB 使用的数据大小。在事务性数据库的情况下，这将成为 MongoDB 持有的数据大小，但也可能存在一些集合根本没有被使用，不会对我们的工作集产生影响。

# 监控 WiredTiger 中的内存使用情况

理解 MMAPv1 中的内存使用相对比较简单。MMAPv1 在底层使用`mmap()`系统调用来将内存页的责任传递给底层操作系统。这就是为什么当我们使用 MMAPv1 时，内存使用量会不受限制地增长，因为操作系统试图尽可能多地将我们的数据集放入内存中。

另一方面，使用 WiredTiger，我们可以在启动时定义内部缓存的内存使用情况。默认情况下，内部缓存最多占用我们 RAM 的一半，即 1GB 或 256MB 之间。

除了内部缓存之外，MongoDB 还可以为其他操作分配内存，比如维护连接和数据处理（内存排序，MapReduce，聚合等）。

MongoDB 进程也会使用底层操作系统的文件系统缓存，就像在 MMAPv1 中一样。文件系统缓存中的数据是压缩的。

我们可以通过 mongo shell 查看 WiredTiger 缓存的设置，如下所示：

```sql
> db.serverStatus().wiredTiger.cache
```

我们可以使用`storage.wiredTiger.engineConfig.cacheSizeGB`参数来调整其大小。

一般的建议是将 WiredTiger 内部缓存大小保持默认。如果我们的数据具有较高的压缩比，可能值得将内部缓存大小减少 10%至 20%，以释放更多内存用于文件系统缓存。

# 跟踪页面错误

页面错误的数量可以保持相对稳定，不会对性能产生显著影响。然而，一旦页面错误数量达到一定阈值，我们的系统将迅速严重地受到影响。对于 HDD 来说更加明显，但对**固态硬盘**（SSD）也有影响。

确保我们不会遇到页面错误的方法是始终拥有一个与我们生产环境设置相同的临时环境。这个环境可以用来压力测试我们的系统可以处理多少页面错误，而不会降低性能。通过比较我们生产系统中实际的页面错误数量和从临时系统计算出的最大页面错误数量，我们可以找出我们还剩下多少余地。

查看页面错误的另一种方法是通过 shell，查看`serverStatus`输出的`extra_info`字段：

```sql
> db.adminCommand({"serverStatus" : 1})['extra_info']
{ "note" : "fields vary by platform", "page_faults" : 3465 }
```

正如`note`所述，这些字段可能不会出现在每个平台上。

# 跟踪 B 树未命中

正如您在前一章中看到的，适当的索引是保持 MongoDB 响应和高性能的最佳方法。B 树未命中指的是当我们尝试访问 B 树索引时发生的页面错误。索引通常被频繁使用，与我们的工作集和可用内存相比相对较小，因此它们应该始终在内存中。

如果 B 树未命中的数量或 B 树命中比例增加，或者 B 树未命中的数量减少，这表明我们的索引已经增长或者设计不够优化。B 树未命中也可以通过 MongoDB Cloud Manager 或 shell 进行监控。

在 shell 中，我们可以使用集合统计来定位它。

# I/O 等待

**I/O 等待**指的是操作系统等待 I/O 操作完成的时间。它与页面错误有很强的正相关性。如果我们看到 I/O 等待随时间增加，这是页面错误即将发生的强烈迹象。我们应该努力保持 I/O 等待在健康的操作集群中低于 60%至 70%。设定这样的阈值将为我们争取一些时间，以便在突然增加的负载情况下进行升级。

# 读写队列

查看 I/O 等待和页面错误的另一种方法是通过读写队列。当出现页面错误和 I/O 等待时，请求将不可避免地开始排队进行读取或写入。队列是效果，而不是根本原因，所以当队列开始积累时，我们知道我们有问题要解决。

# 锁定百分比

这在较早版本的 MongoDB 中更为常见，在使用 WiredTiger 存储引擎时则不太常见。**锁定百分比**显示了数据库被锁定等待使用独占锁的操作释放的时间百分比。通常应该很低：最多为 10%至 20%。超过 50%意味着有问题。

# 后台刷新

默认情况下，MongoDB 每分钟将数据刷新到磁盘。**后台刷新**指的是数据持久化到磁盘所需的时间。对于每 1 分钟的时间段，它不应超过 1 秒。

修改刷新间隔可能有助于后台刷新时间；通过更频繁地写入磁盘，将减少需要写入的数据。在某些情况下，这可能会加快写入速度。

后台刷新时间受写入负载影响的事实意味着，如果我们的后台刷新时间开始变得过长，我们应该考虑对数据库进行分片，以增加写入容量。

# 跟踪空闲空间

使用 MMAPv1（使用 WiredTiger 时较少）时的常见问题是空闲磁盘空间。与内存一样，我们需要跟踪磁盘空间的使用情况，并且要有预见性，而不是被动应对。要保持监控磁盘空间的使用情况，并在达到 40%、60%或 80%时发出适当的警报，特别是对于快速增长的数据集。

磁盘空间问题通常是管理员、DevOps 和开发人员头疼的问题，因为移动数据需要花费时间。

`directoryperdb`选项可以帮助确定数据大小，因为我们可以将存储分割成不同的物理挂载磁盘。

# 监控复制

副本集使用**操作日志**（**oplog**）来保持同步状态。每个操作都会应用在主服务器上，然后写入主服务器的操作日志中，这是一个有上限的集合。辅助服务器会异步读取此操作日志，并逐个应用这些操作。

如果主服务器负载过重，那么辅助服务器将无法快速读取和应用操作，从而产生复制延迟。**复制延迟**是指主服务器上应用的最后一个操作与辅助服务器上应用的最后一个操作之间的时间差，存储在操作日志的有上限的集合中。

例如，如果时间是下午 4:30:00，而辅助服务器刚刚应用了在我们的主服务器上下午 4:25:00 应用的操作，这意味着辅助服务器落后于我们的主服务器五分钟。

在我们的生产集群中，复制延迟应该接近（或等于）零。

# 操作日志大小

副本集中的每个成员都会在`db.oplog.rs()`中有一个操作日志的副本。原因是，如果主服务器下线，其中一个辅助服务器将被选举，并且它需要有最新版本的操作日志，以便新的辅助服务器进行跟踪。

操作日志大小是可配置的，我们应该尽可能设置得更大。操作日志大小不会影响内存使用情况，并且在操作问题的情况下可能会使数据库出现问题。

原因是，如果复制延迟随时间增加，最终会导致辅助服务器落后到无法从主服务器的操作日志中读取的地步，因为主服务器的操作日志中最旧的条目将晚于在辅助服务器上应用的最新条目。

一般来说，操作日志应至少包含一到两天的操作。出于之前详细说明的同样原因，操作日志应比初始同步所需的时间更长。

# 工作集计算

工作集是我们内存需求的最强指标。理想情况下，我们希望整个数据集都在内存中，但大多数情况下，这是不可行的。下一个最好的选择是将我们的工作集放在内存中。工作集可以直接或间接地计算出来。

直接地，我们可以从 shell 中调用`serverStatus`中的`workingSet`标志，如下所示：

```sql
> db.adminCommand({"serverStatus" : 1, "workingSet" : 1})
```

不幸的是，这在 3.0 版本中被移除，因此我们将专注于计算工作集的间接方法。

间接地，我们的工作集是我们需要满足 95%或更多用户请求的数据大小。为了计算这一点，我们需要从日志中识别用户发出的查询以及他们使用的数据集。为了满足索引内存需求，我们可以将其增加 30%到 50%，从而得出工作集的计算。

另一种间接估计工作大小的方法是通过页面错误的数量。如果我们没有页面错误，那么我们的工作集适合内存。通过反复试验，我们可以估计页面错误开始发生的点，并了解我们的系统可以处理多大负载。

如果我们不能将工作集放入内存中，那么我们至少应该有足够的内存，使索引可以放入内存中。在上一章中，我们描述了如何计算索引内存需求，以及如何使用这个计算来相应地调整我们的 RAM 大小。

# 监控工具

有几种监控选项。在本节中，我们将讨论如何使用 MongoDB 自己的工具或第三方工具进行监控。

# 托管工具

MongoDB, Inc.自己的工具 MongoDB Cloud Manager（以前称为 MongoDB Monitoring Service）是一个强大的工具，用于监控之前描述的所有指标。MongoDB Cloud Manager 有一个有限的免费套餐和一个 30 天的试用期。

使用 MongoDB Cloud Manager 的另一个选择是通过 MongoDB Atlas，MongoDB, Inc.的 DBaaS 产品。这也有一个有限的免费套餐，并且在三个主要的云提供商（亚马逊、谷歌和微软）中都可用。

# 开源工具

所有主要的开源工具，如**Nagios**，**Munin**，**Cacti**等，都为 MongoDB 提供了插件支持。虽然这超出了本书的范围，但运维和 DevOps 应该熟悉之前描述的设置和理解指标，以有效地解决 MongoDB 的故障并在问题变得严重之前预先解决问题。

在 mongo shell 中，`mongotop`和`mongostat`命令和脚本也可以用于临时监控。然而，这种手动过程的一个风险是脚本的任何失败可能会危及我们的数据库。如果有为您的监控需求而知名且经过测试的工具，请避免编写自己的工具。

# 备份

一句来自著名格言的引语如下：

“抱最好的希望，为最坏的打算。”

- 约翰·杰伊（1813 年）

这应该是我们设计 MongoDB 备份策略时的方法。有几种不同的故障事件可能发生。

备份应该是我们灾难恢复策略的基石，以防发生意外。一些开发人员可能依赖于复制进行灾难恢复，因为似乎有三份数据已经足够。如果其中一份数据丢失，我们可以从其他两份数据重新构建集群。

这在磁盘故障事件中是适用的。磁盘故障是生产集群中最常见的故障之一，一旦磁盘开始接近其**平均故障时间**（**MTBF**）时间，故障就会发生。

然而，这并不是唯一可能发生的故障事件。安全事件或纯粹的人为错误同样可能发生，并且应该成为我们计划的一部分。一旦所有副本集成员同时丢失，如火灾、洪水、地震或不满的员工，这些事件不应导致生产数据丢失。

一个有用的临时选择，处于复制和实施适当备份之间的中间地带，可能是设置一个延迟的副本集成员。这个成员可以滞后于主服务器几个小时或几天，这样就不会受到主服务器中恶意更改的影响。需要注意的重要细节是，操作日志需要配置成可以保持几个小时的延迟。此外，这个解决方案只是一个临时解决方案，因为它没有考虑到我们需要灾难恢复的全部原因，但肯定可以帮助解决其中的一部分。

这被称为**灾难恢复**。灾难恢复是一类需要定期进行备份的故障，而且还需要使用一个过程来将它们（无论是地理上还是访问规则上）与我们的生产数据隔离开。

# 备份选项

根据我们的部署策略，我们可以选择不同的备份选项。

# 基于云的解决方案

如果我们使用云 DBaaS 解决方案，最直接的解决方案就是在 MongoDB 的例子中，我们可以通过 GUI 管理备份。

如果我们在自己的服务器上托管 MongoDB，我们可以使用 MongoDB, Inc.的 MongoDB Cloud Manager。Cloud Manager 是一个 SaaS，我们可以将其指向我们自己的服务器来监视和备份我们的数据。它使用与复制相同的操作日志，并且可以备份副本集和分片集群。

如果我们不想（或者出于安全原因不能）将我们的服务器指向外部的 SaaS 服务，我们可以在本地使用 MongoDB Cloud Manager 的功能，使用 MongoDB Ops Manager。要获得 MongoDB Ops Manager，我们需要为我们的集群订阅 MongoDB 企业高级版。

# 文件系统快照备份

过去最常见的备份方法，也是目前广泛使用的方法，依赖于底层文件系统的时间点快照功能来备份我们的数据。

EBS on EC2 和 Linux 上的**逻辑卷管理器**（**LVM**）支持时间点快照。

如果我们使用最新版本的 MongoDB 和 WiredTiger，我们可以进行卷级备份，即使我们的数据和日志文件存储在不同的卷中。

我们可以按照以下步骤备份副本集：

+   要备份副本集，我们需要为我们的数据库保持一致的状态。这意味着我们的所有写操作要么已经提交到磁盘，要么在我们的日志文件中。

+   如果我们使用 WiredTiger 存储，我们的快照将与最新的检查点一致，这要么是 2GB 的数据，要么是最后一分钟的备份。

确保将快照存储在离线卷中，以备灾难恢复之需。您需要启用日志记录以使用时间点快照。无论如何，启用日志记录都是一个好的做法。

# 备份分片集群

如果我们想备份整个分片集群，我们需要在开始之前停止平衡器。原因是，如果在我们拍摄快照时有不同分片之间的数据块迁移，我们的数据库将处于不一致状态，拥有在我们拍摄快照时正在传输的不完整或重复的数据块。

整个分片集群的备份将是近似时间的。如果我们需要时间点精度，我们需要停止数据库中的所有写操作，这通常对于生产系统来说是不可能的。

首先，我们需要通过 mongo shell 连接到我们的 mongos 来禁用平衡器：

```sql
> use config
> sh.stopBalancer()
```

然后，如果我们的辅助服务器没有启用日志记录，或者如果我们的日志和数据文件存储在不同的卷中，我们需要锁定所有分片和配置服务器副本集的辅助 mongo 实例。

我们还需要在这些服务器上设置足够的操作日志大小，以便它们可以在我们解锁它们后赶上主服务器；否则，我们将需要从头开始重新同步它们。

假设我们不需要锁定我们的辅助副本，下一步是备份配置服务器。在 Linux（使用 LVM），这类似于执行以下操作：

```sql
$ lvcreate --size 100M --snapshot --name snap-14082017 /dev/vg0/mongodb
```

然后，我们需要为每个分片中每个副本集的单个成员重复相同的过程。

最后，我们需要使用相同的 mongo shell 重新启动平衡器，该 shell 用于停止它：

```sql
> sh.setBalancerState(true)
```

不详细介绍，显而易见的是，备份分片集是一个复杂且耗时的过程。它需要事先规划和广泛测试，以确保它不仅可以在最小干扰下工作，而且我们的备份可用且可以恢复到我们的集群中。

# 使用 mongodump 进行备份

`mongodump`工具是一个可以备份我们 MongoDB 集群中数据的命令行工具。因此，缺点是在恢复时需要重新创建所有索引，这可能是一个耗时的操作。

`mongodump`工具的主要缺点是，为了将数据写入磁盘，它需要首先将数据从内部 MongoDB 存储器带到内存中。这意味着在承受压力运行的生产集群中，`mongodump`将使内存中的数据无效，从而使工作集中的数据与常规操作下不会驻留在内存中的数据相混合。这会降低我们集群的性能。

另一方面，当我们使用`mongodump`时，我们可以继续在我们的集群中进行写入，并且如果我们有一个副本集，我们可以使用`--oplog`选项将`mongodump`操作期间发生的条目包括在其输出 oplog 中。

如果我们选择这个选项，我们需要在使用`mongorestore`工具将数据恢复到 MongoDB 集群时使用`--oplogReplay`。

`mongodump`是单服务器部署的好工具，但一旦我们扩大规模，我们应该考虑使用不同（并且更好计划的）方法来备份我们的数据。

# 通过复制原始文件进行备份

如果我们不想使用前面概述的任何选项，我们的最后选择是使用`cp`/`rsync`或类似的东西复制原始文件。一般来说，这是不推荐的，原因如下：

+   在复制文件之前，我们需要停止所有写入操作

+   备份大小将更大，因为我们需要复制索引和任何底层填充和碎片化存储开销。

+   我们无法通过这种方法为副本集实现恢复到特定时间点，并且以一种一致且可预测的方式从分片集群中复制数据是非常困难的

除非真的没有其他选择，否则应避免通过复制原始文件进行备份。

# 使用排队进行备份

实际上使用的另一种策略是利用排队系统，拦截我们的数据库和前端软件系统。在我们的数据库中插入/更新/删除之前使用类似 ActiveMQ 队列的东西意味着我们可以安全地将数据发送到不同的接收端，这些接收端可以是 MongoDB 服务器或独立存储库中的日志文件。像延迟副本集方法一样，这种方法对于一类备份问题可能有用，但对于其他一些问题可能会失败。

这是一个有用的临时解决方案，但不应作为永久解决方案。

# EC2 备份和恢复

MongoDB Cloud Manager 可以自动从 EC2 卷中进行备份；而且，由于我们的数据在云中，为什么不使用 Cloud Manager 呢？

如果由于某种原因我们无法使用它，我们可以编写一个脚本来通过实施以下步骤进行备份：

1.  假设我们已经启用了日志记录（我们确实应该这样做），并且我们已经将包含数据和日志文件的`dbpath`映射到单个 EBS 卷上，我们首先需要使用`ec2-describe-instances`找到与运行实例相关联的 EBS 块实例。

1.  下一步是使用`lvdisplay`找到我们的 MongoDB 数据库的`dbpath`映射到的逻辑卷。

1.  一旦我们从逻辑卷中确定了逻辑设备，我们可以使用`ec2-create-snapshot`来创建新的快照。我们需要包括每一个映射到我们的`dbpath`目录的逻辑设备。

为了验证我们的备份是否有效，我们需要基于快照创建新卷并将新卷挂载在那里。最后，`mongod`进程应该能够开始挂载新数据，并且我们应该使用 MongoDB 进行连接以验证这些内容。

# 增量备份

每次进行完整备份对于一些部署来说可能是可行的，但是当大小达到一定阈值时，完整备份会花费太多时间和空间。

在这一点上，我们会想要偶尔进行完整备份（例如每月一次），并在此期间进行增量备份（例如每晚）。

Ops Manager 和 Cloud Manager 都支持增量备份，如果我们达到这个规模，使用工具进行备份可能是一个好主意，而不是自己开发。

如果我们不想（或不能）使用这些工具，我们可以通过 oplog 进行恢复，如下所示：

1.  使用之前描述的任何方法进行完整备份

1.  锁定我们副本集的辅助服务器的写入

1.  注意 oplog 中的最新条目

1.  在 oplog 中的最新条目之后导出条目：

```sql
> mongodump --host <secondary> -d local -c oplog.rs -o /mnt/mongo-oldway_backup
 --query '{ "ts" : { $gt :  Timestamp(1467999203, 391) } }'
```

1.  在辅助服务器上解锁写入

要恢复，我们可以使用刚刚导出的`oplog.rs`文件，并使用`mongorestore`选项`--oplogReplay`：

```sql
> mongorestore -h <primary> --port <port> --oplogReplay <data_file_position>
```

这种方法需要锁定写入，并且在将来的版本中可能无法使用。

更好的解决方案是使用**逻辑卷管理（LVM）**文件系统进行增量备份，但这取决于底层的 LVM 实现，我们可能无法进行调整。

# 安全性

安全性是 MongoDB 集群中的一个多方面目标。在本章的其余部分，我们将研究不同的攻击向量以及我们如何保护自己免受攻击。除了这些最佳实践之外，开发人员和管理员必须始终使用常识，以便安全性只在操作目标所需的程度上干扰。

# 认证

**认证**是指验证客户端的身份。这可以防止冒充他人以获取其数据的行为。

最简单的认证方式是使用`username`和`password`对。可以通过两种方式之一在 shell 中完成，第一种方式如下：

```sql
> db.auth( <username>, <password> )
```

传递逗号分隔的`username`和`password`将假定其余字段的默认值：

```sql
> db.auth( {
 user: <username>,
 pwd: <password>,
 mechanism: <authentication mechanism>,
 digestPassword: <boolean>
} )
```

如果我们传递一个文档对象，我们可以定义比`username`/`password`更多的参数。

（认证）`mechanism`参数可以采用几种不同的值，默认值为`SCRAM-SHA-1`。参数值`MONGODB-CR`用于与 3.0 之前的版本向后兼容。

MONGODB-x.509 用于 TLS/SSL 认证。用户和内部副本集服务器可以通过使用 SSL 证书进行认证，这些证书可以是自动生成和签名的，也可以来自受信任的第三方机构。

要为副本集成员的内部认证配置 x.509，我们需要提供以下参数之一。

以下是配置文件的内容：

```sql
security.clusterAuthMode / net.ssl.clusterFile
```

以下是在命令行上使用的：

```sql
--clusterAuthMode and --sslClusterFile
> mongod --replSet <name> --sslMode requireSSL --clusterAuthMode x509 --sslClusterFile <path to membership certificate and key PEM file> --sslPEMKeyFile <path to SSL certificate and key PEM file> --sslCAFile <path to root CA PEM file>
```

MongoDB 企业版是 MongoDB，Inc.提供的付费产品，增加了两个认证选项，如下所示：

+   第一个添加的选项是**通用安全服务应用程序接口**（**GSSAPI**）Kerberos。Kerberos 是一个成熟和强大的认证系统，可用于基于 Windows 的 Active Directory 部署等场景。

+   第二个添加的选项是 PLAIN（LDAP SASL）。LDAP 就像 Kerberos 一样：是一种成熟和健壮的身份验证机制。使用 PLAIN 身份验证机制时的主要考虑因素是凭据以明文形式在网络上传输。这意味着我们应该通过 VPN 或 TSL/SSL 连接来保护客户端和服务器之间的路径，以避免中间人窃取我们的凭据。

# 授权

在我们配置了身份验证以验证用户在连接到我们的 MongoDB 服务器时是否是他们声称的身份后，我们需要配置每个用户在我们数据库中拥有的权限。

这是权限的**授权**方面。MongoDB 使用基于角色的访问控制来控制不同用户类别的权限。

每个角色都有权限在资源上执行一些操作。

资源可以是一个集合/多个集合或一个数据库/多个数据库。

命令的格式如下：

```sql
{ db: <database>, collection: <collection> }
```

如果我们为`db`或`collection`指定了`""`（空字符串），这意味着任何`db`或`collection`。例如：

```sql
{ db: "mongo_books", collection: "" }
```

这将应用我们的操作到`mongo_books`数据库中的每个`collection`。

如果数据库不是`admin`数据库，则不会包括系统集合。系统集合，如`<db>.system.profile`，`<db>.system.js`，`admin.system.users`和`admin.system.roles`，需要明确定义。

与前面的选项类似，我们可以定义以下内容：

```sql
{ db: "", collection: "" }
```

我们定义这个规则，将其应用到所有数据库的所有集合，当然除了系统集合。

我们还可以应用规则到整个集群，如下：

```sql
{ resource: { cluster : true }, actions: [ "addShard" ] }
```

前面的示例授予了在整个集群中执行`addShard`操作（向系统添加新的分片）的权限。集群资源只能用于影响整个集群而不是集合或数据库的操作（例如`shutdown`，`replSetReconfig`，`appendOplogNote`，`resync`，`closeAllDatabases`和`addShard`）。

接下来是一个广泛的特定于集群的操作列表，以及一些最常用的操作。

最常用操作的列表如下：

+   查找

+   插入

+   删除

+   更新

+   绕过文档验证

+   查看角色/查看用户

+   创建角色/删除角色

+   创建用户/删除用户

+   inprog

+   killop

+   replSetGetConfig/replSetConfigure/replSetStateChange/resync

+   获取分片映射/获取分片版本/列出分片/移动分片/移除分片/添加分片

+   删除数据库/删除索引/fsync/修复数据库/关闭

+   服务器状态/顶部/验证

特定于集群的操作如下：

+   解锁

+   authSchemaUpgrade

+   清理孤立

+   cpuProfiler

+   inprog

+   使用户缓存无效

+   killop

+   追加操作日志注释

+   replSetConfigure

+   replSetGetConfig

+   replSetGetStatus

+   replSetHeartbeat

+   replSetStateChange

+   重新同步

+   添加分片

+   刷新路由器配置

+   获取分片映射

+   列出分片

+   移除分片

+   分片状态

+   应用消息

+   关闭所有数据库

+   connPoolSync

+   fsync

+   获取参数

+   主机信息

+   日志轮转

+   设置参数

+   关闭

+   触摸

+   connPoolStats

+   游标信息

+   诊断日志

+   获取 CmdLineOpts

+   获取日志

+   列出数据库

+   netstat

+   服务器状态

+   顶部

如果听起来太复杂，那是因为它确实如此！MongoDB 允许在资源上配置不同操作的灵活性意味着我们需要研究和理解之前描述的广泛列表。

幸运的是，一些最常见的操作和资源已经包含在内置角色中。

我们可以使用这些内置角色来建立我们将授予用户的权限基线，然后根据广泛的列表进行细化。

# 用户角色

我们可以指定两种不同的通用用户角色，如下：

+   读取：在非系统集合和以下系统集合上的只读角色：`system.indexes`，`system.js`和`system.namespaces`集合

+   `readWrite`：在非系统集合和`system.js`集合上具有读写权限

# 数据库管理角色

有三种特定于数据库的管理角色，如下所示：

+   `dbAdmin`：可以执行与模式相关的任务、索引和收集统计信息的基本管理员用户角色。`dbAdmin`不能执行用户和角色管理。

+   `userAdmin`：创建和修改角色和用户。这是`dbAdmin`角色的补充。

`userAdmin`可以修改自身以成为数据库中的超级用户，或者，如果范围限定为`admin`数据库，则可以成为 MongoDB 集群的超级用户。

+   `dbOwner`：结合了`readWrite`、`dbAdmin`和`userAdmin`角色，这是最强大的管理员用户角色。

# 集群管理角色

以下是可用的集群范围管理角色：

+   `hostManager`：监视和管理集群中的服务器。

+   `clusterManager`：提供对集群的管理和监控操作。拥有此角色的用户可以访问用于分片和复制的配置和本地数据库。

+   `clusterMonitor`：只读访问权限，用于监控工具，如 MongoDB Cloud Manager 和 Ops Manager 代理提供的工具。

+   `clusterAdmin`：提供最大的集群管理访问权限。该角色结合了`clusterManager`、`clusterMonitor`和`hostManager`角色授予的权限。此外，该角色提供`dropDatabase`操作。

# 备份和恢复角色

基于角色的授权角色可以在备份和恢复的粒度级别中定义：

+   `backup`：提供备份数据所需的权限。该角色提供足够的权限来使用 MongoDB Cloud Manager 备份代理、Ops Manager 备份代理或`mongodump`。

+   `restore`：提供使用`mongorestore`还原数据所需的权限，但不包括`--oplogReplay`选项或`system.profile`集合数据。

# 所有数据库中的角色

同样，以下是所有数据库中可用的角色集合：

+   `readAnyDatabase`：提供与`read`相同的只读权限，但适用于集群中除了本地和配置数据库之外的所有数据库。该角色还在整个集群上提供`listDatabases`操作。

+   `readWriteAnyDatabase`：提供与`readWrite`相同的读写权限，但适用于集群中除了本地和配置数据库之外的所有数据库。该角色还在整个集群上提供`listDatabases`操作。

+   `userAdminAnyDatabase`：提供与`userAdmin`相同的用户管理操作权限，但适用于集群中除了本地和配置数据库之外的所有数据库。由于`userAdminAnyDatabase`角色允许用户向任何用户授予任何权限，包括自己，该角色间接地提供了超级用户访问权限。

+   `dbAdminAnyDatabase`：提供与`dbAdmin`相同的数据库管理操作权限，但适用于集群中除了本地和配置数据库之外的所有数据库。该角色还在整个集群上提供`listDatabases`操作。

# 超级用户

最后，以下是可用的超级用户角色：

+   `root`：提供对`readWriteAnyDatabase`、`dbAdminAnyDatabase`、`userAdminAnyDatabase`、`clusterAdmin`、`restore`和`backup`的操作和所有资源的访问权限

+   `__internal`：类似于 root 用户，任何`__internal`用户都可以对服务器上的任何对象执行任何操作。

应避免使用超级用户角色，因为它们可能对服务器上的所有数据库具有潜在破坏性的权限。

# 网络级安全

除了 MongoDB 特定的安全措施，还有针对网络级安全建立的最佳实践：

+   只允许服务器之间的通信，并且只打开用于它们之间通信的端口。

+   始终使用 TLS/SSL 进行服务器之间的通信。这可以防止中间人攻击冒充客户端。

+   始终使用不同的开发、暂存和生产环境以及安全凭据。理想情况下，为每个环境创建不同的帐户，并在暂存和生产环境中启用双因素身份验证。

# 审计安全

无论我们如何计划我们的安全措施，来自我们组织之外的第二或第三双眼睛可以对我们的安全措施提供不同的视角，并发现我们可能低估或忽视的问题。不要犹豫，要请安全专家和白帽黑客对服务器进行渗透测试。

# 特殊情况

出于数据隐私原因，医疗或金融应用程序需要增加安全级别。

如果我们正在构建一个涉及医疗保健领域的应用程序，访问用户的个人身份信息，我们可能需要获得 HIPAA 认证。

如果我们正在构建一个与支付交互并管理持卡人信息的应用程序，我们可能需要符合 PCI/DSS 标准。

每个认证的具体细节超出了本书的范围，但重要的是要知道 MongoDB 在这些领域有使用案例，满足要求，并且在适当的设计前可以成为正确的工具。

# 概述

总结涉及安全的最佳实践建议，我们有以下内容：

+   **强制进行身份验证**：始终在生产环境中启用身份验证。

+   **启用访问控制**：首先创建一个系统管理员，然后使用该管理员创建更有限的用户。为每个用户角色提供所需的最少权限。

+   **定义细粒度的访问控制角色**：不要给予每个用户比所需权限更多的权限。

+   **加密客户端和服务器之间的通信**：在生产环境中，始终使用 TLS/SSL 进行客户端和服务器之间的通信。对于`mongod`和`mongos`或配置服务器之间的通信，也应始终使用 TLS/SSL。

+   **加密静止数据**：MongoDB 企业版提供了在存储时加密数据的功能，使用 WiredTiger 静止加密。

或者，我们可以使用文件系统、设备或物理加密来加密数据。在云中，我们通常也可以选择加密（例如，在 Amazon EC2 上使用 EBS）。

+   **限制网络暴露**：MongoDB 服务器应该只连接到应用程序服务器和其他必需的服务器。除了我们为 MongoDB 通信设置的端口之外，不应该对外界开放其他端口。如果我们想要调试 MongoDB 的使用，重要的是设置一个代理服务器，以受控访问与我们的数据库进行通信。

+   **审计服务器以查找异常活动**：MongoDB 企业版提供了一个审计实用程序。通过使用它，我们可以将事件输出到控制台、JSON 文件、BSON 文件或 syslog。无论如何，重要的是确保审计事件存储在对系统用户不可用的分区中。

+   使用专用操作系统用户来运行 MongoDB。确保专用操作系统用户可以访问 MongoDB，但不具备不必要的权限。

+   如果不需要，禁用 JavaScript 服务器端脚本。

MongoDB 可以使用 JavaScript 进行服务器端脚本，使用以下命令：`mapReduce()`、`group()`和`$where`。如果我们不需要这些命令，我们应该在命令行上使用`--noscripting`选项禁用服务器端脚本。

# 总结

在本章中，您了解了 MongoDB 的三个操作方面：监控、备份和安全。

我们讨论了在 MongoDB 中应该监控的指标，以及如何监控它们。在此之后，我们讨论了如何进行备份并确保我们可以使用它们来恢复我们的数据。最后，您了解了身份验证和授权概念以及网络级安全以及如何对其进行审计。

设计、构建和根据需要扩展我们的应用程序同样重要，同样重要的是要确保在运营过程中我们能够心无旁骛，并且能够防范意外事件，比如人为错误和内部或外部恶意用户。

在下一章中，您将了解可插拔存储引擎，这是在 MongoDB 3.0 版本中引入的新概念。可插拔存储引擎允许满足不同的用例，特别是在具有特定和严格的数据处理和隐私要求的应用领域。
