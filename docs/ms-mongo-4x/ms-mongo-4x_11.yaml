- en: Monitoring, Backup, and Security
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控、备份和安全性
- en: Monitoring, backup, and security should not be an afterthought, but a necessary
    process before deploying MongoDB in a production environment. In addition, monitoring
    can (and should) be used to troubleshoot and improve performance at the development
    stage.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 监控、备份和安全性不应该是事后才考虑的，而是在将MongoDB部署到生产环境之前必须进行的过程。此外，监控可以（并且应该）用于在开发阶段排除故障和提高性能。
- en: In this chapter, we will discuss the operational aspects of MongoDB. Having
    a backup strategy that produces correct and consistent backups, as well as making
    sure that our backup strategy will work in the unfortunate case that a backup
    is needed, will be covered in this chapter. Finally, we will discuss security
    for MongoDB for many different aspects, such as authentication, authorization,
    network-level security, and how to audit our security design.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论MongoDB的运营方面。本章将涵盖制定正确和一致的备份策略以及确保我们的备份策略在需要备份时能够正常工作的内容。最后，我们将讨论MongoDB的安全性，包括身份验证、授权、网络级安全性以及如何审计我们的安全设计。
- en: 'This chapter will focus on the following three areas:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点关注以下三个领域：
- en: Monitoring
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控
- en: Backup
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份
- en: Security
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全
- en: Monitoring
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: When we are designing a software system, we undertake many explicit and implicit
    assumptions. We always try to make the best decisions based on our knowledge,
    but there may be some parameters that we have underestimated or didn't take into
    account.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们设计软件系统时，我们进行了许多明确和隐含的假设。我们总是试图根据我们的知识做出最佳决策，但可能有一些参数我们低估了或没有考虑到。
- en: Using monitoring, we can validate our assumptions and verify that our application
    performs as intended and scales as expected. Good monitoring systems are also
    vital for detecting software bugs and to help us detect early potential security
    incidents.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过监控，我们可以验证我们的假设，并验证我们的应用程序是否按预期执行并扩展。良好的监控系统对于检测软件错误和帮助我们及早发现潜在的安全事件也至关重要。
- en: What should we monitor?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们应该监控什么？
- en: By far, the most important metric to monitor in MongoDB is memory usage. MongoDB
    (and every database system, for what it's worth) uses system memory extensively
    to increase performance. No matter whether we use MMAPv1 or WiredTiger storage
    engines, the memory that's used is the first thing that we should keep our eyes
    on.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，在MongoDB中监视的最重要的指标是内存使用情况。MongoDB（以及每个数据库系统）广泛使用系统内存来提高性能。无论我们使用MMAPv1还是WiredTiger存储引擎，使用的内存都是我们应该关注的第一件事。
- en: Understanding how computer memory works can help us to evaluate metrics from
    our monitoring system. These are the most important concepts related to computer
    memory.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 了解计算机内存的工作原理可以帮助我们评估监控系统的指标。这些是与计算机内存相关的最重要的概念。
- en: Page faults
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 页面错误
- en: RAM is fast, yet expensive. Hard disk drives, or solid state drives, are relatively
    cheaper and slower, and also provide durability for our data in the case of system
    and power failures. All of our data is stored on the disk, and when we perform
    a query, MongoDB will try to fetch data from memory. If the data is not in the
    memory, then it will fetch the data from the disk and copy it to the memory. This
    is a **page fault event**, because the data in the memory is organized in pages.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: RAM速度快，但价格昂贵。硬盘驱动器或固态硬盘相对便宜，速度较慢，并且在系统和电源故障的情况下为我们的数据提供耐用性。我们所有的数据都存储在磁盘上，当我们执行查询时，MongoDB将尝试从内存中获取数据。如果数据不在内存中，它将从磁盘中获取数据并将其复制到内存中。这是一个**页面错误事件**，因为内存中的数据是以页面形式组织的。
- en: As page faults happen, the memory gets filled up, and eventually, some pages
    need to be cleared for more recent data to come into the memory. This is called a **page
    eviction event**. We cannot completely avoid page faults unless we have a really
    static dataset, but we do want to try to minimize page faults. This can be achieved
    by holding our working set in memory.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着页面错误的发生，内存被填满，最终，一些页面需要被清除以便将最新的数据放入内存。这被称为**页面驱逐事件**。除非我们有一个非常静态的数据集，否则我们无法完全避免页面错误，但我们确实希望尽量减少页面错误。这可以通过将我们的工作集保留在内存中来实现。
- en: Resident memory
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常驻内存
- en: The **resident memory** size is the total amount of memory that MongoDB owns
    in the RAM. This is the base metric to monitor, and it should be less than 80%
    of the available memory.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**常驻内存**大小是MongoDB在RAM中拥有的总内存量。这是要监视的基本指标，应该小于可用内存的80%。'
- en: Virtual and mapped memory
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟和映射内存
- en: When MongoDB asks for a memory address, the operating system will return a virtual
    address. This may or may not be an actual address in the RAM, depending on where
    the data resides. MongoDB will use this virtual address to request the underlying
    data. When we have journaling enabled (which should be almost always), MongoDB
    will keep another address on record for the journaled data. The virtual memory
    refers to the size of all of the data requested by MongoDB, including the journaling.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当MongoDB请求内存地址时，操作系统将返回一个虚拟地址。这可能是RAM中的实际地址，也可能不是，这取决于数据所在的位置。MongoDB将使用这个虚拟地址来请求底层数据。当我们启用日志记录（几乎总是应该启用），MongoDB将为日志记录的数据保留另一个地址。虚拟内存指的是MongoDB请求的所有数据的大小，包括日志记录。
- en: The mapped memory excludes journaling references.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 映射内存不包括日志记录引用。
- en: What all of this means is that over time, our mapped memory will be roughly
    equal to our working set, and the virtual memory will be around twice the amount
    of our mapped memory.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些意味着，随着时间的推移，我们的映射内存将大致等于我们的工作集，而虚拟内存将大约是我们映射内存的两倍。
- en: Working sets
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作集
- en: The working set is the data size that MongoDB uses. In the case of a transactional
    database, this will end up being the data size that MongoDB holds, but there may
    be cases where we have collections that are not used at all and will not contribute
    to our working set.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 工作集是MongoDB使用的数据大小。在事务性数据库的情况下，这将成为MongoDB持有的数据大小，但也可能存在一些集合根本没有被使用，不会对我们的工作集产生影响。
- en: Monitoring memory usage in WiredTiger
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控WiredTiger中的内存使用情况
- en: Understanding the memory usage in MMAPv1 is relatively straightforward. MMAPv1
    uses the `mmap()` system call under the hood to pass on the responsibility of
    the memory page to the underlying operating system. That is why when we use MMAPv1,
    the memory usage will grow unbounded, as the operating system is trying to fit
    as much of our dataset into the memory as possible.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 理解MMAPv1中的内存使用相对比较简单。MMAPv1在底层使用`mmap()`系统调用来将内存页的责任传递给底层操作系统。这就是为什么当我们使用MMAPv1时，内存使用量会不受限制地增长，因为操作系统试图尽可能多地将我们的数据集放入内存中。
- en: With WiredTiger, on the other hand, we define the internal cache memory usage
    on startup. By default, the internal cache will be, at a maximum, between half
    of our RAM, which is in-between 1 GB or 256 MB.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用WiredTiger，我们可以在启动时定义内部缓存的内存使用情况。默认情况下，内部缓存最多占用我们RAM的一半，即1GB或256MB之间。
- en: On top of the internal cache, there is also memory that MongoDB can allocate
    for other operations, like maintaining connections and data processing (in-memory
    sort, MapReduce, aggregation, and more).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了内部缓存之外，MongoDB还可以为其他操作分配内存，比如维护连接和数据处理（内存排序，MapReduce，聚合等）。
- en: MongoDB processes will also use the underlying operating system's filesystem
    cache, just like in MMAPv1\. The data in the filesystem cache is compressed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB进程也会使用底层操作系统的文件系统缓存，就像在MMAPv1中一样。文件系统缓存中的数据是压缩的。
- en: 'We can view the settings for the WiredTiger cache via the mongo shell, as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过mongo shell查看WiredTiger缓存的设置，如下所示：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can adjust its size by using the `storage.wiredTiger.engineConfig.cacheSizeGB`
    parameter.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`storage.wiredTiger.engineConfig.cacheSizeGB`参数来调整其大小。
- en: The generic recommendation is to leave the WiredTiger internal cache size at
    its default. If our data has a high compression ratio, it may be worth reducing
    the internal cache size by 10% to 20% to free up more memory for the filesystem
    cache.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的建议是将WiredTiger内部缓存大小保持默认。如果我们的数据具有较高的压缩比，可能值得将内部缓存大小减少10%至20%，以释放更多内存用于文件系统缓存。
- en: Tracking page faults
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪页面错误
- en: The number of page faults can remain fairly stable and not affect performance
    significantly. However, once the number of page faults reaches a certain threshold,
    our system will be quickly and severely degraded. This is even more evident for
    HDDs, but it affects **solid-state drives** (**SSDs**) as well.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 页面错误的数量可以保持相对稳定，不会对性能产生显著影响。然而，一旦页面错误数量达到一定阈值，我们的系统将迅速严重地受到影响。对于HDD来说更加明显，但对**固态硬盘**（SSD）也有影响。
- en: The way to ensure that we don't run into problems regarding page faults is to
    always have a staging environment that is identical to our production in setup.
    This environment can be used to stress test how many page faults our system can
    handle, without deteriorating performance. Comparing the actual number of page
    faults in our production system with the maximum number of page faults that we
    calculated from our staging system, we can find out how much leeway we have left.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 确保我们不会遇到页面错误的方法是始终拥有一个与我们生产环境设置相同的临时环境。这个环境可以用来压力测试我们的系统可以处理多少页面错误，而不会降低性能。通过比较我们生产系统中实际的页面错误数量和从临时系统计算出的最大页面错误数量，我们可以找出我们还剩下多少余地。
- en: 'Another way to view page faults is via the shell, looking at the `extra_info`
    field of the `serverStatus` output:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 查看页面错误的另一种方法是通过shell，查看`serverStatus`输出的`extra_info`字段：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As the `note` states, these fields may not be present in every platform.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如`note`所述，这些字段可能不会出现在每个平台上。
- en: Tracking B-tree misses
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪B树未命中
- en: As you saw in the previous chapter, proper indexing is the best way to keep
    MongoDB responsive and performant. B-tree misses refer to page faults that happen
    when we try to access a B-tree index. Indexes are usually used frequently, and
    are relatively small compared to our working set and the memory available, so
    they should be in the memory at all times.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在前一章中看到的，适当的索引是保持MongoDB响应和高性能的最佳方法。B树未命中指的是当我们尝试访问B树索引时发生的页面错误。索引通常被频繁使用，与我们的工作集和可用内存相比相对较小，因此它们应该始终在内存中。
- en: If we have an increasing number of B-tree misses or ratio of B-tree hits, or
    if there is a decrease in the number of B-tree misses, it's a sign that our indexes
    have grown in size and/or are not optimally designed. B-tree misses can also be
    monitored via MongoDB Cloud Manager, or in the shell.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果B树未命中的数量或B树命中比例增加，或者B树未命中的数量减少，这表明我们的索引已经增长或者设计不够优化。B树未命中也可以通过MongoDB Cloud
    Manager或shell进行监控。
- en: In the shell, we can use collection stats to locate it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在shell中，我们可以使用集合统计来定位它。
- en: I/O wait
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: I/O等待
- en: '**I/O wait** refers to the time that the operating system waits for an I/O
    operation to complete. It has a strongly positive correlation with page faults.
    If we see an I/O wait increasing over time, it''s a strong indication that page
    faults will follow, as well. We should aim to keep the I/O wait at less than 60%
    to 70% for a healthy operational cluster. Aiming for a threshold like this will
    buy us some time to upgrade in the case of a suddenly increased load.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**I/O等待**指的是操作系统等待I/O操作完成的时间。它与页面错误有很强的正相关性。如果我们看到I/O等待随时间增加，这是页面错误即将发生的强烈迹象。我们应该努力保持I/O等待在健康的操作集群中低于60%至70%。设定这样的阈值将为我们争取一些时间，以便在突然增加的负载情况下进行升级。'
- en: Read and write queues
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读写队列
- en: Another way to look at I/O wait and page faults is via read and write queues.
    When we have page faults and I/O wait, requests will inevitably start to queue
    for either reads or writes. Queues are the effect, rather than the root cause,
    so by the time the queues start building up, we know we have a problem to solve.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 查看I/O等待和页面错误的另一种方法是通过读写队列。当出现页面错误和I/O等待时，请求将不可避免地开始排队进行读取或写入。队列是效果，而不是根本原因，所以当队列开始积累时，我们知道我们有问题要解决。
- en: Lock percentage
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁定百分比
- en: 'This is more of an issue with earlier versions of MongoDB, and less of an issue
    when using the WiredTiger storage engine. The **lock percentage** shows the percentage
    of time that the database is locked up, waiting for an operation that uses an
    exclusive lock to release it. It should generally be low: 10% to 20%, at the most.
    Over 50% means it''s a cause for concern.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这在较早版本的MongoDB中更为常见，在使用WiredTiger存储引擎时则不太常见。**锁定百分比**显示了数据库被锁定等待使用独占锁的操作释放的时间百分比。通常应该很低：最多为10%至20%。超过50%意味着有问题。
- en: Background flushes
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 后台刷新
- en: MongoDB will flush data to the disk every minute, by default. The **background
    flush** refers to the time it takes for the data to persist to the disk. It should
    not be more than 1 second for every 1 minute period.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，MongoDB每分钟将数据刷新到磁盘。**后台刷新**指的是数据持久化到磁盘所需的时间。对于每1分钟的时间段，它不应超过1秒。
- en: Modifying the flush interval may help with the background flush time; by writing
    to the disk more frequently, there will be less data to write. This could, in
    some cases, make writes faster.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 修改刷新间隔可能有助于后台刷新时间；通过更频繁地写入磁盘，将减少需要写入的数据。在某些情况下，这可能会加快写入速度。
- en: The fact that the background flush time gets affected by the write load means
    that if our background flush time starts to get too high, we should consider sharding
    our database to increase the write capacity.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 后台刷新时间受写入负载影响的事实意味着，如果我们的后台刷新时间开始变得过长，我们应该考虑对数据库进行分片，以增加写入容量。
- en: Tracking free space
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪空闲空间
- en: A common issue when using MMAPv1 (less frequent with WiredTiger) is free disk
    space. Like the memory, we need to track the disk space usage and be proactive,
    rather than reactive, with it. Keep monitoring the disk space usage, with proper
    alerts when it reaches 40%, 60%, or 80% of the disk space, especially for datasets
    that grow quickly.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MMAPv1（使用WiredTiger时较少）时的常见问题是空闲磁盘空间。与内存一样，我们需要跟踪磁盘空间的使用情况，并且要有预见性，而不是被动应对。要保持监控磁盘空间的使用情况，并在达到40%、60%或80%时发出适当的警报，特别是对于快速增长的数据集。
- en: Disk space issues are often the ones that cause the most headaches for administrators,
    DevOps, and developers, because of the time it takes to move data around.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 磁盘空间问题通常是管理员、DevOps和开发人员头疼的问题，因为移动数据需要花费时间。
- en: The `directoryperdb` option can help with data sizing, as we can split our storage
    into different physically mounted disks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`directoryperdb`选项可以帮助确定数据大小，因为我们可以将存储分割成不同的物理挂载磁盘。'
- en: Monitoring replication
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控复制
- en: Replica sets use the **operations log** (**oplog**) to keep the synced state.
    Every operation gets applied on the primary server, and then gets written in the
    primary server's oplog, which is a capped collection. Secondaries read this oplog
    asynchronously and apply the operations one by one.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 副本集使用**操作日志**（**oplog**）来保持同步状态。每个操作都会应用在主服务器上，然后写入主服务器的操作日志中，这是一个有上限的集合。辅助服务器会异步读取此操作日志，并逐个应用这些操作。
- en: If the primary server gets overloaded, then the secondaries won't be able to
    read and apply the operations fast enough, generating replication lag. **Replication
    lag** is counted as the time difference between the last operation applied on
    the primary and the last operation applied on the secondary, as stored in the
    oplog capped collection.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主服务器负载过重，那么辅助服务器将无法快速读取和应用操作，从而产生复制延迟。**复制延迟**是指主服务器上应用的最后一个操作与辅助服务器上应用的最后一个操作之间的时间差，存储在操作日志的有上限的集合中。
- en: For example, if the time is 4:30:00 PM and the secondary just applied an operation
    that was applied on our primary server at 4:25:00 PM, this means that the secondary
    is lagging five minutes behind our primary server.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果时间是下午4:30:00，而辅助服务器刚刚应用了在我们的主服务器上下午4:25:00应用的操作，这意味着辅助服务器落后于我们的主服务器五分钟。
- en: In our production cluster, the replication lag should be close to (or equal
    to) zero.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的生产集群中，复制延迟应该接近（或等于）零。
- en: Oplog size
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作日志大小
- en: Every member in a replica size will have a copy of the oplog in `db.oplog.rs()`.
    The reason for this is that if the primary steps down, one of the secondaries
    will get elected, and it needs to have an up-to-date version of the oplog for
    the new secondaries to track.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 副本集中的每个成员都会在`db.oplog.rs()`中有一个操作日志的副本。原因是，如果主服务器下线，其中一个辅助服务器将被选举，并且它需要有最新版本的操作日志，以便新的辅助服务器进行跟踪。
- en: The oplog size is configurable, and we should set it to be as large as possible.
    The oplog size doesn't affect the memory usage, and can make or break the database
    in cases of operational issues.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 操作日志大小是可配置的，我们应该尽可能设置得更大。操作日志大小不会影响内存使用情况，并且在操作问题的情况下可能会使数据库出现问题。
- en: The reason for this is that if the replication lag increases over time, we will
    eventually get to the point where the secondaries will fall so behind that the
    primary server won't be able to read from the primary's oplog, as the oldest entry
    in the primary's oplog will be later than the latest entry that was applied in
    our secondary server.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 原因是，如果复制延迟随时间增加，最终会导致辅助服务器落后到无法从主服务器的操作日志中读取的地步，因为主服务器的操作日志中最旧的条目将晚于在辅助服务器上应用的最新条目。
- en: In general, the oplog should be at least one to two days' worth of operations.
    The oplog should be longer than the time it takes for the initial sync, for the
    same reason that was detailed previously.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，操作日志应至少包含一到两天的操作。出于之前详细说明的同样原因，操作日志应比初始同步所需的时间更长。
- en: Working set calculations
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作集计算
- en: The working set is the strongest indicator of our memory requirements. Ideally,
    we would like to have our entire dataset in the memory, but most of the time, this
    is not feasible. The next best thing is to have our working set in memory. The
    working set can be calculated directly or indirectly.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 工作集是我们内存需求的最强指标。理想情况下，我们希望整个数据集都在内存中，但大多数情况下，这是不可行的。下一个最好的选择是将我们的工作集放在内存中。工作集可以直接或间接地计算出来。
- en: 'Directly, we had the `workingSet` flag in `serverStatus`, which we can invoke
    from the shell, as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 直接地，我们可以从shell中调用`serverStatus`中的`workingSet`标志，如下所示：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Unfortunately, this was removed in version 3.0, so we will focus on the indirect
    method of calculating a working set.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这在3.0版本中被移除，因此我们将专注于计算工作集的间接方法。
- en: Indirectly, our working set is the size of data that we need to satisfy 95%
    or more of our user's requests. To calculate this, we need to identify the queries
    that the users make and which datasets they use from the logs. Adding 30% to 50%
    to it for index memory requirements, we can arrive at the working set calculation.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 间接地，我们的工作集是我们需要满足95%或更多用户请求的数据大小。为了计算这一点，我们需要从日志中识别用户发出的查询以及他们使用的数据集。为了满足索引内存需求，我们可以将其增加30%到50%，从而得出工作集的计算。
- en: Another indirect way of estimating the working size is through the number of
    page faults. If we don't have page faults, then our working set fits in the memory.
    Through trial and error, we can estimate the point at which the page faults start
    to happen and understand how much more of a load our system can handle.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种间接估计工作大小的方法是通过页面错误的数量。如果我们没有页面错误，那么我们的工作集适合内存。通过反复试验，我们可以估计页面错误开始发生的点，并了解我们的系统可以处理多大负载。
- en: If we can't have the working set in memory, then we should have at least enough
    memory so that the indexes can fit in memory. In the previous chapter, we described
    how we can calculate index memory requirements, and how we can use this calculation
    to size our RAM accordingly.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不能将工作集放入内存中，那么我们至少应该有足够的内存，使索引可以放入内存中。在上一章中，我们描述了如何计算索引内存需求，以及如何使用这个计算来相应地调整我们的RAM大小。
- en: Monitoring tools
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控工具
- en: There are several options for monitoring. In this section, we will discuss how
    we can monitor by using MongoDB's own tools or third-party tools.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种监控选项。在本节中，我们将讨论如何使用MongoDB自己的工具或第三方工具进行监控。
- en: Hosted tools
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 托管工具
- en: MongoDB, Inc.'s own tool, MongoDB Cloud Manager (formerly MongoDB Monitoring
    Service), is a robust tool for monitoring all of the metrics that were described
    previously. MongoDB Cloud Manager has a limited free tier and a 30 day trial period.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB, Inc.自己的工具MongoDB Cloud Manager（以前称为MongoDB Monitoring Service）是一个强大的工具，用于监控之前描述的所有指标。MongoDB
    Cloud Manager有一个有限的免费套餐和一个30天的试用期。
- en: Another option for using MongoDB Cloud Manager is via MongoDB Atlas, MongoDB,
    Inc.'s DBaaS offering. This also has a limited free tier, and is available in
    all three major cloud providers (Amazon, Google, and Microsoft).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MongoDB Cloud Manager的另一个选择是通过MongoDB Atlas，MongoDB, Inc.的DBaaS产品。这也有一个有限的免费套餐，并且在三个主要的云提供商（亚马逊、谷歌和微软）中都可用。
- en: Open source tools
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源工具
- en: All major open source tools, like **Nagios**, **Munin**, **Cacti**, and others,
    provide plugin support for MongoDB. Although it is beyond the scope of this book,
    operations and DevOps should be familiar with both setting up and understanding
    the metrics that were described previously in order to effectively troubleshoot
    MongoDB and preemptively resolve issues before they grow out of proportion.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 所有主要的开源工具，如**Nagios**，**Munin**，**Cacti**等，都为MongoDB提供了插件支持。虽然这超出了本书的范围，但运维和DevOps应该熟悉之前描述的设置和理解指标，以有效地解决MongoDB的故障并在问题变得严重之前预先解决问题。
- en: The `mongotop` and `mongostat` commands and scripts in the mongo shell can also
    be used for ad hoc monitoring. One of the risks with such manual processes, however,
    is that any failure of the scripts may jeopardize our database. If there are well-known
    and tested tools for your monitoring needs, please avoid writing your own.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在mongo shell中，`mongotop`和`mongostat`命令和脚本也可以用于临时监控。然而，这种手动过程的一个风险是脚本的任何失败可能会危及我们的数据库。如果有为您的监控需求而知名且经过测试的工具，请避免编写自己的工具。
- en: Backups
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份
- en: 'A quote from a well-known maxim is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一句来自著名格言的引语如下：
- en: '"Hope for the best, plan for the worst."'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: “抱最好的希望，为最坏的打算。”
- en: – John Jay (1813)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '- 约翰·杰伊（1813年）'
- en: This should be our approach when designing our backup strategy for MongoDB.
    There are several distinct failure events that can happen.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该是我们设计MongoDB备份策略时的方法。有几种不同的故障事件可能发生。
- en: Backups should be the cornerstone of our disaster recovery strategy, in case
    something happens. Some developers may rely on replication for disaster recovery,
    as it seems that having three copies of our data is more than enough. We can always
    rebuild the cluster from the other two copies, in case one of the copies is lost.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 备份应该是我们灾难恢复策略的基石，以防发生意外。一些开发人员可能依赖于复制进行灾难恢复，因为似乎有三份数据已经足够。如果其中一份数据丢失，我们可以从其他两份数据重新构建集群。
- en: This is the case in the event of disks failing. Disk failure is one of the most
    common failures in a production cluster, and will statistically happen once the
    disks start reaching their **mean time between failures** (**MTBF**) time.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这在磁盘故障事件中是适用的。磁盘故障是生产集群中最常见的故障之一，一旦磁盘开始接近其**平均故障时间**（**MTBF**）时间，故障就会发生。
- en: However, it is not the only failure event that can happen. Security incidents,
    or purely human errors, are just as likely to happen, and should be a part of
    our plan, as well. Catastrophic failures by means of losing all replica set members
    at once, from a fire, a flood, an earthquake, or a disgruntled employee, are events
    that should not lead to production data loss.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是唯一可能发生的故障事件。安全事件或纯粹的人为错误同样可能发生，并且应该成为我们计划的一部分。一旦所有副本集成员同时丢失，如火灾、洪水、地震或不满的员工，这些事件不应导致生产数据丢失。
- en: A useful interim option, in the middle ground between replication and implementing
    proper backups, could be setting up a delayed replica set member. This member
    can lag several hours or days behind the primary server so that it will not be
    affected by malicious changes in the primary. The important detail to take into
    account is that the oplog needs to be configured so that it can hold several hours
    of delay. Also, this solution is only an interim, as it doesn't take into account
    the full range of reasons why we need disaster recovery, but can definitely help
    with a subset of them.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有用的临时选择，处于复制和实施适当备份之间的中间地带，可能是设置一个延迟的副本集成员。这个成员可以滞后于主服务器几个小时或几天，这样就不会受到主服务器中恶意更改的影响。需要注意的重要细节是，操作日志需要配置成可以保持几个小时的延迟。此外，这个解决方案只是一个临时解决方案，因为它没有考虑到我们需要灾难恢复的全部原因，但肯定可以帮助解决其中的一部分。
- en: This is called **disaster recovery**. Disaster recovery is a class of failures
    that require backups to be taken not only regularly, but also by using a process
    that isolates them (both geographically and in terms of access rules) from our
    production data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为**灾难恢复**。灾难恢复是一类需要定期进行备份的故障，而且还需要使用一个过程来将它们（无论是地理上还是访问规则上）与我们的生产数据隔离开。
- en: Backup options
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份选项
- en: Depending on our deployment strategy, we can choose different options for backups.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的部署策略，我们可以选择不同的备份选项。
- en: Cloud-based solutions
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于云的解决方案
- en: The most straightforward solution arises if we are using a cloud DBaaS solution.
    In the example of MongoDB, Inc.'s own MongoDB Atlas, we can manage backups from
    the GUI.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用云DBaaS解决方案，最直接的解决方案就是在MongoDB的例子中，我们可以通过GUI管理备份。
- en: If we host MongoDB in our own servers, we can then use MongoDB, Inc.'s MongoDB
    Cloud Manager. Cloud Manager is a SaaS that we can point to our own servers to
    monitor and back up our data. It uses the same oplog that replication uses, and
    can back up both replica sets and sharded clusters.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在自己的服务器上托管MongoDB，我们可以使用MongoDB, Inc.的MongoDB Cloud Manager。Cloud Manager是一个SaaS，我们可以将其指向我们自己的服务器来监视和备份我们的数据。它使用与复制相同的操作日志，并且可以备份副本集和分片集群。
- en: If we don't want to (or can't, for security reasons) point our servers to an
    external SaaS service, we can use MongoDB Cloud Manager's functionality on-premises,
    using MongoDB Ops Manager. To get MongoDB Ops Manager, we need to get a subscription
    to the Enterprise Advanced edition of MongoDB for our cluster.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不想（或者出于安全原因不能）将我们的服务器指向外部的SaaS服务，我们可以在本地使用MongoDB Cloud Manager的功能，使用MongoDB
    Ops Manager。要获得MongoDB Ops Manager，我们需要为我们的集群订阅MongoDB企业高级版。
- en: Backups with filesystem snapshots
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文件系统快照备份
- en: The most common backup method in the past, and one that is still widely used,
    relies on the underlying filesystem point-in-time snapshots functionality to back
    up our data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 过去最常见的备份方法，也是目前广泛使用的方法，依赖于底层文件系统的时间点快照功能来备份我们的数据。
- en: EBS on EC2, and **Logical Volume Manager** (**LVM**) on Linux, support point-in-time
    snapshots.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: EBS on EC2和Linux上的**逻辑卷管理器**（**LVM**）支持时间点快照。
- en: If we use WiredTiger with the latest version of MongoDB, we can have volume-level
    backups, even if our data and journal files reside in different volumes.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用最新版本的MongoDB和WiredTiger，我们可以进行卷级备份，即使我们的数据和日志文件存储在不同的卷中。
- en: 'We can make a backup of a replica set as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按照以下步骤备份副本集：
- en: To make a backup of a replica set, we need to have a consistent state for our
    database. This implies that we have all of our writes either committed to the
    disk or in our journal files.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要备份副本集，我们需要为我们的数据库保持一致的状态。这意味着我们的所有写操作要么已经提交到磁盘，要么在我们的日志文件中。
- en: If we use WiredTiger storage, our snapshot will be consistent as of the latest
    checkpoint, which is either 2 GB of data or the last minute backup.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们使用WiredTiger存储，我们的快照将与最新的检查点一致，这要么是2GB的数据，要么是最后一分钟的备份。
- en: Ensure that you store the snapshot in an offsite volume for disaster recovery
    purposes. You need to have enabled journaling to use point-in-time snapshots.
    It's a good practice to enable journaling regardless.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将快照存储在离线卷中，以备灾难恢复之需。您需要启用日志记录以使用时间点快照。无论如何，启用日志记录都是一个好的做法。
- en: Making a backup of a sharded cluster
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份分片集群
- en: If we want to make a backup of an entire sharded cluster, we need to stop the
    balancer before starting. The reason is that if there are chunks migrating between
    different shards at the time that we take our snapshot, our database will be in
    an inconsistent state, having either incomplete or duplicate data chunks that
    were in flight at the time we took our snapshot.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想备份整个分片集群，我们需要在开始之前停止平衡器。原因是，如果在我们拍摄快照时有不同分片之间的数据块迁移，我们的数据库将处于不一致状态，拥有在我们拍摄快照时正在传输的不完整或重复的数据块。
- en: Backups from an entire sharded cluster will be approximate-in-time. If we need
    point-in-time precision, we need to stop all of the writes in our database, something
    that is generally not possible for production systems.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 整个分片集群的备份将是近似时间的。如果我们需要时间点精度，我们需要停止数据库中的所有写操作，这通常对于生产系统来说是不可能的。
- en: 'First, we need to disable the balancer by connecting to our mongos through
    the mongo shell:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要通过mongo shell连接到我们的mongos来禁用平衡器：
- en: '[PRE3]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Then, if we don't have journaling enabled in our secondaries, or if we have
    journal and data files in different volumes, we need to lock our secondary mongo
    instances for all shards and the config server replica set.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果我们的辅助服务器没有启用日志记录，或者如果我们的日志和数据文件存储在不同的卷中，我们需要锁定所有分片和配置服务器副本集的辅助mongo实例。
- en: We also need to have a sufficient oplog size in these servers so that they can
    catch up to the primaries once we unlock them; otherwise, we will need to resync
    them from scratch.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要在这些服务器上设置足够的操作日志大小，以便它们可以在我们解锁它们后赶上主服务器；否则，我们将需要从头开始重新同步它们。
- en: 'Given that we don''t need to lock our secondaries, the next step is to back
    up the config server. In Linux (and using LVM), this would be similar to doing
    the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们不需要锁定我们的辅助副本，下一步是备份配置服务器。在Linux（使用LVM），这类似于执行以下操作：
- en: '[PRE4]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, we need to repeat the same process for a single member from each replica
    set in each shard.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要为每个分片中每个副本集的单个成员重复相同的过程。
- en: 'Finally, we need to restart the balancer using the same mongo shell that we
    used to stop it:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要使用相同的mongo shell重新启动平衡器，该shell用于停止它：
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Without going into too much detail here, it's evident that making a backup of
    a sharded cluster is a complicated and time-consuming procedure. It needs prior
    planning and extensive testing to make sure that it not only works with minimal
    disruption, but also that our backups are usable and can be restored back to our
    cluster.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 不详细介绍，显而易见的是，备份分片集是一个复杂且耗时的过程。它需要事先规划和广泛测试，以确保它不仅可以在最小干扰下工作，而且我们的备份可用且可以恢复到我们的集群中。
- en: Making backups using mongodump
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用mongodump进行备份
- en: The `mongodump` tool is a command-line tool that can make a backup of the data
    in our MongoDB cluster. As such, the downside is that all of the indexes need
    to be recreated on restore, which may be a time-consuming operation.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`mongodump`工具是一个可以备份我们MongoDB集群中数据的命令行工具。因此，缺点是在恢复时需要重新创建所有索引，这可能是一个耗时的操作。'
- en: The major downside that the `mongodump` tool has is that in order to write data
    to the disk, it needs to bring data from the internal MongoDB storage to the memory
    first. This means that in the case of production clusters running under strain,
    `mongodump` will invalidate the data residing in the memory from the working set
    with the data that would not be residing in the memory under regular operations.
    This degrades the performance of our cluster.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`mongodump`工具的主要缺点是，为了将数据写入磁盘，它需要首先将数据从内部MongoDB存储器带到内存中。这意味着在承受压力运行的生产集群中，`mongodump`将使内存中的数据无效，从而使工作集中的数据与常规操作下不会驻留在内存中的数据相混合。这会降低我们集群的性能。'
- en: On the plus side, when we use `mongodump`, we can continue taking writes in
    our cluster, and if we have a replica set, we can use the `--oplog` option to
    include the entries that occur during the `mongodump` operation in its output
    oplog.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，当我们使用`mongodump`时，我们可以继续在我们的集群中进行写入，并且如果我们有一个副本集，我们可以使用`--oplog`选项将`mongodump`操作期间发生的条目包括在其输出oplog中。
- en: If we go with that option, we need to use `--oplogReplay` when we use the `mongorestore`
    tool to restore our data back to the MongoDB cluster.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择这个选项，我们需要在使用`mongorestore`工具将数据恢复到MongoDB集群时使用`--oplogReplay`。
- en: '`mongodump` is a great tool for single-server deployments, but once we get
    to larger deployments, we should consider using different (and better planned)
    approaches to back up our data.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`mongodump`是单服务器部署的好工具，但一旦我们扩大规模，我们应该考虑使用不同（并且更好计划的）方法来备份我们的数据。'
- en: Backing up by copying raw files
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过复制原始文件进行备份
- en: 'If we don''t want to use any of the preceding options that were outlined, our
    last resort is to copy the raw files using `cp`/`rsync`, or something equivalent.
    This is generally not recommended, for the following reasons:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不想使用前面概述的任何选项，我们的最后选择是使用`cp`/`rsync`或类似的东西复制原始文件。一般来说，这是不推荐的，原因如下：
- en: We need to stop all of the writes before copying files
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在复制文件之前，我们需要停止所有写入操作
- en: The backup size will be larger, since we need to copy indexes and any underlying
    padding and fragmentation storage overhead
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份大小将更大，因为我们需要复制索引和任何底层填充和碎片化存储开销。
- en: We cannot get point-in-time recovery by using this method for replica sets,
    and copying data from sharded clusters in a consistent and predictable manner
    is extremely difficult
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们无法通过这种方法为副本集实现恢复到特定时间点，并且以一种一致且可预测的方式从分片集群中复制数据是非常困难的
- en: Making a backup by copying raw files should be avoided, unless no other option
    really exists.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 除非真的没有其他选择，否则应避免通过复制原始文件进行备份。
- en: Making backups using queuing
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用排队进行备份
- en: Another strategy that's used in practice is utilizing a queuing system, intercepting
    our database and the frontend software system. Having something like an ActiveMQ
    queue before the inserts/updates/deletes in our database means that we can safely
    send out data to different sinks, which are MongoDB servers or log files in a
    separate repository. Like the delayed replica set method, this method can be useful
    for a class of backup problems, but can fail for some others.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上使用的另一种策略是利用排队系统，拦截我们的数据库和前端软件系统。在我们的数据库中插入/更新/删除之前使用类似ActiveMQ队列的东西意味着我们可以安全地将数据发送到不同的接收端，这些接收端可以是MongoDB服务器或独立存储库中的日志文件。像延迟副本集方法一样，这种方法对于一类备份问题可能有用，但对于其他一些问题可能会失败。
- en: This is a useful interim solution, but it should not be used as a permanent
    one.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有用的临时解决方案，但不应作为永久解决方案。
- en: EC2 backup and restore
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EC2备份和恢复
- en: MongoDB Cloud Manager can automate making backups from EC2 volumes; and, since
    our data is in the cloud, why not use the Cloud Manager anyway?
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB Cloud Manager可以自动从EC2卷中进行备份；而且，由于我们的数据在云中，为什么不使用Cloud Manager呢？
- en: 'If we can''t use it for some reason, we can write a script to make backup by
    implementing the following steps:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由于某种原因我们无法使用它，我们可以编写一个脚本来通过实施以下步骤进行备份：
- en: Assuming that we have journaling enabled (and we really should) and we have
    already mapped `dbpath`, containing data and journal files to a single EBS volume,
    we first need to find the EBS block instances associated with the running instance
    by using `ec2-describe-instances`.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们已经启用了日志记录（我们确实应该这样做），并且我们已经将包含数据和日志文件的`dbpath`映射到单个EBS卷上，我们首先需要使用`ec2-describe-instances`找到与运行实例相关联的EBS块实例。
- en: The next step is to find the logical volumes that `dbpath` of our MongoDB database
    is mapped to using `lvdisplay`.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是使用`lvdisplay`找到我们的MongoDB数据库的`dbpath`映射到的逻辑卷。
- en: Once we have identified the logical devices from the logical volumes, we can
    use `ec2-create-snapshot` to create new snapshots. We need to include each and
    every logical device that maps to our `dbpath` directory.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们从逻辑卷中确定了逻辑设备，我们可以使用`ec2-create-snapshot`来创建新的快照。我们需要包括每一个映射到我们的`dbpath`目录的逻辑设备。
- en: To verify that our backups work, we need to create new volumes based on the
    snapshots and mount the new volumes there. Finally, the `mongod` process should
    be able to start mounting the new data, and we should connect by using MongoDB
    to verify these.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们的备份是否有效，我们需要基于快照创建新卷并将新卷挂载在那里。最后，`mongod`进程应该能够开始挂载新数据，并且我们应该使用MongoDB进行连接以验证这些内容。
- en: Incremental backups
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增量备份
- en: Making full backups every time may be viable for some deployments, but as the
    size reaches a certain threshold, full backups take too much time and space.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 每次进行完整备份对于一些部署来说可能是可行的，但是当大小达到一定阈值时，完整备份会花费太多时间和空间。
- en: At this point, we will want to make full backups every once in a while (maybe
    one per month, for example) and incremental backups in-between (for example, nightly).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们会想要偶尔进行完整备份（例如每月一次），并在此期间进行增量备份（例如每晚）。
- en: Both Ops Manager and Cloud Manager support incremental backups, and if we get
    to this size, it may be a good idea to use a tool to make our backups instead
    of rolling out our own.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Ops Manager和Cloud Manager都支持增量备份，如果我们达到这个规模，使用工具进行备份可能是一个好主意，而不是自己开发。
- en: 'If we don''t want to (or can''t) use these tools, we have the option of restoring
    via the oplog, as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不想（或不能）使用这些工具，我们可以通过oplog进行恢复，如下所示：
- en: Make a full backup with any method that was described previously
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用之前描述的任何方法进行完整备份
- en: Lock writes on the secondary server of our replica set
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 锁定我们副本集的辅助服务器的写入
- en: Note the latest entry in the oplog
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意oplog中的最新条目
- en: 'Export the entries in the oplog after the latest entry in the oplog:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在oplog中的最新条目之后导出条目：
- en: '[PRE6]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Unlock writes on the secondary server
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在辅助服务器上解锁写入
- en: 'To restore, we can use the `oplog.rs` file that we just exported, and use `mongorestore`
    with the option `--oplogReplay`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复，我们可以使用刚刚导出的`oplog.rs`文件，并使用`mongorestore`选项`--oplogReplay`：
- en: '[PRE7]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This method requires locking writes, and may not work in future versions.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法需要锁定写入，并且在将来的版本中可能无法使用。
- en: An even better solution is to use the **L****ogical Volume Management (LVM)** filesystem
    with incremental backups, but this depends on the underlying LVM implementation,
    which we may or may not be able to tweak.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的解决方案是使用**逻辑卷管理（LVM）**文件系统进行增量备份，但这取决于底层的LVM实现，我们可能无法进行调整。
- en: Security
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全性
- en: Security is a multifaceted goal in a MongoDB cluster. For the rest of this chapter,
    we will examine different attack vectors and how we can protect against them.
    In addition to these best practices, developers and administrators must always
    use common sense so that security interferes only as much as is required for operational
    goals.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性是MongoDB集群中的一个多方面目标。在本章的其余部分，我们将研究不同的攻击向量以及我们如何保护自己免受攻击。除了这些最佳实践之外，开发人员和管理员必须始终使用常识，以便安全性只在操作目标所需的程度上干扰。
- en: Authentication
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认证
- en: '**Authentication** refers to verifying the identity of a client. This prevents
    the impersonation of someone in order to gain access to their data.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**认证**是指验证客户端的身份。这可以防止冒充他人以获取其数据的行为。'
- en: 'The simplest way to authenticate is by using a `username` and `password` pair.
    This can be done via the shell in two ways, the first of which is as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的认证方式是使用`username`和`password`对。可以通过两种方式之一在shell中完成，第一种方式如下：
- en: '[PRE8]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Passing in a comma-separated `username` and `password` will assume the default
    values for the rest of the fields:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 传递逗号分隔的`username`和`password`将假定其余字段的默认值：
- en: '[PRE9]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If we pass a document object, we can define more parameters than `username`/`password`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们传递一个文档对象，我们可以定义比`username`/`password`更多的参数。
- en: The (authentication) `mechanism` parameter can take several different values,
    with the default being `SCRAM-SHA-1`. The parameter value `MONGODB-CR` is used
    for backwards compatibility with versions earlier than 3.0.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: （认证）`mechanism`参数可以采用几种不同的值，默认值为`SCRAM-SHA-1`。参数值`MONGODB-CR`用于与3.0之前的版本向后兼容。
- en: MONGODB-x.509 is used for TLS/SSL authentication. Users and internal replica
    set servers can be authenticated by using SSL certificates, which are self-generated
    and signed, or comes from a trusted third-party authority.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: MONGODB-x.509用于TLS/SSL认证。用户和内部副本集服务器可以通过使用SSL证书进行认证，这些证书可以是自动生成和签名的，也可以来自受信任的第三方机构。
- en: To configure x.509 for internal authentication of replica set members, we need
    to supply one of the following parameters.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要为副本集成员的内部认证配置x.509，我们需要提供以下参数之一。
- en: 'The following is for the configuration file:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是配置文件的内容：
- en: '[PRE10]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following is used on the command line:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在命令行上使用的：
- en: '[PRE11]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'MongoDB Enterprise Edition, the paid offering from MongoDB, Inc., adds two
    more options for authentication, as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB企业版是MongoDB，Inc.提供的付费产品，增加了两个认证选项，如下所示：
- en: The first added option is **Generic Security Service Application Program Interface**
    (**GSSAPI**) Kerberos. Kerberos is a mature and robust authentication system that
    can be used for Windows-based Active Directory deployments, among others.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个添加的选项是**通用安全服务应用程序接口**（**GSSAPI**）Kerberos。Kerberos是一个成熟和强大的认证系统，可用于基于Windows的Active
    Directory部署等场景。
- en: 'The second added option is PLAIN (LDAP SASL). LDAP is just like Kerberos: a
    mature and robust authentication mechanism. The main consideration when using
    the PLAIN authentication mechanism is that the credentials are transmitted in
    plain text over the wire. This means that we should secure the path between the
    client and server via VPN or a TSL/SSL connection to avoid a man in the middle
    stealing our credentials.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个添加的选项是PLAIN（LDAP SASL）。LDAP就像Kerberos一样：是一种成熟和健壮的身份验证机制。使用PLAIN身份验证机制时的主要考虑因素是凭据以明文形式在网络上传输。这意味着我们应该通过VPN或TSL/SSL连接来保护客户端和服务器之间的路径，以避免中间人窃取我们的凭据。
- en: Authorization
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 授权
- en: After we have configured the authentication to verify that the users are who
    they claim they are when connecting to our MongoDB server, we need to configure
    the rights that each one of them will have in our database.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们配置了身份验证以验证用户在连接到我们的MongoDB服务器时是否是他们声称的身份后，我们需要配置每个用户在我们数据库中拥有的权限。
- en: This is the **authorization** aspect of permissions. MongoDB uses role-based
    access control to control permissions for different user classes.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这是权限的**授权**方面。MongoDB使用基于角色的访问控制来控制不同用户类别的权限。
- en: Every role has permissions to perform some actions on a resource.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 每个角色都有权限在资源上执行一些操作。
- en: A resource can be a collection/collections or a database/databases.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 资源可以是一个集合/多个集合或一个数据库/多个数据库。
- en: 'The command''s format is as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 命令的格式如下：
- en: '[PRE12]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If we specify `""` (an empty string) for either `db` or `collection`, it means
    any `db` or `collection`. An example of this is as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们为`db`或`collection`指定了`""`（空字符串），这意味着任何`db`或`collection`。例如：
- en: '[PRE13]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This would apply our action in every `collection` in the `mongo_books` database.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这将应用我们的操作到`mongo_books`数据库中的每个`collection`。
- en: If the database is not the `admin` database, this will not include the system
    collections. System collections, such as `<db>.system.profile`, `<db>.system.js`,
    `admin.system.users`, and `admin.system.roles`, need to be defined explicitly.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据库不是`admin`数据库，则不会包括系统集合。系统集合，如`<db>.system.profile`，`<db>.system.js`，`admin.system.users`和`admin.system.roles`，需要明确定义。
- en: 'Similar to the preceding option, we can define the following:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 与前面的选项类似，我们可以定义以下内容：
- en: '[PRE14]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We define this to apply our rule to all of the collections across all of the
    databases, except for system collections, of course.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义这个规则，将其应用到所有数据库的所有集合，当然除了系统集合。
- en: 'We can also apply rules across an entire cluster, as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以应用规则到整个集群，如下：
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The preceding example grants privileges for the `addShard` action (adding a
    new shard to our system) across the entire cluster. The cluster resource can only
    be used for actions that affect the entire cluster, rather than a collection or
    database (for example, `shutdown`, `replSetReconfig`, `appendOplogNote`, `resync`,
    `closeAllDatabases`, and `addShard`).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例授予了在整个集群中执行`addShard`操作（向系统添加新的分片）的权限。集群资源只能用于影响整个集群而不是集合或数据库的操作（例如`shutdown`，`replSetReconfig`，`appendOplogNote`，`resync`，`closeAllDatabases`和`addShard`）。
- en: What follows is an extensive list of cluster-specific actions, and some of the
    most widely used actions.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是一个广泛的特定于集群的操作列表，以及一些最常用的操作。
- en: 'The list of the most widely used actions is as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用操作的列表如下：
- en: '`find`'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找
- en: '`insert`'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 插入
- en: '`remove`'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除
- en: '`update`'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新
- en: '`bypassDocumentValidation`'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绕过文档验证
- en: '`viewRole`/`viewUser`'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看角色/查看用户
- en: '`createRole`/`dropRole`'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建角色/删除角色
- en: '`createUser`/`dropUser`'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用户/删除用户
- en: '`inprog`'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: inprog
- en: '`killop`'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: killop
- en: '`replSetGetConfig`/`replSetConfigure`/`replSetStateChange`/`resync`'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: replSetGetConfig/replSetConfigure/replSetStateChange/resync
- en: '`getShardMap`/`getShardVersion`/`listShards`/`moveChunk`/`removeShard`/`addShard`'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取分片映射/获取分片版本/列出分片/移动分片/移除分片/添加分片
- en: '`dropDatabase`/`dropIndex`/`fsync`/`repairDatabase`/`shutDown`'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除数据库/删除索引/fsync/修复数据库/关闭
- en: '`serverStatus`/`top`/`validate`'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器状态/顶部/验证
- en: 'Cluster-specific actions are as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 特定于集群的操作如下：
- en: '`unlock`'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解锁
- en: '`authSchemaUpgrade`'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: authSchemaUpgrade
- en: '`cleanupOrphaned`'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理孤立
- en: '`cpuProfiler`'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: cpuProfiler
- en: '`inprog`'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: inprog
- en: '`invalidateUserCache`'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用户缓存无效
- en: '`killop`'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: killop
- en: '`appendOplogNote`'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 追加操作日志注释
- en: '`replSetConfigure`'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: replSetConfigure
- en: '`replSetGetConfig`'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: replSetGetConfig
- en: '`replSetGetStatus`'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: replSetGetStatus
- en: '`replSetHeartbeat`'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: replSetHeartbeat
- en: '`replSetStateChange`'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: replSetStateChange
- en: '`resync`'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新同步
- en: '`addShard`'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加分片
- en: '`flushRouterConfig`'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刷新路由器配置
- en: '`getShardMap`'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取分片映射
- en: '`listShards`'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出分片
- en: '`removeShard`'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除分片
- en: '`shardingState`'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分片状态
- en: '`applicationMessage`'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用消息
- en: '`closeAllDatabases`'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关闭所有数据库
- en: '`connPoolSync`'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: connPoolSync
- en: '`fsync`'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fsync
- en: '`getParameter`'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取参数
- en: '`hostInfo`'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机信息
- en: '`logRotate`'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志轮转
- en: '`setParameter`'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置参数
- en: '`shutdown`'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关闭
- en: '`touch`'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 触摸
- en: '`connPoolStats`'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: connPoolStats
- en: '`cursorInfo`'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游标信息
- en: '`diagLogging`'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 诊断日志
- en: '`getCmdLineOpts`'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取CmdLineOpts
- en: '`getLog`'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取日志
- en: '`listDatabases`'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出数据库
- en: '`netstat`'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: netstat
- en: '`serverStatus`'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器状态
- en: '`top`'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶部
- en: If this sounds too complicated, that's because it is! The flexibility that MongoDB
    allows for configuring different actions on resources means that we need to study
    and understand the extensive lists, as described previously.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如果听起来太复杂，那是因为它确实如此！MongoDB允许在资源上配置不同操作的灵活性意味着我们需要研究和理解之前描述的广泛列表。
- en: Thankfully, some of the most common actions and resources are bundled in built-in
    roles.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，一些最常见的操作和资源已经包含在内置角色中。
- en: We can use these built-in roles to establish the baseline of permissions that
    we will give to our users, and then fine-grain these based on the extensive list.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这些内置角色来建立我们将授予用户的权限基线，然后根据广泛的列表进行细化。
- en: User roles
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户角色
- en: 'There are two different generic user roles that we can specify, as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以指定两种不同的通用用户角色，如下：
- en: '`read`: A read-only role across non-system collections and the following system
    collections: `system.indexes`, `system.js`, and `system.namespaces` collections'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取：在非系统集合和以下系统集合上的只读角色：`system.indexes`，`system.js`和`system.namespaces`集合
- en: '`readWrite`: A read and modify role across non-system collections and the `system.js`
    collection'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`readWrite`：在非系统集合和`system.js`集合上具有读写权限'
- en: Database administration roles
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库管理角色
- en: 'There are three database-specific administration roles, as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种特定于数据库的管理角色，如下所示：
- en: '`dbAdmin`: The basic admin user role that can perform schema-related tasks,
    indexing, and gathering statistics. A `dbAdmin` cannot perform user and role management.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dbAdmin`：可以执行与模式相关的任务、索引和收集统计信息的基本管理员用户角色。`dbAdmin`不能执行用户和角色管理。'
- en: '`userAdmin`: Create and modify roles and users. This is complementary to the
    `dbAdmin` role.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`userAdmin`：创建和修改角色和用户。这是`dbAdmin`角色的补充。'
- en: A `userAdmin` can modify itself to become a superuser in the database, or, if
    scoped to the `admin` database, the MongoDB cluster.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`userAdmin`可以修改自身以成为数据库中的超级用户，或者，如果范围限定为`admin`数据库，则可以成为MongoDB集群的超级用户。'
- en: '`dbOwner`: Combining `readWrite`, `dbAdmin`, and `userAdmin` roles, this is
    the most powerful admin user role.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dbOwner`：结合了`readWrite`、`dbAdmin`和`userAdmin`角色，这是最强大的管理员用户角色。'
- en: Cluster administration roles
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群管理角色
- en: 'The following are the cluster-wide administration roles that are available:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可用的集群范围管理角色：
- en: '`hostManager`: Monitor and manage servers in a cluster.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hostManager`：监视和管理集群中的服务器。'
- en: '`clusterManager`: Provides management and monitoring actions on the cluster.
    A user with this role can access the config and local databases, which are used
    in sharding and replication, respectively.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clusterManager`：提供对集群的管理和监控操作。拥有此角色的用户可以访问用于分片和复制的配置和本地数据库。'
- en: '`clusterMonitor`: Read-only access for monitoring tools provided by MongoDB,
    such as MongoDB Cloud Manager and the Ops Manager agent.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clusterMonitor`：只读访问权限，用于监控工具，如MongoDB Cloud Manager和Ops Manager代理提供的工具。'
- en: '`clusterAdmin`: Provides the greatest cluster management access. This role
    combines the privileges that are granted by the `clusterManager`, `clusterMonitor`,
    and `hostManager` roles. Additionally, the role provides the `dropDatabase` action.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clusterAdmin`：提供最大的集群管理访问权限。该角色结合了`clusterManager`、`clusterMonitor`和`hostManager`角色授予的权限。此外，该角色提供`dropDatabase`操作。'
- en: Backup and restore roles
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份和恢复角色
- en: 'Role-based authorization roles can be defined in the backup and restore granularity
    level, as well:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 基于角色的授权角色可以在备份和恢复的粒度级别中定义：
- en: '`backup`: Provides privileges that are needed to back up the data. This role
    provides sufficient privileges to use the MongoDB Cloud Manager backup agent,
    the Ops Manager backup agent, or `mongodump`.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backup`：提供备份数据所需的权限。该角色提供足够的权限来使用MongoDB Cloud Manager备份代理、Ops Manager备份代理或`mongodump`。'
- en: '`restore`: Provides the privileges that are needed to restore data with `mongorestore`,
    without the `--oplogReplay` option or `system.profile` collection data.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`restore`：提供使用`mongorestore`还原数据所需的权限，但不包括`--oplogReplay`选项或`system.profile`集合数据。'
- en: Roles across all databases
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 所有数据库中的角色
- en: 'Similarly, the following is the set of available roles across all databases:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，以下是所有数据库中可用的角色集合：
- en: '`readAnyDatabase`: Provides the same read-only permissions as `read`, except
    it applies to all but the local and config databases in the cluster. The role
    also provides the `listDatabases` action on the cluster as a whole.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`readAnyDatabase`：提供与`read`相同的只读权限，但适用于集群中除了本地和配置数据库之外的所有数据库。该角色还在整个集群上提供`listDatabases`操作。'
- en: '`readWriteAnyDatabase`: Provides the same read and write permissions as `readWrite`,
    except it applies to all but the local and config databases in the cluster. The
    role also provides the `listDatabases` action on the cluster as a whole.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`readWriteAnyDatabase`：提供与`readWrite`相同的读写权限，但适用于集群中除了本地和配置数据库之外的所有数据库。该角色还在整个集群上提供`listDatabases`操作。'
- en: '`userAdminAnyDatabase`: Provides the same access to user administration operations
    as `userAdmin`, except it applies to all but the local and config databases in
    the cluster. Since the `userAdminAnyDatabase` role allows users to grant any privilege
    to any user, including themselves, the role also indirectly provides superuser
    access.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`userAdminAnyDatabase`：提供与`userAdmin`相同的用户管理操作权限，但适用于集群中除了本地和配置数据库之外的所有数据库。由于`userAdminAnyDatabase`角色允许用户向任何用户授予任何权限，包括自己，该角色间接地提供了超级用户访问权限。'
- en: '`dbAdminAnyDatabase`: Provides the same access to database administration operations
    as `dbAdmin`, except it applies to all but the local and config databases in the
    cluster. The role also provides the `listDatabases` action on the cluster as a
    whole.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dbAdminAnyDatabase`：提供与`dbAdmin`相同的数据库管理操作权限，但适用于集群中除了本地和配置数据库之外的所有数据库。该角色还在整个集群上提供`listDatabases`操作。'
- en: Superuser
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超级用户
- en: 'Finally, the following are the superuser roles that are available:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，以下是可用的超级用户角色：
- en: '`root`: Provides access to the operations and all of the resources of the `readWriteAnyDatabase`,
    `dbAdminAnyDatabase`, `userAdminAnyDatabase`, `clusterAdmin`, `restore`, and `backup`
    combined'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`root`：提供对`readWriteAnyDatabase`、`dbAdminAnyDatabase`、`userAdminAnyDatabase`、`clusterAdmin`、`restore`和`backup`的操作和所有资源的访问权限'
- en: '`__internal`: Similar to the root user, any `__internal` user can perform any
    action against any object across the server'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__internal`：类似于root用户，任何`__internal`用户都可以对服务器上的任何对象执行任何操作。'
- en: Superuser roles should be avoided, as they can have potentially destructive
    permissions across all of the databases on our server.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 应避免使用超级用户角色，因为它们可能对服务器上的所有数据库具有潜在破坏性的权限。
- en: Network-level security
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络级安全
- en: 'Apart from MongoDB-specific security measures, there are best practices that
    have been established for network-level security:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 除了MongoDB特定的安全措施，还有针对网络级安全建立的最佳实践：
- en: Only allow communication between servers, and only open the ports that are used
    for communicating between them.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只允许服务器之间的通信，并且只打开用于它们之间通信的端口。
- en: Always use TLS/SSL for communication between servers. This prevents man-in-the-middle
    attacks from impersonating a client.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 始终使用TLS/SSL进行服务器之间的通信。这可以防止中间人攻击冒充客户端。
- en: Always use different sets of development, staging, and production environments
    and security credentials. Ideally, create different accounts for each environment,
    and enable two-factor authentication in both staging and production environments.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 始终使用不同的开发、暂存和生产环境以及安全凭据。理想情况下，为每个环境创建不同的帐户，并在暂存和生产环境中启用双因素身份验证。
- en: Auditing security
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审计安全
- en: No matter how much we plan our security measures, a second or third pair of
    eyes from someone outside of our organization can give a different view of our
    security measures and uncover problems that we may have underestimated or overlooked.
    Don't hesitate to involve security experts and white hat hackers to do penetration
    testing in your servers.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们如何计划我们的安全措施，来自我们组织之外的第二或第三双眼睛可以对我们的安全措施提供不同的视角，并发现我们可能低估或忽视的问题。不要犹豫，要请安全专家和白帽黑客对服务器进行渗透测试。
- en: Special cases
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特殊情况
- en: Medical or financial applications require added levels of security for data
    privacy reasons.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 出于数据隐私原因，医疗或金融应用程序需要增加安全级别。
- en: If we are building an application in the healthcare space, accessing users'
    personally identifiable information, we may need to get HIPAA certified.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们正在构建一个涉及医疗保健领域的应用程序，访问用户的个人身份信息，我们可能需要获得HIPAA认证。
- en: If we are building an application that interacts with payments and manages cardholder
    information, we may need to become PCI/DSS compliant.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们正在构建一个与支付交互并管理持卡人信息的应用程序，我们可能需要符合PCI/DSS标准。
- en: The specifics of each certification are outside the scope of this book, but
    it is important to know that MongoDB has use cases in these fields that fulfill
    the requirements, and, as such, it can be the right tool with proper design beforehand.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 每个认证的具体细节超出了本书的范围，但重要的是要知道MongoDB在这些领域有使用案例，满足要求，并且在适当的设计前可以成为正确的工具。
- en: Overview
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: 'Summing up the best practice recommendations involving security, we have the
    following:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 总结涉及安全的最佳实践建议，我们有以下内容：
- en: '**Enforce authentication**: Always enable authentication in production environments.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强制进行身份验证**：始终在生产环境中启用身份验证。'
- en: '**Enable access control**: First, create a system administrator, and then use
    that administrator to create more limited users. Give as few permissions as are
    needed for each user role.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启用访问控制**：首先创建一个系统管理员，然后使用该管理员创建更有限的用户。为每个用户角色提供所需的最少权限。'
- en: '**Define fine-grained roles in access control**: Do not give more permissions
    than are needed for each user.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义细粒度的访问控制角色**：不要给予每个用户比所需权限更多的权限。'
- en: '**Encrypt communication between clients and servers**: Always use TLS/SSL for
    communication between clients and servers in production environments. Always use
    TLS/SSL for communication between `mongod` and `mongos` or config servers, as
    well.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加密客户端和服务器之间的通信**：在生产环境中，始终使用TLS/SSL进行客户端和服务器之间的通信。对于`mongod`和`mongos`或配置服务器之间的通信，也应始终使用TLS/SSL。'
- en: '**Encrypt data at rest**: MongoDB Enterprise Edition offers the functionality
    to encrypt data when stored, using WiredTiger encryption at rest.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加密静止数据**：MongoDB企业版提供了在存储时加密数据的功能，使用WiredTiger静止加密。'
- en: Alternatively, we can encrypt data using filesystem, device, or physical encryption.
    In the cloud, we often get the option for encryption, as well (for example, with
    EBS on Amazon EC2).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用文件系统、设备或物理加密来加密数据。在云中，我们通常也可以选择加密（例如，在Amazon EC2上使用EBS）。
- en: '**Limit network exposure**: MongoDB servers should only be connected to the
    application servers and any other servers that are needed for operations. Ports
    other than the ones that we set up for MongoDB communications should not be open
    to the outside world. If we want to debug MongoDB usage, it''s important to have
    a proxy server with controlled access set up to communicate with our database.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**限制网络暴露**：MongoDB服务器应该只连接到应用程序服务器和其他必需的服务器。除了我们为MongoDB通信设置的端口之外，不应该对外界开放其他端口。如果我们想要调试MongoDB的使用，重要的是设置一个代理服务器，以受控访问与我们的数据库进行通信。'
- en: '**Audit servers for unusual activity**: MongoDB Enterprise Edition offers a
    utility for auditing. By using it, we can output events to the console, a JSON
    file, a BSON file, or the syslog. In any case, it''s important to make sure that
    audit events are stored in a partition that is not available to the system''s
    users.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**审计服务器以查找异常活动**：MongoDB企业版提供了一个审计实用程序。通过使用它，我们可以将事件输出到控制台、JSON文件、BSON文件或syslog。无论如何，重要的是确保审计事件存储在对系统用户不可用的分区中。'
- en: Use a dedicated operating system user to run MongoDB. Make sure that the dedicated
    operating system user can access MongoDB, but doesn't have unnecessary permissions.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用专用操作系统用户来运行MongoDB。确保专用操作系统用户可以访问MongoDB，但不具备不必要的权限。
- en: Disable JavaScript server-side scripts if they are not needed.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不需要，禁用JavaScript服务器端脚本。
- en: MongoDB can use JavaScript for server-side scripts with the following commands: `mapReduce()`,
    `group()`, and `$where`. If we don't need these commands, we should disable server-side
    scripting by using the `--noscripting` option on the command line.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB可以使用JavaScript进行服务器端脚本，使用以下命令：`mapReduce()`、`group()`和`$where`。如果我们不需要这些命令，我们应该在命令行上使用`--noscripting`选项禁用服务器端脚本。
- en: Summary
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you learned about three operational aspects of MongoDB: monitoring,
    backup, and security.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了MongoDB的三个操作方面：监控、备份和安全。
- en: We discussed the metrics that we should monitor in MongoDB, and how to monitor
    them. Following that, we discussed how to make backups and ensure that we can
    use them to restore our data. Finally, you learned about security with the authentication
    and authorization concepts, as well as network-level security and how to audit
    it.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了在MongoDB中应该监控的指标，以及如何监控它们。在此之后，我们讨论了如何进行备份并确保我们可以使用它们来恢复我们的数据。最后，您了解了身份验证和授权概念以及网络级安全以及如何对其进行审计。
- en: As important as it is to design, build, and extend our application as needed,
    it is equally important to make sure that we have peace of mind during operations
    and are safeguarded from unexpected events, such as human error and internal or
    external malicious users.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 设计、构建和根据需要扩展我们的应用程序同样重要，同样重要的是要确保在运营过程中我们能够心无旁骛，并且能够防范意外事件，比如人为错误和内部或外部恶意用户。
- en: In the next chapter, you will learn about pluggable storage engines, a new concept
    that was introduced in version 3.0 of MongoDB. Pluggable storage engines allow
    different use cases to be served, especially in application domains that have
    specific and stringent requirements concerning data handling and privacy.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将了解可插拔存储引擎，这是在MongoDB 3.0版本中引入的新概念。可插拔存储引擎允许满足不同的用例，特别是在具有特定和严格的数据处理和隐私要求的应用领域。
